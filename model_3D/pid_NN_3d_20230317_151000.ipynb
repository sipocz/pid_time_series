{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sipocz/pid_time_series/blob/main/model_3D/pid_NN_3d_20230317_151000.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0tNYnFR-6Xh",
        "outputId": "62a900f6-bff6-483b-e97c-5e1fb601397a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.14.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb) (63.4.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (8.1.3)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.17.0-py2.py3-none-any.whl (189 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.1/189.1 KB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (2.25.1)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (5.4.8)\n",
            "Collecting appdirs>=1.4.3\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.19.6)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.15.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=2f6def1525af59ff4994f86dc307b5829814b6c4c9bde4197418d2e6e21e4c42\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/0a/67/ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, appdirs, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.31 appdirs-1.4.4 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.17.0 setproctitle-1.3.2 smmap-5.0.0 wandb-0.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OWFIUUUGKGdA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import seaborn as sns\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ag6zIuPmKTux"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coqJiGk7KW_4",
        "outputId": "ea8091d4-4d01-4738-e0c0-e644e725c444"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-_usNw7yKZDt"
      },
      "outputs": [],
      "source": [
        "#user = \"Anna\"\n",
        "user = \"SL\"\n",
        "uzem = \"Szint3\"\n",
        "data_source=\"SINT3_415/3D_transposed\"\n",
        "#fname=\"72C03_TC_error_toNN.csv\"\n",
        "fname_good = \"415_SC_3D_part\"\n",
        "fname_bad = \"415_SC_3D_part\"\n",
        "fname_good_ext=[\"1.csv\",\"3.csv\",\"5.csv\",\"7.csv\"]\n",
        "fname_bad_ext=[\"2.csv\",\"4.csv\",\"6.csv\",\"8.csv\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OkO7F6NaKbxi"
      },
      "outputs": [],
      "source": [
        "# Elérési út a 415_SC_error-hoz\n",
        "if user==\"Anna\":\n",
        "    path_good = \"/content/drive/MyDrive/Egyetem_MSc/Diplomamunka/2022Anna/Datapipeline/\" + data_source + \"/\" + fname_good\n",
        "    path_bad = \"/content/drive/MyDrive/Egyetem_MSc/Diplomamunka/2022Anna/Datapipeline/\" + data_source + \"/\" + fname_bad\n",
        "    path_fig = \"/content/drive/MyDrive/Egyetem_MSc/Diplomamunka/2022Anna/Datapipeline/plots/\"\n",
        "else:\n",
        "    path_good = \"/content/drive/MyDrive/2022Anna/Datapipeline/\" + data_source + \"/\" + fname_good \n",
        "    path_bad = \"/content/drive/MyDrive/2022Anna/Datapipeline/\" + data_source + \"/\" + fname_bad\n",
        "    path_fig = \"/content/drive/MyDrive/2022Anna/Datapipeline/plots/\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5ZDDiY9KfAQ",
        "outputId": "66f48562-0315-4f19-d8e9-843d4be6c369"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/2022Anna/Datapipeline/SINT3_415/3D_transposed/415_SC_3D_part\n",
            "/content/drive/MyDrive/2022Anna/Datapipeline/SINT3_415/3D_transposed/415_SC_3D_part\n"
          ]
        }
      ],
      "source": [
        "print(path_good)\n",
        "print(path_bad)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols=[str(i) for i in range(60)]"
      ],
      "metadata": {
        "id": "SpsF7dVwl7bH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vUcMjZAGKvtt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc95c37e-fd2b-46e0-a829-8c7fd845ef16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n",
            "Index: []\n",
            "\n",
            "[0 rows x 60 columns]\n"
          ]
        }
      ],
      "source": [
        "df_good=pd.DataFrame(columns=cols)\n",
        "df_bad=pd.DataFrame(columns=cols)\n",
        "print(df_good.head())\n",
        "for i,goods in enumerate(fname_good_ext):\n",
        "    df_good_tmp = pd.read_csv(path_good+goods,usecols=None )\n",
        "    df_good_tmp.columns=cols\n",
        "    df_good=pd.concat([df_good,df_good_tmp],axis=0,)\n",
        "    df_bad_tmp = pd.read_csv(path_bad+fname_bad_ext[i],usecols=None)\n",
        "    df_bad_tmp.columns=cols\n",
        "    df_bad=pd.concat([df_bad,df_bad_tmp],axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYuDXKraLOt4",
        "outputId": "34c8ba6c-b76b-4bc8-df7f-2195126b8e18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "print(df_good.isnull().values.any())\n",
        "print(df_bad.isnull().values.any())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "vzl5zIO1LUoq",
        "outputId": "720b0542-8ad9-453a-f4c3-8cd0751dc383"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        0     1     2     3     4     5     6     7     8     9  ...  \\\n",
              "569  45.0  45.0  45.0  45.0  45.0  45.0  45.0  45.0  45.0  45.0  ...   \n",
              "570  45.0  45.0  45.0  45.0  45.0  45.0  45.0  45.0  45.0  45.0  ...   \n",
              "571  45.0  45.0  45.0  45.0  45.0  45.0  45.0  45.0  45.0  45.0  ...   \n",
              "572  45.0  45.0  45.0  45.0  45.0  45.0  45.0  45.0  45.0  45.0  ...   \n",
              "573  45.0  45.0  45.0  45.0  45.0  45.0  45.0  45.0  45.0  45.0  ...   \n",
              "\n",
              "           50        51        52        53        54        55        56  \\\n",
              "569  0.216297  0.216297  0.216297  0.216297  0.216297  0.216297  0.216297   \n",
              "570  0.216297  0.216297  0.216297  0.216297  0.216297  0.216297  0.216297   \n",
              "571  0.216297  0.216297  0.216297  0.216297  0.216297  0.216297  0.216297   \n",
              "572  0.216297  0.216297  0.216297  0.216297  0.216297  0.216297  0.216297   \n",
              "573  0.216297  0.216297  0.216297  0.216297  0.216297  0.216297  0.216297   \n",
              "\n",
              "           57        58        59  \n",
              "569  0.216297  0.216297  0.216297  \n",
              "570  0.216297  0.216297  0.216297  \n",
              "571  0.216297  0.216297  0.216297  \n",
              "572  0.216297  0.216297  0.163654  \n",
              "573  0.216297  0.163654  0.216297  \n",
              "\n",
              "[5 rows x 60 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-753423bc-4889-441f-8b66-5fd478fce7ac\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>569</th>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>570</th>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>571</th>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>572</th>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.163654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>573</th>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.216297</td>\n",
              "      <td>0.163654</td>\n",
              "      <td>0.216297</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 60 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-753423bc-4889-441f-8b66-5fd478fce7ac')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-753423bc-4889-441f-8b66-5fd478fce7ac button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-753423bc-4889-441f-8b66-5fd478fce7ac');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df_good.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "f0xJfadFMOfA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hIMQw2sULmj9"
      },
      "outputs": [],
      "source": [
        "\n",
        "import matplotlib.pyplot as plot\n",
        "\n",
        "df_ = df_good\n",
        "\n",
        "# You must normalize the data before applying the fit method\n",
        "df_good_normalized=(df_ - df_.mean()) / df_.std()\n",
        "\n",
        "# Normalize bad data with the good data parameters\n",
        "df_bad_normalized=(df_bad - df_.mean()) / df_.std()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wknFhIRBNQ7k"
      },
      "outputs": [],
      "source": [
        "df_good_normalized[\"state\"]=0\n",
        "df_bad_normalized[\"state\"]=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3W5mi70VM6hL"
      },
      "outputs": [],
      "source": [
        "df_good_normalized=df_good_normalized.reindex()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_good_normalized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "Vg9QgProrxU_",
        "outputId": "d633fb87-3742-42da-c739-7233c8b12a9b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0         1         2         3         4         5         6  \\\n",
              "0   -1.453455 -1.454954 -1.456455 -1.457960 -1.459467 -1.460977 -1.462489   \n",
              "1   -1.453455 -1.454954 -1.456455 -1.457960 -1.459467 -1.460977 -1.462489   \n",
              "2   -1.453455 -1.454954 -1.456455 -1.457960 -1.459467 -1.460977 -1.462489   \n",
              "3   -1.453455 -1.454954 -1.456455 -1.457960 -1.459467 -1.460977 -1.462489   \n",
              "4   -1.453455 -1.454954 -1.456455 -1.457960 -1.459467 -1.460977 -1.462489   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "569 -0.691638 -0.692917 -0.694198 -0.695481 -0.696765 -0.698051 -0.699339   \n",
              "570 -0.691638 -0.692917 -0.694198 -0.695481 -0.696765 -0.698051 -0.699339   \n",
              "571 -0.691638 -0.692917 -0.694198 -0.695481 -0.696765 -0.698051 -0.699339   \n",
              "572 -0.691638 -0.692917 -0.694198 -0.695481 -0.696765 -0.698051 -0.699339   \n",
              "573 -0.691638 -0.692917 -0.694198 -0.695481 -0.696765 -0.698051 -0.699339   \n",
              "\n",
              "            7         8         9  ...        51        52        53  \\\n",
              "0   -1.464005 -1.465523 -1.467043  ... -0.024124 -0.024124 -0.024124   \n",
              "1   -1.464005 -1.465523 -1.467043  ... -0.024124 -0.024124 -0.024124   \n",
              "2   -1.464005 -1.465523 -1.467043  ... -0.024124 -0.024124 -0.024124   \n",
              "3   -1.464005 -1.465523 -1.467043  ... -0.024124 -0.024124 -0.024124   \n",
              "4   -1.464005 -1.465523 -1.467043  ... -0.024124 -0.024124 -0.024124   \n",
              "..        ...       ...       ...  ...       ...       ...       ...   \n",
              "569 -0.700628 -0.701918 -0.703211  ... -0.025480 -0.025480 -0.025480   \n",
              "570 -0.700628 -0.701918 -0.703211  ... -0.025480 -0.025480 -0.025480   \n",
              "571 -0.700628 -0.701918 -0.703211  ... -0.025480 -0.025480 -0.025480   \n",
              "572 -0.700628 -0.701918 -0.703211  ... -0.025480 -0.025480 -0.025480   \n",
              "573 -0.700628 -0.701918 -0.703211  ... -0.025480 -0.025480 -0.025480   \n",
              "\n",
              "           54        55        56        57        58        59  state  \n",
              "0   -0.024124 -0.024124 -0.024124 -0.024124 -0.024118 -0.024223      0  \n",
              "1   -0.024124 -0.024124 -0.024124 -0.024124 -0.024118 -0.024223      0  \n",
              "2   -0.024124 -0.024124 -0.024124 -0.024124 -0.024118 -0.024223      0  \n",
              "3   -0.024124 -0.024124 -0.024124 -0.024124 -0.024118 -0.024223      0  \n",
              "4   -0.024124 -0.024124 -0.024124 -0.024124 -0.024118 -0.024223      0  \n",
              "..        ...       ...       ...       ...       ...       ...    ...  \n",
              "569 -0.025480 -0.025480 -0.025479 -0.025479 -0.025473 -0.025578      0  \n",
              "570 -0.025480 -0.025480 -0.025479 -0.025479 -0.025473 -0.025578      0  \n",
              "571 -0.025480 -0.025480 -0.025479 -0.025479 -0.025473 -0.025578      0  \n",
              "572 -0.025480 -0.025480 -0.025479 -0.025479 -0.025473 -0.041168      0  \n",
              "573 -0.025480 -0.025480 -0.025479 -0.025479 -0.041063 -0.025578      0  \n",
              "\n",
              "[2646 rows x 61 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-05cacdde-339e-4843-be4c-a0d56b513132\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.453455</td>\n",
              "      <td>-1.454954</td>\n",
              "      <td>-1.456455</td>\n",
              "      <td>-1.457960</td>\n",
              "      <td>-1.459467</td>\n",
              "      <td>-1.460977</td>\n",
              "      <td>-1.462489</td>\n",
              "      <td>-1.464005</td>\n",
              "      <td>-1.465523</td>\n",
              "      <td>-1.467043</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024118</td>\n",
              "      <td>-0.024223</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.453455</td>\n",
              "      <td>-1.454954</td>\n",
              "      <td>-1.456455</td>\n",
              "      <td>-1.457960</td>\n",
              "      <td>-1.459467</td>\n",
              "      <td>-1.460977</td>\n",
              "      <td>-1.462489</td>\n",
              "      <td>-1.464005</td>\n",
              "      <td>-1.465523</td>\n",
              "      <td>-1.467043</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024118</td>\n",
              "      <td>-0.024223</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.453455</td>\n",
              "      <td>-1.454954</td>\n",
              "      <td>-1.456455</td>\n",
              "      <td>-1.457960</td>\n",
              "      <td>-1.459467</td>\n",
              "      <td>-1.460977</td>\n",
              "      <td>-1.462489</td>\n",
              "      <td>-1.464005</td>\n",
              "      <td>-1.465523</td>\n",
              "      <td>-1.467043</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024118</td>\n",
              "      <td>-0.024223</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.453455</td>\n",
              "      <td>-1.454954</td>\n",
              "      <td>-1.456455</td>\n",
              "      <td>-1.457960</td>\n",
              "      <td>-1.459467</td>\n",
              "      <td>-1.460977</td>\n",
              "      <td>-1.462489</td>\n",
              "      <td>-1.464005</td>\n",
              "      <td>-1.465523</td>\n",
              "      <td>-1.467043</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024118</td>\n",
              "      <td>-0.024223</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.453455</td>\n",
              "      <td>-1.454954</td>\n",
              "      <td>-1.456455</td>\n",
              "      <td>-1.457960</td>\n",
              "      <td>-1.459467</td>\n",
              "      <td>-1.460977</td>\n",
              "      <td>-1.462489</td>\n",
              "      <td>-1.464005</td>\n",
              "      <td>-1.465523</td>\n",
              "      <td>-1.467043</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024118</td>\n",
              "      <td>-0.024223</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>569</th>\n",
              "      <td>-0.691638</td>\n",
              "      <td>-0.692917</td>\n",
              "      <td>-0.694198</td>\n",
              "      <td>-0.695481</td>\n",
              "      <td>-0.696765</td>\n",
              "      <td>-0.698051</td>\n",
              "      <td>-0.699339</td>\n",
              "      <td>-0.700628</td>\n",
              "      <td>-0.701918</td>\n",
              "      <td>-0.703211</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.025480</td>\n",
              "      <td>-0.025480</td>\n",
              "      <td>-0.025480</td>\n",
              "      <td>-0.025480</td>\n",
              "      <td>-0.025480</td>\n",
              "      <td>-0.025479</td>\n",
              "      <td>-0.025479</td>\n",
              "      <td>-0.025473</td>\n",
              "      <td>-0.025578</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>570</th>\n",
              "      <td>-0.691638</td>\n",
              "      <td>-0.692917</td>\n",
              "      <td>-0.694198</td>\n",
              "      <td>-0.695481</td>\n",
              "      <td>-0.696765</td>\n",
              "      <td>-0.698051</td>\n",
              "      <td>-0.699339</td>\n",
              "      <td>-0.700628</td>\n",
              "      <td>-0.701918</td>\n",
              "      <td>-0.703211</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.025480</td>\n",
              "      <td>-0.025480</td>\n",
              "      <td>-0.025480</td>\n",
              "      <td>-0.025480</td>\n",
              "      <td>-0.025480</td>\n",
              "      <td>-0.025479</td>\n",
              "      <td>-0.025479</td>\n",
              "      <td>-0.025473</td>\n",
              "      <td>-0.025578</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>571</th>\n",
              "      <td>-0.691638</td>\n",
              "      <td>-0.692917</td>\n",
              "      <td>-0.694198</td>\n",
              "      <td>-0.695481</td>\n",
              "      <td>-0.696765</td>\n",
              "      <td>-0.698051</td>\n",
              "      <td>-0.699339</td>\n",
              "      <td>-0.700628</td>\n",
              "      <td>-0.701918</td>\n",
              "      <td>-0.703211</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.025480</td>\n",
              "      <td>-0.025480</td>\n",
              "      <td>-0.025480</td>\n",
              "      <td>-0.025480</td>\n",
              "      <td>-0.025480</td>\n",
              "      <td>-0.025479</td>\n",
              "      <td>-0.025479</td>\n",
              "      <td>-0.025473</td>\n",
              "      <td>-0.025578</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>572</th>\n",
              "      <td>-0.691638</td>\n",
              "      <td>-0.692917</td>\n",
              "      <td>-0.694198</td>\n",
              "      <td>-0.695481</td>\n",
              "      <td>-0.696765</td>\n",
              "      <td>-0.698051</td>\n",
              "      <td>-0.699339</td>\n",
              "      <td>-0.700628</td>\n",
              "      <td>-0.701918</td>\n",
              "      <td>-0.703211</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.025480</td>\n",
              "      <td>-0.025480</td>\n",
              "      <td>-0.025480</td>\n",
              "      <td>-0.025480</td>\n",
              "      <td>-0.025480</td>\n",
              "      <td>-0.025479</td>\n",
              "      <td>-0.025479</td>\n",
              "      <td>-0.025473</td>\n",
              "      <td>-0.041168</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>573</th>\n",
              "      <td>-0.691638</td>\n",
              "      <td>-0.692917</td>\n",
              "      <td>-0.694198</td>\n",
              "      <td>-0.695481</td>\n",
              "      <td>-0.696765</td>\n",
              "      <td>-0.698051</td>\n",
              "      <td>-0.699339</td>\n",
              "      <td>-0.700628</td>\n",
              "      <td>-0.701918</td>\n",
              "      <td>-0.703211</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.025480</td>\n",
              "      <td>-0.025480</td>\n",
              "      <td>-0.025480</td>\n",
              "      <td>-0.025480</td>\n",
              "      <td>-0.025480</td>\n",
              "      <td>-0.025479</td>\n",
              "      <td>-0.025479</td>\n",
              "      <td>-0.041063</td>\n",
              "      <td>-0.025578</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2646 rows × 61 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05cacdde-339e-4843-be4c-a0d56b513132')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-05cacdde-339e-4843-be4c-a0d56b513132 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-05cacdde-339e-4843-be4c-a0d56b513132');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "9nY0OMtYPT8J"
      },
      "outputs": [],
      "source": [
        "df_all_normalized=pd.concat([df_good_normalized,df_bad_normalized],axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "ClfUnwBRPwgK",
        "outputId": "26435364-cdbc-45a0-bd01-d5117b4c1b69"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0         1         2         3         4         5         6  \\\n",
              "0   -1.453455 -1.454954 -1.456455 -1.457960 -1.459467 -1.460977 -1.462489   \n",
              "1   -1.453455 -1.454954 -1.456455 -1.457960 -1.459467 -1.460977 -1.462489   \n",
              "2   -1.453455 -1.454954 -1.456455 -1.457960 -1.459467 -1.460977 -1.462489   \n",
              "3   -1.453455 -1.454954 -1.456455 -1.457960 -1.459467 -1.460977 -1.462489   \n",
              "4   -1.453455 -1.454954 -1.456455 -1.457960 -1.459467 -1.460977 -1.462489   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "515 -0.310730 -0.311899 -0.313070 -0.314242 -0.315414 -0.316588 -0.317763   \n",
              "516 -0.310730 -0.311899 -0.313070 -0.314242 -0.315414 -0.316588 -0.317763   \n",
              "517 -0.310730 -0.311899 -0.313070 -0.314242 -0.315414 -0.316588 -0.317763   \n",
              "518 -0.310730 -0.311899 -0.313070 -0.314242 -0.315414 -0.316588 -0.317763   \n",
              "519 -0.310730 -0.311899 -0.313070 -0.314242 -0.315414 -0.316588 -0.317763   \n",
              "\n",
              "            7         8         9  ...        51        52        53  \\\n",
              "0   -1.464005 -1.465523 -1.467043  ... -0.024124 -0.024124 -0.024124   \n",
              "1   -1.464005 -1.465523 -1.467043  ... -0.024124 -0.024124 -0.024124   \n",
              "2   -1.464005 -1.465523 -1.467043  ... -0.024124 -0.024124 -0.024124   \n",
              "3   -1.464005 -1.465523 -1.467043  ... -0.024124 -0.024124 -0.024124   \n",
              "4   -1.464005 -1.465523 -1.467043  ... -0.024124 -0.024124 -0.024124   \n",
              "..        ...       ...       ...  ...       ...       ...       ...   \n",
              "515 -0.318939 -0.320116 -0.321295  ... -0.370495  2.344881  3.525656   \n",
              "516 -0.318939 -0.320116 -0.321295  ...  2.344881  3.525656  1.690100   \n",
              "517 -0.318939 -0.320116 -0.321295  ...  3.525656  1.690100 -2.078618   \n",
              "518 -0.318939 -0.320116 -0.321295  ...  1.690100 -2.078619 -2.669684   \n",
              "519 -0.318939 -0.320116 -0.321295  ... -2.078619 -2.669684  0.108052   \n",
              "\n",
              "           54        55        56        57        58        59  state  \n",
              "0   -0.024124 -0.024124 -0.024124 -0.024124 -0.024118 -0.024223      0  \n",
              "1   -0.024124 -0.024124 -0.024124 -0.024124 -0.024118 -0.024223      0  \n",
              "2   -0.024124 -0.024124 -0.024124 -0.024124 -0.024118 -0.024223      0  \n",
              "3   -0.024124 -0.024124 -0.024124 -0.024124 -0.024118 -0.024223      0  \n",
              "4   -0.024124 -0.024124 -0.024124 -0.024124 -0.024118 -0.024223      0  \n",
              "..        ...       ...       ...       ...       ...       ...    ...  \n",
              "515  1.690100 -2.078618 -2.669683  0.108053  2.199832  2.951400      1  \n",
              "516 -2.078618 -2.669683  0.108053  2.199826  2.951541  3.221172      1  \n",
              "517 -2.669683  0.108053  2.199826  2.951536  3.221317  1.193817      1  \n",
              "518  0.108052  2.199826  2.951536  3.221312  1.193936 -2.382354      1  \n",
              "519  2.199826  2.951536  3.221312  1.193931 -2.382277  0.507865      1  \n",
              "\n",
              "[5658 rows x 61 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e96a3146-509a-44d2-b5fb-93b8cf205329\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.453455</td>\n",
              "      <td>-1.454954</td>\n",
              "      <td>-1.456455</td>\n",
              "      <td>-1.457960</td>\n",
              "      <td>-1.459467</td>\n",
              "      <td>-1.460977</td>\n",
              "      <td>-1.462489</td>\n",
              "      <td>-1.464005</td>\n",
              "      <td>-1.465523</td>\n",
              "      <td>-1.467043</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024118</td>\n",
              "      <td>-0.024223</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.453455</td>\n",
              "      <td>-1.454954</td>\n",
              "      <td>-1.456455</td>\n",
              "      <td>-1.457960</td>\n",
              "      <td>-1.459467</td>\n",
              "      <td>-1.460977</td>\n",
              "      <td>-1.462489</td>\n",
              "      <td>-1.464005</td>\n",
              "      <td>-1.465523</td>\n",
              "      <td>-1.467043</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024118</td>\n",
              "      <td>-0.024223</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.453455</td>\n",
              "      <td>-1.454954</td>\n",
              "      <td>-1.456455</td>\n",
              "      <td>-1.457960</td>\n",
              "      <td>-1.459467</td>\n",
              "      <td>-1.460977</td>\n",
              "      <td>-1.462489</td>\n",
              "      <td>-1.464005</td>\n",
              "      <td>-1.465523</td>\n",
              "      <td>-1.467043</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024118</td>\n",
              "      <td>-0.024223</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.453455</td>\n",
              "      <td>-1.454954</td>\n",
              "      <td>-1.456455</td>\n",
              "      <td>-1.457960</td>\n",
              "      <td>-1.459467</td>\n",
              "      <td>-1.460977</td>\n",
              "      <td>-1.462489</td>\n",
              "      <td>-1.464005</td>\n",
              "      <td>-1.465523</td>\n",
              "      <td>-1.467043</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024118</td>\n",
              "      <td>-0.024223</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.453455</td>\n",
              "      <td>-1.454954</td>\n",
              "      <td>-1.456455</td>\n",
              "      <td>-1.457960</td>\n",
              "      <td>-1.459467</td>\n",
              "      <td>-1.460977</td>\n",
              "      <td>-1.462489</td>\n",
              "      <td>-1.464005</td>\n",
              "      <td>-1.465523</td>\n",
              "      <td>-1.467043</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024124</td>\n",
              "      <td>-0.024118</td>\n",
              "      <td>-0.024223</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>-0.310730</td>\n",
              "      <td>-0.311899</td>\n",
              "      <td>-0.313070</td>\n",
              "      <td>-0.314242</td>\n",
              "      <td>-0.315414</td>\n",
              "      <td>-0.316588</td>\n",
              "      <td>-0.317763</td>\n",
              "      <td>-0.318939</td>\n",
              "      <td>-0.320116</td>\n",
              "      <td>-0.321295</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.370495</td>\n",
              "      <td>2.344881</td>\n",
              "      <td>3.525656</td>\n",
              "      <td>1.690100</td>\n",
              "      <td>-2.078618</td>\n",
              "      <td>-2.669683</td>\n",
              "      <td>0.108053</td>\n",
              "      <td>2.199832</td>\n",
              "      <td>2.951400</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>-0.310730</td>\n",
              "      <td>-0.311899</td>\n",
              "      <td>-0.313070</td>\n",
              "      <td>-0.314242</td>\n",
              "      <td>-0.315414</td>\n",
              "      <td>-0.316588</td>\n",
              "      <td>-0.317763</td>\n",
              "      <td>-0.318939</td>\n",
              "      <td>-0.320116</td>\n",
              "      <td>-0.321295</td>\n",
              "      <td>...</td>\n",
              "      <td>2.344881</td>\n",
              "      <td>3.525656</td>\n",
              "      <td>1.690100</td>\n",
              "      <td>-2.078618</td>\n",
              "      <td>-2.669683</td>\n",
              "      <td>0.108053</td>\n",
              "      <td>2.199826</td>\n",
              "      <td>2.951541</td>\n",
              "      <td>3.221172</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>-0.310730</td>\n",
              "      <td>-0.311899</td>\n",
              "      <td>-0.313070</td>\n",
              "      <td>-0.314242</td>\n",
              "      <td>-0.315414</td>\n",
              "      <td>-0.316588</td>\n",
              "      <td>-0.317763</td>\n",
              "      <td>-0.318939</td>\n",
              "      <td>-0.320116</td>\n",
              "      <td>-0.321295</td>\n",
              "      <td>...</td>\n",
              "      <td>3.525656</td>\n",
              "      <td>1.690100</td>\n",
              "      <td>-2.078618</td>\n",
              "      <td>-2.669683</td>\n",
              "      <td>0.108053</td>\n",
              "      <td>2.199826</td>\n",
              "      <td>2.951536</td>\n",
              "      <td>3.221317</td>\n",
              "      <td>1.193817</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>518</th>\n",
              "      <td>-0.310730</td>\n",
              "      <td>-0.311899</td>\n",
              "      <td>-0.313070</td>\n",
              "      <td>-0.314242</td>\n",
              "      <td>-0.315414</td>\n",
              "      <td>-0.316588</td>\n",
              "      <td>-0.317763</td>\n",
              "      <td>-0.318939</td>\n",
              "      <td>-0.320116</td>\n",
              "      <td>-0.321295</td>\n",
              "      <td>...</td>\n",
              "      <td>1.690100</td>\n",
              "      <td>-2.078619</td>\n",
              "      <td>-2.669684</td>\n",
              "      <td>0.108052</td>\n",
              "      <td>2.199826</td>\n",
              "      <td>2.951536</td>\n",
              "      <td>3.221312</td>\n",
              "      <td>1.193936</td>\n",
              "      <td>-2.382354</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>519</th>\n",
              "      <td>-0.310730</td>\n",
              "      <td>-0.311899</td>\n",
              "      <td>-0.313070</td>\n",
              "      <td>-0.314242</td>\n",
              "      <td>-0.315414</td>\n",
              "      <td>-0.316588</td>\n",
              "      <td>-0.317763</td>\n",
              "      <td>-0.318939</td>\n",
              "      <td>-0.320116</td>\n",
              "      <td>-0.321295</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.078619</td>\n",
              "      <td>-2.669684</td>\n",
              "      <td>0.108052</td>\n",
              "      <td>2.199826</td>\n",
              "      <td>2.951536</td>\n",
              "      <td>3.221312</td>\n",
              "      <td>1.193931</td>\n",
              "      <td>-2.382277</td>\n",
              "      <td>0.507865</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5658 rows × 61 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e96a3146-509a-44d2-b5fb-93b8cf205329')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e96a3146-509a-44d2-b5fb-93b8cf205329 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e96a3146-509a-44d2-b5fb-93b8cf205329');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "df_all_normalized"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n"
      ],
      "metadata": {
        "id": "nVvhP84S_F1y"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_N1_=700 #70  #700\n",
        "_N2_=120 #12  #120\n",
        "_lr_=0.001\n",
        "_batch_size_=3\n",
        "_drop1_=0.5\n",
        "_drop2_=0.5\n",
        "_epochs_=9500\n"
      ],
      "metadata": {
        "id": "XC5_bGE0iyi4"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"lr\": _lr_, \"batch_size\": _batch_size_,\"architecture\": \"NN\", \n",
        "          \"depth\": 2,\n",
        "          \"layer1\":_N1_,  \"layer2\":_N2_, \n",
        "          \"drop1\":_drop1_,\"drop2\":_drop2_,\n",
        "          \"epochs\":_epochs_\n",
        "          \n",
        "          \n",
        "          }\n",
        "\n",
        "wandb.init(project=\"pid_3d\", entity=\"sipoczlaszlo\",config=config)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540,
          "referenced_widgets": [
            "c87c61177f4748b2bdfb31295cff1fda",
            "9e1844b69cf74824b0d2fab73f57ed81",
            "39a0d96ff0b24795959e6728ca72d8a3",
            "0d239abe35ed490da92da3bc36facb7e",
            "b19d54cce6d94f11bd5054348d3531b5",
            "a1a9e4c9c55d4aa0a705214aeb709898",
            "344fd49416ff433aa6504eff336f98b3",
            "90c5214645e34f709e7d8aad1abc70e4"
          ]
        },
        "id": "nOtKllcviuoj",
        "outputId": "9d3582f5-7280-415b-d40e-ffbfad11d7d8"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:nhpb4lrp) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c87c61177f4748b2bdfb31295cff1fda"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁▂▃▃▃▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇███████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃█████████▃▃▃▃▃▃▃▃▃▃▁▁</td></tr><tr><td>epoch/loss</td><td>█▆▆▆▆▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/lr</td><td>▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃█████████▃▃▃▃▃▃▃▃▃▃▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▂▂▃▂▂▃▃▅▆▅▅▅▅▅▅▅▅▆▅▆▆▆▇▇▇▇▇▇█▇▇██▇▇█▇▇▇</td></tr><tr><td>epoch/val_loss</td><td>▃▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▄▃▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.96787</td></tr><tr><td>epoch/epoch</td><td>4258</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.07419</td></tr><tr><td>epoch/lr</td><td>0.001</td></tr><tr><td>epoch/val_accuracy</td><td>0.96703</td></tr><tr><td>epoch/val_loss</td><td>0.50499</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">brisk-night-14</strong> at: <a href='https://wandb.ai/sipoczlaszlo/pid_3d/runs/nhpb4lrp' target=\"_blank\">https://wandb.ai/sipoczlaszlo/pid_3d/runs/nhpb4lrp</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230317_134225-nhpb4lrp/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:nhpb4lrp). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230317_140044-5lacvevp</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sipoczlaszlo/pid_3d/runs/5lacvevp' target=\"_blank\">charmed-dawn-15</a></strong> to <a href='https://wandb.ai/sipoczlaszlo/pid_3d' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sipoczlaszlo/pid_3d' target=\"_blank\">https://wandb.ai/sipoczlaszlo/pid_3d</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sipoczlaszlo/pid_3d/runs/5lacvevp' target=\"_blank\">https://wandb.ai/sipoczlaszlo/pid_3d/runs/5lacvevp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/sipoczlaszlo/pid_3d/runs/5lacvevp?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f24a73ff610>"
            ]
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "id": "rcPrX4lWP2R_"
      },
      "outputs": [],
      "source": [
        "from keras.engine.base_layer import regularizers\n",
        "from keras.layers import InputLayer, Dense, LSTM, Input, Dropout\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import SGD,Adam,Adamax,Nadam,Ftrl,Adadelta\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from keras.backend import clear_session\n",
        "from tensorflow.keras.losses import mean_absolute_percentage_error, huber,kld\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "clear_session()\n",
        "\n",
        "kernel_reg_1=tf.keras.regularizers.L2(0.1)\n",
        "\n",
        "input_size=60\n",
        "\n",
        "\n",
        "input1=Input(shape=(input_size,))\n",
        "l1_out=Dense(_N1_,activation=\"swish\",kernel_initializer='glorot_uniform',)(input1) # kernel_initializer='lecun_normal'\n",
        "l2_out=Dropout(_drop1_)(l1_out)\n",
        "\n",
        "\n",
        "l3_out=Dense(_N2_,activation=\"swish\",kernel_initializer='glorot_uniform',)(l2_out) #kernel_initializer='lecun_normal',\n",
        "l4_out=Dropout(_drop2_)(l3_out)\n",
        "\n",
        "pred=Dense(1, activation=\"sigmoid\",)(l4_out)\n",
        "\n",
        "model = Model(inputs=input1, outputs=pred)\n",
        "optimizer=Adamax(learning_rate=_lr_,) #\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "    optimizer=optimizer,\n",
        "    metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "id": "yLzRRMnbIk9X"
      },
      "outputs": [],
      "source": [
        "# 35 5 1 relu relu sigmoid SGD 0.01 loss: 0.1402 - accuracy: 0.9435 - val_loss: 0.7302 - val_accuracy: 0.8548\n",
        "# 35 12 1 relu relu sigmoid SGD 0.01 loss 0.1162 94.6% test : 85%\n",
        "# 17 5 1 relu relu sigmoid SGD 0.01  loss: 0.1714 - accuracy: 0.9300 - val_loss: 0.9535 - val_accuracy: 0.8503\n",
        "# 35 5 1 relu relu sigmoid Adam 0.01 loss: 0.1238 - accuracy: 0.9467 - val_loss: 5.7545 - val_accuracy: 0.8653\n",
        "# 35 5 1 relu relu sigmoid Adamax 0.01 loss: 0.1184 - accuracy: 0.9525 - val_loss: 3.5327 - val_accuracy: 0.8428\n",
        "# 35 5 1 relu relu sigmoid Adamax 0.001 loss: 0.1185 - accuracy: 0.9525 - val_loss: 2.3218 - val_accuracy: 0.8593\n",
        "# 35 5 1 relu relu sigmoid Adamax 0.001 loss: 0.1041 - accuracy: 0.9576 - val_loss: 5.1465 - val_accuracy: 0.8353  +1300 epoch \n",
        "# 135 15 1 swish swish sigmoid Adamax 0.001 batch size:1 epoch 100 loss: 0.1707 - accuracy: 0.9352 - val_loss: 0.8066 - val_accuracy: 0.8892   **** egész jó\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "id": "RGIztQ3tQ3ni"
      },
      "outputs": [],
      "source": [
        "prediktorok=cols\n",
        "X_NN=df_all_normalized[prediktorok][:]  # \n",
        "y_NN=df_all_normalized[\"state\"][:]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_file=\"model_PID__54_loss_0.116_vloss_0.115_acc_0.953_vacc_0.958.hdf5\"\n",
        "#model_file=\"model_PID__94_loss_0.116_vloss_0.115_acc_0.950_vacc_0.966.hdf5\"\n",
        "model_file=\"model_PID__4491_loss_0.115_vloss_0.679_acc_0.954_vacc_0.880.hdf5\""
      ],
      "metadata": {
        "id": "DgjVCU185nNO"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_url=\"https://github.com/sipocz/pid_time_series/raw/main/model3/\"+model_file"
      ],
      "metadata": {
        "id": "iUhe0_4L5ufk"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "__load_file__=False"
      ],
      "metadata": {
        "id": "UIxI3AS6Yw3S"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __load_file__:\n",
        "    ! rm *.hdf5 \n",
        "    ! wget $model_url\n",
        "    model.load_weights(model_file)"
      ],
      "metadata": {
        "id": "ZNjx5XGesZPO"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {
        "id": "rdH49nLKRVoh"
      },
      "outputs": [],
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(X_NN,y_NN,train_size=0.7,shuffle=True,random_state=33)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm *.hdf5 "
      ],
      "metadata": {
        "id": "jJfOOTfGfDXi"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def learning_rate_corrector(epoch,lr):\n",
        "    if epoch > 4000:\n",
        "        lr = 0.001\n",
        "        return lr\n",
        "    if epoch > 3000:\n",
        "        lr = 0.002\n",
        "        return lr\n",
        "    if epoch > 2000:\n",
        "        lr = 0.005\n",
        "        return lr\n",
        "    \n",
        "    if epoch > 500:\n",
        "        lr = 0.002\n",
        "        return lr\n",
        "    return lr\n",
        "    "
      ],
      "metadata": {
        "id": "A-Kv8ORiEfub"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wandb.keras import WandbMetricsLogger\n",
        "fname=\"./model_PID_3D\"\n",
        "callbacks = [\n",
        "        LearningRateScheduler(learning_rate_corrector,verbose=1),\n",
        "        WandbMetricsLogger(),       \n",
        "        ModelCheckpoint(filepath=fname+\"_{epoch:04.0f}\"+\"_loss_{loss:.3f}_vloss_{val_loss:.3f}_acc_{accuracy:.3f}_vacc_{val_accuracy:.3f}.hdf5\", monitor='loss',\n",
        "                        verbose=2, save_best_only=True, mode='min')]\n"
      ],
      "metadata": {
        "id": "RNfi--Kfo4HM"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "__learning__=True"
      ],
      "metadata": {
        "id": "O6ofy0moderd"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Z3Z4q14D7eC"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ol0mW6WRlkS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ef08dd9-57b7-40e9-f1db-248cf4e78b70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mA streamkimeneten csak az utolsó 5000 sor látható.\u001b[0m\n",
            "\n",
            "Epoch 1534: loss did not improve from 0.17124\n",
            "\n",
            "Epoch 1535: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1535: loss did not improve from 0.17124\n",
            "\n",
            "Epoch 1536: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1536: loss did not improve from 0.17124\n",
            "\n",
            "Epoch 1537: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1537: loss did not improve from 0.17124\n",
            "\n",
            "Epoch 1538: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1538: loss improved from 0.17124 to 0.17065, saving model to ./model_PID_3D_1538_loss_0.171_vloss_0.272_acc_0.924_vacc_0.929.hdf5\n",
            "\n",
            "Epoch 1539: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1539: loss did not improve from 0.17065\n",
            "\n",
            "Epoch 1540: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1540: loss did not improve from 0.17065\n",
            "\n",
            "Epoch 1541: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1541: loss did not improve from 0.17065\n",
            "\n",
            "Epoch 1542: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1542: loss did not improve from 0.17065\n",
            "\n",
            "Epoch 1543: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1543: loss did not improve from 0.17065\n",
            "\n",
            "Epoch 1544: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1544: loss did not improve from 0.17065\n",
            "\n",
            "Epoch 1545: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1545: loss improved from 0.17065 to 0.17002, saving model to ./model_PID_3D_1545_loss_0.170_vloss_0.272_acc_0.919_vacc_0.930.hdf5\n",
            "\n",
            "Epoch 1546: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1546: loss did not improve from 0.17002\n",
            "\n",
            "Epoch 1547: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1547: loss did not improve from 0.17002\n",
            "\n",
            "Epoch 1548: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1548: loss did not improve from 0.17002\n",
            "\n",
            "Epoch 1549: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1549: loss did not improve from 0.17002\n",
            "\n",
            "Epoch 1550: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1550: loss did not improve from 0.17002\n",
            "\n",
            "Epoch 1551: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1551: loss did not improve from 0.17002\n",
            "\n",
            "Epoch 1552: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1552: loss did not improve from 0.17002\n",
            "\n",
            "Epoch 1553: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1553: loss did not improve from 0.17002\n",
            "\n",
            "Epoch 1554: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1554: loss did not improve from 0.17002\n",
            "\n",
            "Epoch 1555: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1555: loss did not improve from 0.17002\n",
            "\n",
            "Epoch 1556: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1556: loss did not improve from 0.17002\n",
            "\n",
            "Epoch 1557: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1557: loss did not improve from 0.17002\n",
            "\n",
            "Epoch 1558: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1558: loss did not improve from 0.17002\n",
            "\n",
            "Epoch 1559: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1559: loss did not improve from 0.17002\n",
            "\n",
            "Epoch 1560: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1560: loss did not improve from 0.17002\n",
            "\n",
            "Epoch 1561: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1561: loss did not improve from 0.17002\n",
            "\n",
            "Epoch 1562: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1562: loss improved from 0.17002 to 0.16979, saving model to ./model_PID_3D_1562_loss_0.170_vloss_0.273_acc_0.919_vacc_0.928.hdf5\n",
            "\n",
            "Epoch 1563: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1563: loss did not improve from 0.16979\n",
            "\n",
            "Epoch 1564: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1564: loss did not improve from 0.16979\n",
            "\n",
            "Epoch 1565: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1565: loss did not improve from 0.16979\n",
            "\n",
            "Epoch 1566: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1566: loss did not improve from 0.16979\n",
            "\n",
            "Epoch 1567: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1567: loss improved from 0.16979 to 0.16885, saving model to ./model_PID_3D_1567_loss_0.169_vloss_0.274_acc_0.922_vacc_0.918.hdf5\n",
            "\n",
            "Epoch 1568: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1568: loss did not improve from 0.16885\n",
            "\n",
            "Epoch 1569: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1569: loss did not improve from 0.16885\n",
            "\n",
            "Epoch 1570: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1570: loss did not improve from 0.16885\n",
            "\n",
            "Epoch 1571: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1571: loss did not improve from 0.16885\n",
            "\n",
            "Epoch 1572: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1572: loss did not improve from 0.16885\n",
            "\n",
            "Epoch 1573: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1573: loss did not improve from 0.16885\n",
            "\n",
            "Epoch 1574: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1574: loss did not improve from 0.16885\n",
            "\n",
            "Epoch 1575: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1575: loss did not improve from 0.16885\n",
            "\n",
            "Epoch 1576: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1576: loss did not improve from 0.16885\n",
            "\n",
            "Epoch 1577: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1577: loss did not improve from 0.16885\n",
            "\n",
            "Epoch 1578: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1578: loss did not improve from 0.16885\n",
            "\n",
            "Epoch 1579: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1579: loss did not improve from 0.16885\n",
            "\n",
            "Epoch 1580: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1580: loss did not improve from 0.16885\n",
            "\n",
            "Epoch 1581: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1581: loss did not improve from 0.16885\n",
            "\n",
            "Epoch 1582: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1582: loss did not improve from 0.16885\n",
            "\n",
            "Epoch 1583: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1583: loss did not improve from 0.16885\n",
            "\n",
            "Epoch 1584: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1584: loss did not improve from 0.16885\n",
            "\n",
            "Epoch 1585: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1585: loss did not improve from 0.16885\n",
            "\n",
            "Epoch 1586: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1586: loss did not improve from 0.16885\n",
            "\n",
            "Epoch 1587: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1587: loss did not improve from 0.16885\n",
            "\n",
            "Epoch 1588: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1588: loss did not improve from 0.16885\n",
            "\n",
            "Epoch 1589: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1589: loss did not improve from 0.16885\n",
            "\n",
            "Epoch 1590: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1590: loss did not improve from 0.16885\n",
            "\n",
            "Epoch 1591: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1591: loss did not improve from 0.16885\n",
            "\n",
            "Epoch 1592: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1592: loss did not improve from 0.16885\n",
            "\n",
            "Epoch 1593: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1593: loss improved from 0.16885 to 0.16571, saving model to ./model_PID_3D_1593_loss_0.166_vloss_0.274_acc_0.923_vacc_0.929.hdf5\n",
            "\n",
            "Epoch 1594: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1594: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1595: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1595: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1596: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1596: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1597: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1597: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1598: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1598: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1599: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1599: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1600: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1600: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1601: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1601: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1602: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1602: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1603: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1603: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1604: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1604: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1605: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1605: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1606: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1606: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1607: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1607: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1608: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1608: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1609: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1609: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1610: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1610: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1611: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1611: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1612: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1612: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1613: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1613: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1614: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1614: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1615: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1615: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1616: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1616: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1617: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1617: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1618: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1618: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1619: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1619: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1620: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1620: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1621: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1621: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1622: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1622: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1623: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1623: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1624: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1624: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1625: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1625: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1626: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1626: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1627: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1627: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1628: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1628: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1629: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1629: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1630: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1630: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1631: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1631: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1632: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1632: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1633: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1633: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1634: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1634: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1635: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1635: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1636: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1636: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1637: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1637: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1638: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1638: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1639: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1639: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1640: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1640: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1641: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1641: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1642: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1642: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1643: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1643: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1644: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1644: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1645: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1645: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1646: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1646: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1647: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1647: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1648: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1648: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1649: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1649: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1650: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1650: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1651: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1651: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1652: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1652: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1653: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1653: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1654: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1654: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1655: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1655: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1656: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1656: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1657: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1657: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1658: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1658: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1659: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1659: loss did not improve from 0.16571\n",
            "\n",
            "Epoch 1660: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1660: loss improved from 0.16571 to 0.16527, saving model to ./model_PID_3D_1660_loss_0.165_vloss_0.283_acc_0.921_vacc_0.930.hdf5\n",
            "\n",
            "Epoch 1661: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1661: loss did not improve from 0.16527\n",
            "\n",
            "Epoch 1662: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1662: loss did not improve from 0.16527\n",
            "\n",
            "Epoch 1663: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1663: loss did not improve from 0.16527\n",
            "\n",
            "Epoch 1664: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1664: loss did not improve from 0.16527\n",
            "\n",
            "Epoch 1665: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1665: loss did not improve from 0.16527\n",
            "\n",
            "Epoch 1666: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1666: loss did not improve from 0.16527\n",
            "\n",
            "Epoch 1667: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1667: loss did not improve from 0.16527\n",
            "\n",
            "Epoch 1668: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1668: loss improved from 0.16527 to 0.16291, saving model to ./model_PID_3D_1668_loss_0.163_vloss_0.281_acc_0.923_vacc_0.928.hdf5\n",
            "\n",
            "Epoch 1669: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1669: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1670: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1670: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1671: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1671: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1672: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1672: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1673: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1673: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1674: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1674: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1675: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1675: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1676: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1676: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1677: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1677: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1678: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1678: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1679: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1679: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1680: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1680: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1681: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1681: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1682: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1682: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1683: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1683: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1684: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1684: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1685: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1685: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1686: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1686: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1687: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1687: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1688: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1688: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1689: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1689: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1690: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1690: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1691: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1691: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1692: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1692: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1693: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1693: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1694: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1694: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1695: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1695: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1696: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1696: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1697: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1697: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1698: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1698: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1699: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1699: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1700: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1700: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1701: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1701: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1702: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1702: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1703: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1703: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1704: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1704: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1705: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1705: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1706: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1706: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1707: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1707: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1708: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1708: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1709: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1709: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1710: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1710: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1711: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1711: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1712: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1712: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1713: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1713: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1714: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1714: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1715: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1715: loss did not improve from 0.16291\n",
            "\n",
            "Epoch 1716: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1716: loss improved from 0.16291 to 0.16223, saving model to ./model_PID_3D_1716_loss_0.162_vloss_0.284_acc_0.926_vacc_0.929.hdf5\n",
            "\n",
            "Epoch 1717: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1717: loss did not improve from 0.16223\n",
            "\n",
            "Epoch 1718: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1718: loss did not improve from 0.16223\n",
            "\n",
            "Epoch 1719: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1719: loss did not improve from 0.16223\n",
            "\n",
            "Epoch 1720: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1720: loss did not improve from 0.16223\n",
            "\n",
            "Epoch 1721: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1721: loss did not improve from 0.16223\n",
            "\n",
            "Epoch 1722: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1722: loss did not improve from 0.16223\n",
            "\n",
            "Epoch 1723: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1723: loss did not improve from 0.16223\n",
            "\n",
            "Epoch 1724: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1724: loss did not improve from 0.16223\n",
            "\n",
            "Epoch 1725: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1725: loss did not improve from 0.16223\n",
            "\n",
            "Epoch 1726: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1726: loss did not improve from 0.16223\n",
            "\n",
            "Epoch 1727: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1727: loss did not improve from 0.16223\n",
            "\n",
            "Epoch 1728: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1728: loss did not improve from 0.16223\n",
            "\n",
            "Epoch 1729: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1729: loss did not improve from 0.16223\n",
            "\n",
            "Epoch 1730: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1730: loss did not improve from 0.16223\n",
            "\n",
            "Epoch 1731: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1731: loss did not improve from 0.16223\n",
            "\n",
            "Epoch 1732: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1732: loss did not improve from 0.16223\n",
            "\n",
            "Epoch 1733: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1733: loss did not improve from 0.16223\n",
            "\n",
            "Epoch 1734: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1734: loss did not improve from 0.16223\n",
            "\n",
            "Epoch 1735: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1735: loss did not improve from 0.16223\n",
            "\n",
            "Epoch 1736: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1736: loss did not improve from 0.16223\n",
            "\n",
            "Epoch 1737: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1737: loss did not improve from 0.16223\n",
            "\n",
            "Epoch 1738: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1738: loss did not improve from 0.16223\n",
            "\n",
            "Epoch 1739: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1739: loss did not improve from 0.16223\n",
            "\n",
            "Epoch 1740: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1740: loss did not improve from 0.16223\n",
            "\n",
            "Epoch 1741: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1741: loss did not improve from 0.16223\n",
            "\n",
            "Epoch 1742: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1742: loss did not improve from 0.16223\n",
            "\n",
            "Epoch 1743: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1743: loss did not improve from 0.16223\n",
            "\n",
            "Epoch 1744: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1744: loss did not improve from 0.16223\n",
            "\n",
            "Epoch 1745: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1745: loss did not improve from 0.16223\n",
            "\n",
            "Epoch 1746: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1746: loss improved from 0.16223 to 0.16218, saving model to ./model_PID_3D_1746_loss_0.162_vloss_0.284_acc_0.920_vacc_0.925.hdf5\n",
            "\n",
            "Epoch 1747: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1747: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1748: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1748: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1749: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1749: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1750: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1750: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1751: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1751: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1752: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1752: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1753: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1753: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1754: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1754: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1755: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1755: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1756: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1756: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1757: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1757: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1758: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1758: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1759: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1759: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1760: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1760: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1761: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1761: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1762: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1762: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1763: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1763: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1764: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1764: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1765: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1765: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1766: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1766: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1767: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1767: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1768: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1768: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1769: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1769: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1770: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1770: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1771: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1771: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1772: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1772: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1773: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1773: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1774: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1774: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1775: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1775: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1776: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1776: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1777: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1777: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1778: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1778: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1779: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1779: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1780: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1780: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1781: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1781: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1782: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1782: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1783: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1783: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1784: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1784: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1785: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1785: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1786: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1786: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1787: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1787: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1788: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1788: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1789: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1789: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1790: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1790: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1791: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1791: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1792: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1792: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1793: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1793: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1794: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1794: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1795: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1795: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1796: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1796: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1797: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1797: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1798: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1798: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1799: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1799: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1800: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1800: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1801: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1801: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1802: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1802: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1803: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1803: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1804: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1804: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1805: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1805: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1806: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1806: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1807: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1807: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1808: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1808: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1809: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1809: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1810: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1810: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1811: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1811: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1812: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1812: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1813: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1813: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1814: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1814: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1815: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1815: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1816: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1816: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1817: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1817: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1818: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1818: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1819: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1819: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1820: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1820: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1821: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1821: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1822: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1822: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1823: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1823: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1824: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1824: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1825: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1825: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1826: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1826: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1827: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1827: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1828: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1828: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1829: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1829: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1830: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1830: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1831: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1831: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1832: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1832: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1833: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1833: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1834: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1834: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1835: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1835: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1836: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1836: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1837: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1837: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1838: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1838: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1839: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1839: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1840: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1840: loss did not improve from 0.16218\n",
            "\n",
            "Epoch 1841: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1841: loss improved from 0.16218 to 0.16014, saving model to ./model_PID_3D_1841_loss_0.160_vloss_0.287_acc_0.924_vacc_0.923.hdf5\n",
            "\n",
            "Epoch 1842: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1842: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1843: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1843: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1844: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1844: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1845: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1845: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1846: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1846: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1847: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1847: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1848: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1848: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1849: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1849: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1850: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1850: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1851: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1851: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1852: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1852: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1853: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1853: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1854: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1854: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1855: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1855: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1856: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1856: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1857: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1857: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1858: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1858: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1859: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1859: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1860: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1860: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1861: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1861: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1862: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1862: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1863: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1863: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1864: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1864: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1865: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1865: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1866: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1866: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1867: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1867: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1868: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1868: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1869: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1869: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1870: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1870: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1871: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1871: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1872: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1872: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1873: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1873: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1874: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1874: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1875: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1875: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1876: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1876: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1877: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1877: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1878: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1878: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1879: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1879: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1880: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1880: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1881: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1881: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1882: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1882: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1883: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1883: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1884: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1884: loss did not improve from 0.16014\n",
            "\n",
            "Epoch 1885: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1885: loss improved from 0.16014 to 0.15802, saving model to ./model_PID_3D_1885_loss_0.158_vloss_0.284_acc_0.923_vacc_0.929.hdf5\n",
            "\n",
            "Epoch 1886: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1886: loss did not improve from 0.15802\n",
            "\n",
            "Epoch 1887: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1887: loss did not improve from 0.15802\n",
            "\n",
            "Epoch 1888: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1888: loss did not improve from 0.15802\n",
            "\n",
            "Epoch 1889: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1889: loss did not improve from 0.15802\n",
            "\n",
            "Epoch 1890: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1890: loss did not improve from 0.15802\n",
            "\n",
            "Epoch 1891: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1891: loss did not improve from 0.15802\n",
            "\n",
            "Epoch 1892: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1892: loss did not improve from 0.15802\n",
            "\n",
            "Epoch 1893: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1893: loss did not improve from 0.15802\n",
            "\n",
            "Epoch 1894: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1894: loss did not improve from 0.15802\n",
            "\n",
            "Epoch 1895: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1895: loss did not improve from 0.15802\n",
            "\n",
            "Epoch 1896: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1896: loss did not improve from 0.15802\n",
            "\n",
            "Epoch 1897: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1897: loss did not improve from 0.15802\n",
            "\n",
            "Epoch 1898: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1898: loss did not improve from 0.15802\n",
            "\n",
            "Epoch 1899: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1899: loss did not improve from 0.15802\n",
            "\n",
            "Epoch 1900: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1900: loss did not improve from 0.15802\n",
            "\n",
            "Epoch 1901: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1901: loss improved from 0.15802 to 0.15639, saving model to ./model_PID_3D_1901_loss_0.156_vloss_0.284_acc_0.927_vacc_0.926.hdf5\n",
            "\n",
            "Epoch 1902: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1902: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1903: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1903: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1904: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1904: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1905: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1905: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1906: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1906: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1907: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1907: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1908: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1908: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1909: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1909: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1910: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1910: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1911: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1911: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1912: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1912: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1913: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1913: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1914: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1914: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1915: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1915: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1916: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1916: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1917: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1917: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1918: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1918: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1919: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1919: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1920: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1920: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1921: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1921: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1922: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1922: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1923: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1923: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1924: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1924: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1925: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1925: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1926: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1926: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1927: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1927: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1928: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1928: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1929: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1929: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1930: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1930: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1931: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1931: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1932: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1932: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1933: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1933: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1934: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1934: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1935: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1935: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1936: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1936: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1937: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1937: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1938: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1938: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1939: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1939: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1940: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1940: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1941: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1941: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1942: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1942: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1943: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1943: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1944: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1944: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1945: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1945: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1946: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1946: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1947: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1947: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1948: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1948: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1949: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1949: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1950: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1950: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1951: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1951: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1952: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1952: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1953: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1953: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1954: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1954: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1955: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1955: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1956: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1956: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1957: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1957: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1958: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1958: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1959: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1959: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1960: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1960: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1961: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1961: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1962: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1962: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1963: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1963: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1964: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1964: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1965: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1965: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1966: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1966: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1967: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1967: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1968: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1968: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1969: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1969: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1970: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1970: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1971: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1971: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1972: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1972: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1973: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1973: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1974: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1974: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1975: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1975: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1976: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1976: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1977: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1977: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1978: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1978: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1979: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1979: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1980: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1980: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1981: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1981: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1982: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1982: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1983: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1983: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1984: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1984: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1985: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1985: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1986: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1986: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1987: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1987: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1988: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1988: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1989: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1989: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1990: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1990: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1991: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1991: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1992: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1992: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1993: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1993: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1994: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1994: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1995: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1995: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1996: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1996: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1997: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1997: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1998: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1998: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 1999: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 1999: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2000: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 2000: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2001: LearningRateScheduler setting learning rate to 0.002.\n",
            "\n",
            "Epoch 2001: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2002: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2002: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2003: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2003: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2004: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2004: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2005: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2005: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2006: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2006: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2007: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2007: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2008: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2008: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2009: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2009: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2010: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2010: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2011: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2011: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2012: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2012: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2013: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2013: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2014: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2014: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2015: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2015: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2016: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2016: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2017: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2017: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2018: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2018: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2019: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2019: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2020: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2020: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2021: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2021: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2022: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2022: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2023: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2023: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2024: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2024: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2025: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2025: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2026: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2026: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2027: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2027: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2028: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2028: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2029: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2029: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2030: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2030: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2031: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2031: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2032: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2032: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2033: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2033: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2034: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2034: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2035: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2035: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2036: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2036: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2037: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2037: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2038: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2038: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2039: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2039: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2040: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2040: loss did not improve from 0.15639\n",
            "\n",
            "Epoch 2041: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2041: loss improved from 0.15639 to 0.15538, saving model to ./model_PID_3D_2041_loss_0.155_vloss_0.286_acc_0.928_vacc_0.925.hdf5\n",
            "\n",
            "Epoch 2042: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2042: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2043: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2043: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2044: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2044: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2045: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2045: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2046: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2046: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2047: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2047: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2048: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2048: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2049: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2049: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2050: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2050: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2051: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2051: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2052: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2052: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2053: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2053: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2054: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2054: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2055: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2055: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2056: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2056: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2057: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2057: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2058: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2058: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2059: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2059: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2060: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2060: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2061: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2061: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2062: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2062: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2063: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2063: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2064: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2064: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2065: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2065: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2066: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2066: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2067: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2067: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2068: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2068: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2069: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2069: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2070: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2070: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2071: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2071: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2072: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2072: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2073: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2073: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2074: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2074: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2075: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2075: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2076: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2076: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2077: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2077: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2078: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2078: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2079: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2079: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2080: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2080: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2081: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2081: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2082: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2082: loss did not improve from 0.15538\n",
            "\n",
            "Epoch 2083: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2083: loss improved from 0.15538 to 0.15511, saving model to ./model_PID_3D_2083_loss_0.155_vloss_0.286_acc_0.922_vacc_0.922.hdf5\n",
            "\n",
            "Epoch 2084: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2084: loss did not improve from 0.15511\n",
            "\n",
            "Epoch 2085: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2085: loss improved from 0.15511 to 0.15390, saving model to ./model_PID_3D_2085_loss_0.154_vloss_0.287_acc_0.927_vacc_0.932.hdf5\n",
            "\n",
            "Epoch 2086: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2086: loss improved from 0.15390 to 0.15337, saving model to ./model_PID_3D_2086_loss_0.153_vloss_0.290_acc_0.928_vacc_0.932.hdf5\n",
            "\n",
            "Epoch 2087: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2087: loss did not improve from 0.15337\n",
            "\n",
            "Epoch 2088: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2088: loss did not improve from 0.15337\n",
            "\n",
            "Epoch 2089: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2089: loss did not improve from 0.15337\n",
            "\n",
            "Epoch 2090: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2090: loss did not improve from 0.15337\n",
            "\n",
            "Epoch 2091: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2091: loss did not improve from 0.15337\n",
            "\n",
            "Epoch 2092: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2092: loss did not improve from 0.15337\n",
            "\n",
            "Epoch 2093: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2093: loss did not improve from 0.15337\n",
            "\n",
            "Epoch 2094: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2094: loss did not improve from 0.15337\n",
            "\n",
            "Epoch 2095: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2095: loss did not improve from 0.15337\n",
            "\n",
            "Epoch 2096: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2096: loss did not improve from 0.15337\n",
            "\n",
            "Epoch 2097: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2097: loss did not improve from 0.15337\n",
            "\n",
            "Epoch 2098: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2098: loss did not improve from 0.15337\n",
            "\n",
            "Epoch 2099: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2099: loss did not improve from 0.15337\n",
            "\n",
            "Epoch 2100: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2100: loss did not improve from 0.15337\n",
            "\n",
            "Epoch 2101: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2101: loss did not improve from 0.15337\n",
            "\n",
            "Epoch 2102: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2102: loss did not improve from 0.15337\n",
            "\n",
            "Epoch 2103: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2103: loss did not improve from 0.15337\n",
            "\n",
            "Epoch 2104: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2104: loss did not improve from 0.15337\n",
            "\n",
            "Epoch 2105: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2105: loss did not improve from 0.15337\n",
            "\n",
            "Epoch 2106: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2106: loss did not improve from 0.15337\n",
            "\n",
            "Epoch 2107: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2107: loss did not improve from 0.15337\n",
            "\n",
            "Epoch 2108: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2108: loss did not improve from 0.15337\n",
            "\n",
            "Epoch 2109: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2109: loss did not improve from 0.15337\n",
            "\n",
            "Epoch 2110: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2110: loss did not improve from 0.15337\n",
            "\n",
            "Epoch 2111: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2111: loss did not improve from 0.15337\n",
            "\n",
            "Epoch 2112: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2112: loss did not improve from 0.15337\n",
            "\n",
            "Epoch 2113: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2113: loss did not improve from 0.15337\n",
            "\n",
            "Epoch 2114: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2114: loss did not improve from 0.15337\n",
            "\n",
            "Epoch 2115: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2115: loss did not improve from 0.15337\n",
            "\n",
            "Epoch 2116: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2116: loss did not improve from 0.15337\n",
            "\n",
            "Epoch 2117: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2117: loss did not improve from 0.15337\n",
            "\n",
            "Epoch 2118: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2118: loss did not improve from 0.15337\n",
            "\n",
            "Epoch 2119: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2119: loss did not improve from 0.15337\n",
            "\n",
            "Epoch 2120: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2120: loss improved from 0.15337 to 0.14925, saving model to ./model_PID_3D_2120_loss_0.149_vloss_0.287_acc_0.932_vacc_0.932.hdf5\n",
            "\n",
            "Epoch 2121: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2121: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2122: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2122: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2123: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2123: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2124: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2124: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2125: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2125: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2126: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2126: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2127: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2127: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2128: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2128: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2129: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2129: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2130: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2130: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2131: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2131: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2132: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2132: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2133: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2133: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2134: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2134: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2135: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2135: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2136: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2136: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2137: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2137: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2138: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2138: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2139: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2139: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2140: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2140: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2141: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2141: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2142: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2142: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2143: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2143: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2144: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2144: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2145: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2145: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2146: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2146: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2147: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2147: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2148: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2148: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2149: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2149: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2150: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2150: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2151: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2151: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2152: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2152: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2153: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2153: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2154: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2154: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2155: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2155: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2156: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2156: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2157: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2157: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2158: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2158: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2159: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2159: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2160: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2160: loss did not improve from 0.14925\n",
            "\n",
            "Epoch 2161: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2161: loss improved from 0.14925 to 0.14922, saving model to ./model_PID_3D_2161_loss_0.149_vloss_0.287_acc_0.932_vacc_0.932.hdf5\n",
            "\n",
            "Epoch 2162: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2162: loss did not improve from 0.14922\n",
            "\n",
            "Epoch 2163: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2163: loss did not improve from 0.14922\n",
            "\n",
            "Epoch 2164: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2164: loss did not improve from 0.14922\n",
            "\n",
            "Epoch 2165: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2165: loss did not improve from 0.14922\n",
            "\n",
            "Epoch 2166: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2166: loss did not improve from 0.14922\n",
            "\n",
            "Epoch 2167: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2167: loss did not improve from 0.14922\n",
            "\n",
            "Epoch 2168: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2168: loss did not improve from 0.14922\n",
            "\n",
            "Epoch 2169: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2169: loss did not improve from 0.14922\n",
            "\n",
            "Epoch 2170: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2170: loss did not improve from 0.14922\n",
            "\n",
            "Epoch 2171: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2171: loss did not improve from 0.14922\n",
            "\n",
            "Epoch 2172: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2172: loss did not improve from 0.14922\n",
            "\n",
            "Epoch 2173: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2173: loss did not improve from 0.14922\n",
            "\n",
            "Epoch 2174: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2174: loss did not improve from 0.14922\n",
            "\n",
            "Epoch 2175: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2175: loss did not improve from 0.14922\n",
            "\n",
            "Epoch 2176: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2176: loss did not improve from 0.14922\n",
            "\n",
            "Epoch 2177: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2177: loss did not improve from 0.14922\n",
            "\n",
            "Epoch 2178: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2178: loss did not improve from 0.14922\n",
            "\n",
            "Epoch 2179: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2179: loss improved from 0.14922 to 0.14849, saving model to ./model_PID_3D_2179_loss_0.148_vloss_0.292_acc_0.934_vacc_0.931.hdf5\n",
            "\n",
            "Epoch 2180: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2180: loss did not improve from 0.14849\n",
            "\n",
            "Epoch 2181: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2181: loss did not improve from 0.14849\n",
            "\n",
            "Epoch 2182: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2182: loss did not improve from 0.14849\n",
            "\n",
            "Epoch 2183: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2183: loss did not improve from 0.14849\n",
            "\n",
            "Epoch 2184: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2184: loss did not improve from 0.14849\n",
            "\n",
            "Epoch 2185: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2185: loss did not improve from 0.14849\n",
            "\n",
            "Epoch 2186: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2186: loss did not improve from 0.14849\n",
            "\n",
            "Epoch 2187: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2187: loss did not improve from 0.14849\n",
            "\n",
            "Epoch 2188: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2188: loss did not improve from 0.14849\n",
            "\n",
            "Epoch 2189: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2189: loss did not improve from 0.14849\n",
            "\n",
            "Epoch 2190: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2190: loss did not improve from 0.14849\n",
            "\n",
            "Epoch 2191: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2191: loss did not improve from 0.14849\n",
            "\n",
            "Epoch 2192: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2192: loss did not improve from 0.14849\n",
            "\n",
            "Epoch 2193: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2193: loss did not improve from 0.14849\n",
            "\n",
            "Epoch 2194: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2194: loss did not improve from 0.14849\n",
            "\n",
            "Epoch 2195: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2195: loss did not improve from 0.14849\n",
            "\n",
            "Epoch 2196: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2196: loss did not improve from 0.14849\n",
            "\n",
            "Epoch 2197: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2197: loss improved from 0.14849 to 0.14755, saving model to ./model_PID_3D_2197_loss_0.148_vloss_0.290_acc_0.930_vacc_0.929.hdf5\n",
            "\n",
            "Epoch 2198: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2198: loss improved from 0.14755 to 0.14649, saving model to ./model_PID_3D_2198_loss_0.146_vloss_0.292_acc_0.931_vacc_0.929.hdf5\n",
            "\n",
            "Epoch 2199: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2199: loss did not improve from 0.14649\n",
            "\n",
            "Epoch 2200: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2200: loss did not improve from 0.14649\n",
            "\n",
            "Epoch 2201: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2201: loss did not improve from 0.14649\n",
            "\n",
            "Epoch 2202: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2202: loss did not improve from 0.14649\n",
            "\n",
            "Epoch 2203: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2203: loss did not improve from 0.14649\n",
            "\n",
            "Epoch 2204: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2204: loss did not improve from 0.14649\n",
            "\n",
            "Epoch 2205: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2205: loss did not improve from 0.14649\n",
            "\n",
            "Epoch 2206: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2206: loss did not improve from 0.14649\n",
            "\n",
            "Epoch 2207: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2207: loss did not improve from 0.14649\n",
            "\n",
            "Epoch 2208: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2208: loss did not improve from 0.14649\n",
            "\n",
            "Epoch 2209: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2209: loss did not improve from 0.14649\n",
            "\n",
            "Epoch 2210: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2210: loss did not improve from 0.14649\n",
            "\n",
            "Epoch 2211: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2211: loss did not improve from 0.14649\n",
            "\n",
            "Epoch 2212: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2212: loss did not improve from 0.14649\n",
            "\n",
            "Epoch 2213: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2213: loss improved from 0.14649 to 0.14635, saving model to ./model_PID_3D_2213_loss_0.146_vloss_0.293_acc_0.929_vacc_0.931.hdf5\n",
            "\n",
            "Epoch 2214: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2214: loss did not improve from 0.14635\n",
            "\n",
            "Epoch 2215: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2215: loss did not improve from 0.14635\n",
            "\n",
            "Epoch 2216: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2216: loss did not improve from 0.14635\n",
            "\n",
            "Epoch 2217: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2217: loss did not improve from 0.14635\n",
            "\n",
            "Epoch 2218: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2218: loss did not improve from 0.14635\n",
            "\n",
            "Epoch 2219: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2219: loss did not improve from 0.14635\n",
            "\n",
            "Epoch 2220: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2220: loss did not improve from 0.14635\n",
            "\n",
            "Epoch 2221: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2221: loss did not improve from 0.14635\n",
            "\n",
            "Epoch 2222: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2222: loss did not improve from 0.14635\n",
            "\n",
            "Epoch 2223: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2223: loss did not improve from 0.14635\n",
            "\n",
            "Epoch 2224: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2224: loss did not improve from 0.14635\n",
            "\n",
            "Epoch 2225: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2225: loss did not improve from 0.14635\n",
            "\n",
            "Epoch 2226: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2226: loss did not improve from 0.14635\n",
            "\n",
            "Epoch 2227: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2227: loss did not improve from 0.14635\n",
            "\n",
            "Epoch 2228: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2228: loss did not improve from 0.14635\n",
            "\n",
            "Epoch 2229: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2229: loss did not improve from 0.14635\n",
            "\n",
            "Epoch 2230: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2230: loss did not improve from 0.14635\n",
            "\n",
            "Epoch 2231: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2231: loss did not improve from 0.14635\n",
            "\n",
            "Epoch 2232: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2232: loss did not improve from 0.14635\n",
            "\n",
            "Epoch 2233: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2233: loss did not improve from 0.14635\n",
            "\n",
            "Epoch 2234: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2234: loss did not improve from 0.14635\n",
            "\n",
            "Epoch 2235: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2235: loss did not improve from 0.14635\n",
            "\n",
            "Epoch 2236: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2236: loss did not improve from 0.14635\n",
            "\n",
            "Epoch 2237: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2237: loss did not improve from 0.14635\n",
            "\n",
            "Epoch 2238: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2238: loss improved from 0.14635 to 0.14090, saving model to ./model_PID_3D_2238_loss_0.141_vloss_0.294_acc_0.933_vacc_0.932.hdf5\n",
            "\n",
            "Epoch 2239: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2239: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2240: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2240: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2241: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2241: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2242: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2242: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2243: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2243: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2244: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2244: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2245: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2245: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2246: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2246: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2247: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2247: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2248: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2248: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2249: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2249: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2250: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2250: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2251: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2251: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2252: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2252: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2253: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2253: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2254: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2254: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2255: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2255: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2256: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2256: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2257: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2257: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2258: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2258: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2259: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2259: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2260: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2260: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2261: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2261: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2262: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2262: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2263: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2263: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2264: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2264: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2265: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2265: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2266: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2266: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2267: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2267: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2268: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2268: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2269: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2269: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2270: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2270: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2271: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2271: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2272: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2272: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2273: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2273: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2274: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2274: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2275: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2275: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2276: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2276: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2277: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2277: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2278: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2278: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2279: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2279: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2280: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2280: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2281: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2281: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2282: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2282: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2283: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2283: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2284: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2284: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2285: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2285: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2286: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2286: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2287: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2287: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2288: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2288: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2289: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2289: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2290: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2290: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2291: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2291: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2292: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2292: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2293: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2293: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2294: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2294: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2295: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2295: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2296: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2296: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2297: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2297: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2298: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2298: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2299: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2299: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2300: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2300: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2301: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2301: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2302: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2302: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2303: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2303: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2304: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2304: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2305: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2305: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2306: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2306: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2307: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2307: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2308: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2308: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2309: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2309: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2310: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2310: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2311: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2311: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2312: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2312: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2313: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2313: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2314: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2314: loss did not improve from 0.14090\n",
            "\n",
            "Epoch 2315: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2315: loss improved from 0.14090 to 0.14007, saving model to ./model_PID_3D_2315_loss_0.140_vloss_0.292_acc_0.936_vacc_0.931.hdf5\n",
            "\n",
            "Epoch 2316: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2316: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2317: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2317: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2318: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2318: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2319: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2319: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2320: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2320: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2321: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2321: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2322: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2322: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2323: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2323: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2324: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2324: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2325: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2325: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2326: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2326: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2327: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2327: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2328: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2328: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2329: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2329: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2330: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2330: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2331: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2331: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2332: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2332: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2333: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2333: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2334: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2334: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2335: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2335: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2336: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2336: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2337: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2337: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2338: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2338: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2339: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2339: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2340: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2340: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2341: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2341: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2342: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2342: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2343: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2343: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2344: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2344: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2345: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2345: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2346: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2346: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2347: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2347: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2348: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2348: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2349: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2349: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2350: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2350: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2351: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2351: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2352: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2352: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2353: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2353: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2354: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2354: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2355: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2355: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2356: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2356: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2357: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2357: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2358: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2358: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2359: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2359: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2360: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2360: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2361: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2361: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2362: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2362: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2363: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2363: loss did not improve from 0.14007\n",
            "\n",
            "Epoch 2364: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2364: loss improved from 0.14007 to 0.13582, saving model to ./model_PID_3D_2364_loss_0.136_vloss_0.297_acc_0.941_vacc_0.933.hdf5\n",
            "\n",
            "Epoch 2365: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2365: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2366: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2366: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2367: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2367: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2368: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2368: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2369: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2369: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2370: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2370: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2371: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2371: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2372: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2372: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2373: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2373: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2374: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2374: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2375: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2375: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2376: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2376: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2377: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2377: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2378: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2378: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2379: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2379: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2380: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2380: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2381: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2381: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2382: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2382: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2383: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2383: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2384: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2384: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2385: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2385: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2386: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2386: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2387: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2387: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2388: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2388: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2389: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2389: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2390: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2390: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2391: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2391: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2392: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2392: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2393: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2393: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2394: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2394: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2395: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2395: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2396: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2396: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2397: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2397: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2398: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2398: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2399: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2399: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2400: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2400: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2401: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2401: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2402: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2402: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2403: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2403: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2404: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2404: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2405: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2405: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2406: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2406: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2407: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2407: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2408: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2408: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2409: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2409: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2410: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2410: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2411: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2411: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2412: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2412: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2413: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2413: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2414: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2414: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2415: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2415: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2416: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2416: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2417: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2417: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2418: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2418: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2419: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2419: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2420: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2420: loss did not improve from 0.13582\n",
            "\n",
            "Epoch 2421: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2421: loss improved from 0.13582 to 0.13473, saving model to ./model_PID_3D_2421_loss_0.135_vloss_0.299_acc_0.940_vacc_0.936.hdf5\n",
            "\n",
            "Epoch 2422: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2422: loss did not improve from 0.13473\n",
            "\n",
            "Epoch 2423: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2423: loss did not improve from 0.13473\n",
            "\n",
            "Epoch 2424: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2424: loss did not improve from 0.13473\n",
            "\n",
            "Epoch 2425: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2425: loss did not improve from 0.13473\n",
            "\n",
            "Epoch 2426: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2426: loss did not improve from 0.13473\n",
            "\n",
            "Epoch 2427: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2427: loss did not improve from 0.13473\n",
            "\n",
            "Epoch 2428: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2428: loss did not improve from 0.13473\n",
            "\n",
            "Epoch 2429: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2429: loss did not improve from 0.13473\n",
            "\n",
            "Epoch 2430: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2430: loss did not improve from 0.13473\n",
            "\n",
            "Epoch 2431: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2431: loss did not improve from 0.13473\n",
            "\n",
            "Epoch 2432: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2432: loss did not improve from 0.13473\n",
            "\n",
            "Epoch 2433: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2433: loss did not improve from 0.13473\n",
            "\n",
            "Epoch 2434: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2434: loss did not improve from 0.13473\n",
            "\n",
            "Epoch 2435: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2435: loss did not improve from 0.13473\n",
            "\n",
            "Epoch 2436: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2436: loss did not improve from 0.13473\n",
            "\n",
            "Epoch 2437: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2437: loss did not improve from 0.13473\n",
            "\n",
            "Epoch 2438: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2438: loss did not improve from 0.13473\n",
            "\n",
            "Epoch 2439: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2439: loss did not improve from 0.13473\n",
            "\n",
            "Epoch 2440: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2440: loss did not improve from 0.13473\n",
            "\n",
            "Epoch 2441: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2441: loss did not improve from 0.13473\n",
            "\n",
            "Epoch 2442: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2442: loss did not improve from 0.13473\n",
            "\n",
            "Epoch 2443: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2443: loss did not improve from 0.13473\n",
            "\n",
            "Epoch 2444: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2444: loss did not improve from 0.13473\n",
            "\n",
            "Epoch 2445: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2445: loss did not improve from 0.13473\n",
            "\n",
            "Epoch 2446: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2446: loss did not improve from 0.13473\n",
            "\n",
            "Epoch 2447: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2447: loss did not improve from 0.13473\n",
            "\n",
            "Epoch 2448: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2448: loss did not improve from 0.13473\n",
            "\n",
            "Epoch 2449: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2449: loss did not improve from 0.13473\n",
            "\n",
            "Epoch 2450: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2450: loss did not improve from 0.13473\n",
            "\n",
            "Epoch 2451: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2451: loss did not improve from 0.13473\n",
            "\n",
            "Epoch 2452: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2452: loss did not improve from 0.13473\n",
            "\n",
            "Epoch 2453: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2453: loss did not improve from 0.13473\n",
            "\n",
            "Epoch 2454: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2454: loss did not improve from 0.13473\n",
            "\n",
            "Epoch 2455: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2455: loss did not improve from 0.13473\n",
            "\n",
            "Epoch 2456: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2456: loss improved from 0.13473 to 0.13279, saving model to ./model_PID_3D_2456_loss_0.133_vloss_0.307_acc_0.942_vacc_0.928.hdf5\n",
            "\n",
            "Epoch 2457: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2457: loss did not improve from 0.13279\n",
            "\n",
            "Epoch 2458: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2458: loss did not improve from 0.13279\n",
            "\n",
            "Epoch 2459: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2459: loss did not improve from 0.13279\n",
            "\n",
            "Epoch 2460: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2460: loss did not improve from 0.13279\n",
            "\n",
            "Epoch 2461: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2461: loss did not improve from 0.13279\n",
            "\n",
            "Epoch 2462: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2462: loss did not improve from 0.13279\n",
            "\n",
            "Epoch 2463: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2463: loss did not improve from 0.13279\n",
            "\n",
            "Epoch 2464: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2464: loss did not improve from 0.13279\n",
            "\n",
            "Epoch 2465: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2465: loss did not improve from 0.13279\n",
            "\n",
            "Epoch 2466: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2466: loss did not improve from 0.13279\n",
            "\n",
            "Epoch 2467: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2467: loss did not improve from 0.13279\n",
            "\n",
            "Epoch 2468: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2468: loss did not improve from 0.13279\n",
            "\n",
            "Epoch 2469: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2469: loss did not improve from 0.13279\n",
            "\n",
            "Epoch 2470: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2470: loss did not improve from 0.13279\n",
            "\n",
            "Epoch 2471: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2471: loss did not improve from 0.13279\n",
            "\n",
            "Epoch 2472: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2472: loss did not improve from 0.13279\n",
            "\n",
            "Epoch 2473: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2473: loss did not improve from 0.13279\n",
            "\n",
            "Epoch 2474: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2474: loss did not improve from 0.13279\n",
            "\n",
            "Epoch 2475: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2475: loss did not improve from 0.13279\n",
            "\n",
            "Epoch 2476: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2476: loss did not improve from 0.13279\n",
            "\n",
            "Epoch 2477: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2477: loss did not improve from 0.13279\n",
            "\n",
            "Epoch 2478: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2478: loss did not improve from 0.13279\n",
            "\n",
            "Epoch 2479: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2479: loss did not improve from 0.13279\n",
            "\n",
            "Epoch 2480: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2480: loss did not improve from 0.13279\n",
            "\n",
            "Epoch 2481: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2481: loss did not improve from 0.13279\n",
            "\n",
            "Epoch 2482: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2482: loss did not improve from 0.13279\n",
            "\n",
            "Epoch 2483: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2483: loss did not improve from 0.13279\n",
            "\n",
            "Epoch 2484: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2484: loss did not improve from 0.13279\n",
            "\n",
            "Epoch 2485: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2485: loss improved from 0.13279 to 0.13195, saving model to ./model_PID_3D_2485_loss_0.132_vloss_0.309_acc_0.936_vacc_0.935.hdf5\n",
            "\n",
            "Epoch 2486: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2486: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2487: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2487: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2488: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2488: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2489: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2489: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2490: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2490: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2491: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2491: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2492: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2492: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2493: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2493: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2494: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2494: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2495: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2495: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2496: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2496: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2497: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2497: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2498: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2498: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2499: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2499: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2500: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2500: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2501: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2501: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2502: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2502: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2503: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2503: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2504: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2504: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2505: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2505: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2506: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2506: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2507: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2507: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2508: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2508: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2509: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2509: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2510: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2510: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2511: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2511: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2512: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2512: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2513: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2513: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2514: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2514: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2515: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2515: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2516: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2516: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2517: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2517: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2518: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2518: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2519: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2519: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2520: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2520: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2521: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2521: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2522: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2522: loss did not improve from 0.13195\n",
            "\n",
            "Epoch 2523: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2523: loss improved from 0.13195 to 0.13031, saving model to ./model_PID_3D_2523_loss_0.130_vloss_0.315_acc_0.943_vacc_0.937.hdf5\n",
            "\n",
            "Epoch 2524: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2524: loss did not improve from 0.13031\n",
            "\n",
            "Epoch 2525: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2525: loss did not improve from 0.13031\n",
            "\n",
            "Epoch 2526: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2526: loss did not improve from 0.13031\n",
            "\n",
            "Epoch 2527: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2527: loss did not improve from 0.13031\n",
            "\n",
            "Epoch 2528: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2528: loss did not improve from 0.13031\n",
            "\n",
            "Epoch 2529: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2529: loss did not improve from 0.13031\n",
            "\n",
            "Epoch 2530: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2530: loss did not improve from 0.13031\n",
            "\n",
            "Epoch 2531: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2531: loss did not improve from 0.13031\n",
            "\n",
            "Epoch 2532: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2532: loss did not improve from 0.13031\n",
            "\n",
            "Epoch 2533: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2533: loss did not improve from 0.13031\n",
            "\n",
            "Epoch 2534: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2534: loss did not improve from 0.13031\n",
            "\n",
            "Epoch 2535: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2535: loss did not improve from 0.13031\n",
            "\n",
            "Epoch 2536: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2536: loss improved from 0.13031 to 0.12896, saving model to ./model_PID_3D_2536_loss_0.129_vloss_0.311_acc_0.938_vacc_0.938.hdf5\n",
            "\n",
            "Epoch 2537: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2537: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2538: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2538: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2539: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2539: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2540: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2540: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2541: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2541: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2542: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2542: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2543: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2543: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2544: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2544: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2545: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2545: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2546: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2546: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2547: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2547: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2548: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2548: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2549: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2549: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2550: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2550: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2551: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2551: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2552: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2552: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2553: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2553: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2554: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2554: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2555: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2555: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2556: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2556: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2557: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2557: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2558: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2558: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2559: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2559: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2560: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2560: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2561: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2561: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2562: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2562: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2563: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2563: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2564: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2564: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2565: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2565: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2566: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2566: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2567: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2567: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2568: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2568: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2569: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2569: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2570: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2570: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2571: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2571: loss did not improve from 0.12896\n",
            "\n",
            "Epoch 2572: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2572: loss improved from 0.12896 to 0.12849, saving model to ./model_PID_3D_2572_loss_0.128_vloss_0.313_acc_0.941_vacc_0.933.hdf5\n",
            "\n",
            "Epoch 2573: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2573: loss did not improve from 0.12849\n",
            "\n",
            "Epoch 2574: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2574: loss did not improve from 0.12849\n",
            "\n",
            "Epoch 2575: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2575: loss did not improve from 0.12849\n",
            "\n",
            "Epoch 2576: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2576: loss did not improve from 0.12849\n",
            "\n",
            "Epoch 2577: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2577: loss did not improve from 0.12849\n",
            "\n",
            "Epoch 2578: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2578: loss did not improve from 0.12849\n",
            "\n",
            "Epoch 2579: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2579: loss improved from 0.12849 to 0.12747, saving model to ./model_PID_3D_2579_loss_0.127_vloss_0.317_acc_0.945_vacc_0.936.hdf5\n",
            "\n",
            "Epoch 2580: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2580: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2581: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2581: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2582: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2582: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2583: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2583: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2584: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2584: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2585: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2585: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2586: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2586: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2587: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2587: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2588: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2588: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2589: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2589: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2590: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2590: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2591: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2591: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2592: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2592: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2593: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2593: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2594: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2594: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2595: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2595: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2596: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2596: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2597: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2597: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2598: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2598: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2599: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2599: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2600: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2600: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2601: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2601: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2602: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2602: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2603: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2603: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2604: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2604: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2605: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2605: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2606: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2606: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2607: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2607: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2608: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2608: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2609: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2609: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2610: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2610: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2611: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2611: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2612: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2612: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2613: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2613: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2614: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2614: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2615: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2615: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2616: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2616: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2617: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2617: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2618: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2618: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2619: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2619: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2620: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2620: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2621: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2621: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2622: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2622: loss did not improve from 0.12747\n",
            "\n",
            "Epoch 2623: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2623: loss improved from 0.12747 to 0.12660, saving model to ./model_PID_3D_2623_loss_0.127_vloss_0.312_acc_0.944_vacc_0.936.hdf5\n",
            "\n",
            "Epoch 2624: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2624: loss did not improve from 0.12660\n",
            "\n",
            "Epoch 2625: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2625: loss did not improve from 0.12660\n",
            "\n",
            "Epoch 2626: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2626: loss did not improve from 0.12660\n",
            "\n",
            "Epoch 2627: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2627: loss did not improve from 0.12660\n",
            "\n",
            "Epoch 2628: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2628: loss did not improve from 0.12660\n",
            "\n",
            "Epoch 2629: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2629: loss did not improve from 0.12660\n",
            "\n",
            "Epoch 2630: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2630: loss did not improve from 0.12660\n",
            "\n",
            "Epoch 2631: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2631: loss did not improve from 0.12660\n",
            "\n",
            "Epoch 2632: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2632: loss did not improve from 0.12660\n",
            "\n",
            "Epoch 2633: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2633: loss did not improve from 0.12660\n",
            "\n",
            "Epoch 2634: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2634: loss did not improve from 0.12660\n",
            "\n",
            "Epoch 2635: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2635: loss did not improve from 0.12660\n",
            "\n",
            "Epoch 2636: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2636: loss did not improve from 0.12660\n",
            "\n",
            "Epoch 2637: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2637: loss did not improve from 0.12660\n",
            "\n",
            "Epoch 2638: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2638: loss did not improve from 0.12660\n",
            "\n",
            "Epoch 2639: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2639: loss did not improve from 0.12660\n",
            "\n",
            "Epoch 2640: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2640: loss did not improve from 0.12660\n",
            "\n",
            "Epoch 2641: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2641: loss did not improve from 0.12660\n",
            "\n",
            "Epoch 2642: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2642: loss did not improve from 0.12660\n",
            "\n",
            "Epoch 2643: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2643: loss did not improve from 0.12660\n",
            "\n",
            "Epoch 2644: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2644: loss did not improve from 0.12660\n",
            "\n",
            "Epoch 2645: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2645: loss did not improve from 0.12660\n",
            "\n",
            "Epoch 2646: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2646: loss did not improve from 0.12660\n",
            "\n",
            "Epoch 2647: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2647: loss did not improve from 0.12660\n",
            "\n",
            "Epoch 2648: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2648: loss did not improve from 0.12660\n",
            "\n",
            "Epoch 2649: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2649: loss did not improve from 0.12660\n",
            "\n",
            "Epoch 2650: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2650: loss did not improve from 0.12660\n",
            "\n",
            "Epoch 2651: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2651: loss did not improve from 0.12660\n",
            "\n",
            "Epoch 2652: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2652: loss did not improve from 0.12660\n",
            "\n",
            "Epoch 2653: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2653: loss improved from 0.12660 to 0.12633, saving model to ./model_PID_3D_2653_loss_0.126_vloss_0.319_acc_0.944_vacc_0.935.hdf5\n",
            "\n",
            "Epoch 2654: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2654: loss did not improve from 0.12633\n",
            "\n",
            "Epoch 2655: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2655: loss did not improve from 0.12633\n",
            "\n",
            "Epoch 2656: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2656: loss did not improve from 0.12633\n",
            "\n",
            "Epoch 2657: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2657: loss did not improve from 0.12633\n",
            "\n",
            "Epoch 2658: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2658: loss did not improve from 0.12633\n",
            "\n",
            "Epoch 2659: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2659: loss improved from 0.12633 to 0.12622, saving model to ./model_PID_3D_2659_loss_0.126_vloss_0.322_acc_0.944_vacc_0.941.hdf5\n",
            "\n",
            "Epoch 2660: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2660: loss did not improve from 0.12622\n",
            "\n",
            "Epoch 2661: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2661: loss did not improve from 0.12622\n",
            "\n",
            "Epoch 2662: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2662: loss did not improve from 0.12622\n",
            "\n",
            "Epoch 2663: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2663: loss did not improve from 0.12622\n",
            "\n",
            "Epoch 2664: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2664: loss improved from 0.12622 to 0.12549, saving model to ./model_PID_3D_2664_loss_0.125_vloss_0.327_acc_0.946_vacc_0.938.hdf5\n",
            "\n",
            "Epoch 2665: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2665: loss did not improve from 0.12549\n",
            "\n",
            "Epoch 2666: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2666: loss did not improve from 0.12549\n",
            "\n",
            "Epoch 2667: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2667: loss did not improve from 0.12549\n",
            "\n",
            "Epoch 2668: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2668: loss did not improve from 0.12549\n",
            "\n",
            "Epoch 2669: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2669: loss did not improve from 0.12549\n",
            "\n",
            "Epoch 2670: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2670: loss did not improve from 0.12549\n",
            "\n",
            "Epoch 2671: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2671: loss did not improve from 0.12549\n",
            "\n",
            "Epoch 2672: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2672: loss did not improve from 0.12549\n",
            "\n",
            "Epoch 2673: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2673: loss did not improve from 0.12549\n",
            "\n",
            "Epoch 2674: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2674: loss did not improve from 0.12549\n",
            "\n",
            "Epoch 2675: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2675: loss did not improve from 0.12549\n",
            "\n",
            "Epoch 2676: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2676: loss did not improve from 0.12549\n",
            "\n",
            "Epoch 2677: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2677: loss did not improve from 0.12549\n",
            "\n",
            "Epoch 2678: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2678: loss did not improve from 0.12549\n",
            "\n",
            "Epoch 2679: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2679: loss improved from 0.12549 to 0.12341, saving model to ./model_PID_3D_2679_loss_0.123_vloss_0.323_acc_0.945_vacc_0.936.hdf5\n",
            "\n",
            "Epoch 2680: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2680: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2681: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2681: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2682: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2682: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2683: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2683: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2684: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2684: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2685: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2685: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2686: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2686: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2687: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2687: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2688: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2688: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2689: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2689: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2690: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2690: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2691: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2691: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2692: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2692: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2693: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2693: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2694: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2694: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2695: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2695: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2696: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2696: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2697: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2697: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2698: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2698: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2699: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2699: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2700: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2700: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2701: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2701: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2702: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2702: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2703: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2703: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2704: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2704: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2705: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2705: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2706: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2706: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2707: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2707: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2708: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2708: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2709: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2709: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2710: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2710: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2711: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2711: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2712: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2712: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2713: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2713: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2714: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2714: loss did not improve from 0.12341\n",
            "\n",
            "Epoch 2715: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2715: loss improved from 0.12341 to 0.12283, saving model to ./model_PID_3D_2715_loss_0.123_vloss_0.319_acc_0.948_vacc_0.938.hdf5\n",
            "\n",
            "Epoch 2716: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2716: loss did not improve from 0.12283\n",
            "\n",
            "Epoch 2717: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2717: loss did not improve from 0.12283\n",
            "\n",
            "Epoch 2718: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2718: loss did not improve from 0.12283\n",
            "\n",
            "Epoch 2719: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2719: loss did not improve from 0.12283\n",
            "\n",
            "Epoch 2720: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2720: loss did not improve from 0.12283\n",
            "\n",
            "Epoch 2721: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2721: loss did not improve from 0.12283\n",
            "\n",
            "Epoch 2722: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2722: loss did not improve from 0.12283\n",
            "\n",
            "Epoch 2723: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2723: loss did not improve from 0.12283\n",
            "\n",
            "Epoch 2724: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2724: loss improved from 0.12283 to 0.12054, saving model to ./model_PID_3D_2724_loss_0.121_vloss_0.320_acc_0.946_vacc_0.944.hdf5\n",
            "\n",
            "Epoch 2725: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2725: loss did not improve from 0.12054\n",
            "\n",
            "Epoch 2726: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2726: loss did not improve from 0.12054\n",
            "\n",
            "Epoch 2727: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2727: loss did not improve from 0.12054\n",
            "\n",
            "Epoch 2728: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2728: loss did not improve from 0.12054\n",
            "\n",
            "Epoch 2729: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2729: loss did not improve from 0.12054\n",
            "\n",
            "Epoch 2730: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2730: loss did not improve from 0.12054\n",
            "\n",
            "Epoch 2731: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2731: loss did not improve from 0.12054\n",
            "\n",
            "Epoch 2732: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2732: loss improved from 0.12054 to 0.11825, saving model to ./model_PID_3D_2732_loss_0.118_vloss_0.324_acc_0.949_vacc_0.939.hdf5\n",
            "\n",
            "Epoch 2733: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2733: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2734: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2734: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2735: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2735: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2736: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2736: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2737: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2737: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2738: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2738: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2739: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2739: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2740: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2740: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2741: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2741: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2742: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2742: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2743: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2743: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2744: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2744: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2745: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2745: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2746: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2746: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2747: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2747: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2748: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2748: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2749: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2749: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2750: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2750: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2751: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2751: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2752: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2752: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2753: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2753: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2754: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2754: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2755: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2755: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2756: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2756: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2757: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2757: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2758: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2758: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2759: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2759: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2760: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2760: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2761: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2761: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2762: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2762: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2763: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2763: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2764: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2764: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2765: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2765: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2766: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2766: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2767: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2767: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2768: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2768: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2769: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2769: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2770: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2770: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2771: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2771: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2772: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2772: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2773: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2773: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2774: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2774: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2775: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2775: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2776: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2776: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2777: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2777: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2778: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2778: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2779: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2779: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2780: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2780: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2781: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2781: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2782: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2782: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2783: LearningRateScheduler setting learning rate to 0.005.\n",
            "\n",
            "Epoch 2783: loss did not improve from 0.11825\n",
            "\n",
            "Epoch 2784: LearningRateScheduler setting learning rate to 0.005.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if __learning__: \n",
        "    history = model.fit(X_train, y_train, epochs=_epochs_, batch_size=_epochs_, validation_data=(X_test, y_test),verbose=0,callbacks=callbacks,)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "blabla"
      ],
      "metadata": {
        "id": "pSNV4K_HDX5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "__load_file__=True\n",
        "model_file=\"model_PID__0634_loss_0.086_vloss_1.253_acc_0.961_vacc_0.886.hdf5\"\n",
        "model_url=\"https://github.com/sipocz/pid_time_series/raw/main/model3/\"+model_file"
      ],
      "metadata": {
        "id": "EGg1PjCJDTKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __load_file__:\n",
        "    ! rm *.hdf5 \n",
        "    ! wget $model_url\n",
        "    model.load_weights(model_file)"
      ],
      "metadata": {
        "id": "JgzklVywoNmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwcWQ94IpDFu"
      },
      "outputs": [],
      "source": [
        "y_pred=model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_display_object_visualization.html#sphx-glr-auto-examples-miscellaneous-plot-display-object-visualization-py"
      ],
      "metadata": {
        "id": "H0c0Fkd2cWRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import Binarizer\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "zctwrl1AcTZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bina_transformer=Binarizer(threshold=0.5)\n",
        "y_pred_transform=bina_transformer.fit_transform(y_pred)"
      ],
      "metadata": {
        "id": "hxZwDiKYhA5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCqcqNJl79G5"
      },
      "outputs": [],
      "source": [
        "cm=confusion_matrix(y_test,y_pred_transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm_display = ConfusionMatrixDisplay(cm).plot()"
      ],
      "metadata": {
        "id": "Z69kCq3T-pMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZ0rmkNsBGnl"
      },
      "outputs": [],
      "source": [
        "fpr, tpr, _ = roc_curve( y_pred_transform,y_test,pos_label=1)\n",
        "roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()\n",
        "auc = roc_auc_score(y_test, y_pred_transform)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_all_normalized"
      ],
      "metadata": {
        "id": "sNIc1l6vF6Y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def color_changer(arr):\n",
        "    o=[\"r\" if i>0.5 else \"g\" for i in arr]\n",
        "    return o"
      ],
      "metadata": {
        "id": "YFJoZO8TG1ED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotgraf(df_in, predicted):\n",
        "    xkoordinata=[i for i in range(len(df_in[\"0\"]))]\n",
        "    plot.figure(figsize=(12,6))\n",
        "    col_ch=color_changer(predicted)\n",
        "    plot.scatter(xkoordinata,df_in[\"0\"],c=col_ch,marker=\".\",alpha=0.3)\n",
        "    plot.ylabel('értékek')\n",
        "    plot.xlabel('index')\n",
        "    plot\n",
        "    plot.show()"
      ],
      "metadata": {
        "id": "YMHy-wbZGeqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_y_all_predict"
      ],
      "metadata": {
        "id": "HuL1OutGHHEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_y_all_predict=model.predict(df_all_normalized[prediktorok])"
      ],
      "metadata": {
        "id": "4aXpzheKE7bM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_y_predict=df_y_all_predict.round()"
      ],
      "metadata": {
        "id": "70M96KLSdCHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_y_predict"
      ],
      "metadata": {
        "id": "e72-bHKzdZve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plotgraf(df_all_normalized[400:600],df_y_predict[400:600])"
      ],
      "metadata": {
        "id": "BO3xdrHVGXhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auc"
      ],
      "metadata": {
        "id": "WMRd5eGU9ASA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grafikon3(fx,desc1,txt1,desc2=\"\",txt2=\"\",desc3=\"\",txt3=\"\",ngraf=2,c1='rgba(35,128,132,0.8)', c2='rgba(193,99,99,0.8)',c3='rgba(193,99,99,0.8)',title=None):\n",
        "    '''\n",
        "    fx: dataFrame\n",
        "    desc1:column1\n",
        "    txt1: label1\n",
        "    desc2:column2\n",
        "    txt2: label2\n",
        "    ngraf: number of graph\n",
        "    c1: color1\n",
        "    c2: color2\n",
        "    title: graph title\n",
        "    '''\n",
        "    \n",
        "    #x_=[i for i in range(len(y_pred))]\n",
        "    if title==None:\n",
        "      title=txt1+\" \"+txt2\n",
        "    import plotly.express as px\n",
        "    import plotly.graph_objects as go\n",
        "    from plotly.subplots import make_subplots\n",
        "    fig0 = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
        "\n",
        "\n",
        "    if ngraf>=3:\n",
        "        fig0.add_trace(\n",
        "            go.Bar(x=fx.index, y=fx[desc3], marker_color='rgba(225, 20, 20,0.2)',  name=txt3, showlegend=True, ),\n",
        "              secondary_y=False,\n",
        "            #row=1, col=1\n",
        "        )\n",
        "\n",
        "\n",
        "    if ngraf>=2:\n",
        "        fig0.add_trace(\n",
        "            go.Scatter(x=fx.index, y=fx[desc2], name=txt2, line=dict(color=c2) ,showlegend=True  ),\n",
        "            secondary_y=False,\n",
        "            #row=1, col=1\n",
        "\n",
        "        )\n",
        "\n",
        "    fig0.add_trace(\n",
        "        go.Scatter(x=fx.index, y=fx[desc1], name=txt1, line=dict(color=c1) ,showlegend=True  ),\n",
        "        secondary_y=False,\n",
        "        #row=1, col=1\n",
        "\n",
        "    )\n",
        "\n",
        "    fig0.update_layout(\n",
        "        title=title,\n",
        "        autosize=False,\n",
        "        width=1200,\n",
        "        height=600,\n",
        "        \n",
        "        )\n",
        "\n",
        "    print(title)\n",
        "    fig0.update_yaxes(title_text=\"<b>\"+title+\"</b>\", secondary_y=False)\n",
        "    #fig0.update_yaxes(title_text=\"<b>Alarm státusz</b>\", secondary_y=True)\n",
        "    fig0.update_layout(paper_bgcolor='rgb(200,200,200)')\n",
        "    fig0.show()"
      ],
      "metadata": {
        "id": "qa-AQAZV0EPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history_df=pd.DataFrame({\"epoch\":history.epoch, \"loss\":history.history[\"loss\"],\"val_loss\":history.history[\"val_loss\"]})"
      ],
      "metadata": {
        "id": "Uve0EfpV0Rkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grafikon3(history_df,\"loss\",\"Loss\",\"val_loss\",\"Val_Loss\",title=None)"
      ],
      "metadata": {
        "id": "4ENvDCA-0U1g"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnHwH/Fh2hPnF1cdaXbdNf",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c87c61177f4748b2bdfb31295cff1fda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e1844b69cf74824b0d2fab73f57ed81",
              "IPY_MODEL_39a0d96ff0b24795959e6728ca72d8a3"
            ],
            "layout": "IPY_MODEL_0d239abe35ed490da92da3bc36facb7e"
          }
        },
        "9e1844b69cf74824b0d2fab73f57ed81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b19d54cce6d94f11bd5054348d3531b5",
            "placeholder": "​",
            "style": "IPY_MODEL_a1a9e4c9c55d4aa0a705214aeb709898",
            "value": "0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "39a0d96ff0b24795959e6728ca72d8a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_344fd49416ff433aa6504eff336f98b3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_90c5214645e34f709e7d8aad1abc70e4",
            "value": 1
          }
        },
        "0d239abe35ed490da92da3bc36facb7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b19d54cce6d94f11bd5054348d3531b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1a9e4c9c55d4aa0a705214aeb709898": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "344fd49416ff433aa6504eff336f98b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90c5214645e34f709e7d8aad1abc70e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}