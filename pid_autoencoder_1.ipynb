{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sipocz/pid_time_series/blob/main/pid_autoencoder_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0tNYnFR-6Xh",
        "outputId": "6826b316-a204-44a4-c7ba-c026c33dc25b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.8/dist-packages (0.13.7)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (3.19.6)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (3.1.29)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.8/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (1.9.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (1.0.11)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.8/dist-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.8/dist-packages (from GitPython>=1.0.0->wandb) (4.0.10)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OWFIUUUGKGdA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import seaborn as sns\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ag6zIuPmKTux"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coqJiGk7KW_4",
        "outputId": "acee04ab-5944-45ee-e68b-49d3b19ff2f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-_usNw7yKZDt"
      },
      "outputs": [],
      "source": [
        "#user = \"Anna\"\n",
        "user = \"SL\"\n",
        "uzem = \"Szint1\"\n",
        "data_source=\"5\"\n",
        "#fname=\"72C03_TC_error_toNN.csv\"\n",
        "fname_good = \"415_SC_error_part1.csv\"\n",
        "fname_bad = \"415_SC_error_part2.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OkO7F6NaKbxi"
      },
      "outputs": [],
      "source": [
        "# Elérési út a 415_SC_error-hoz\n",
        "if user==\"Anna\":\n",
        "    path_good = \"/content/drive/MyDrive/Egyetem_MSc/Diplomamunka/2022Anna/Datapipeline/\" + data_source + \"/\" + fname_good\n",
        "    path_bad = \"/content/drive/MyDrive/Egyetem_MSc/Diplomamunka/2022Anna/Datapipeline/\" + data_source + \"/\" + fname_bad\n",
        "    path_fig = \"/content/drive/MyDrive/Egyetem_MSc/Diplomamunka/2022Anna/Datapipeline/plots/\"\n",
        "else:\n",
        "    path_good = \"/content/drive/MyDrive/2022Anna/Datapipeline/\" + data_source + \"/\" + fname_good\n",
        "    path_bad = \"/content/drive/MyDrive/2022Anna/Datapipeline/\" + data_source + \"/\" + fname_bad\n",
        "    path_fig = \"/content/drive/MyDrive/2022Anna/Datapipeline/plots/\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5ZDDiY9KfAQ",
        "outputId": "952423e3-8433-401b-cd1b-99cd6e8201e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/2022Anna/Datapipeline/5/415_SC_error_part1.csv\n",
            "/content/drive/MyDrive/2022Anna/Datapipeline/5/415_SC_error_part2.csv\n"
          ]
        }
      ],
      "source": [
        "print(path_good)\n",
        "print(path_bad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vUcMjZAGKvtt"
      },
      "outputs": [],
      "source": [
        "df_good = pd.read_csv(path_good,usecols=None)\n",
        "df_bad = pd.read_csv(path_bad,usecols=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYuDXKraLOt4",
        "outputId": "ca71a202-06b0-47f1-f1ba-ef9b63bfcfba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "print(df_good.isnull().values.any())\n",
        "print(df_bad.isnull().values.any())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "vzl5zIO1LUoq",
        "outputId": "82a3306a-f520-4b16-b11f-7dc06e0486a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0          1          2          3          4        5         6  \\\n",
              "0 -54.810024 -80.342186 -60.770203 -41.081482 -21.779583 -3.82353 -0.806820   \n",
              "1 -80.342186 -60.770203 -41.081482 -21.779583  -3.823530 -0.80682  0.220875   \n",
              "\n",
              "          7         8         9        10        11        12        13  \\\n",
              "0  0.220875  0.220875  0.220875  0.220875  0.220875  0.220875  0.220875   \n",
              "1  0.220875  0.220875  0.220875  0.220875  0.220875  0.220875  0.220875   \n",
              "\n",
              "         14        15        16        17        18        19  \n",
              "0  0.220875  0.220875  0.220875  0.220875  0.220875  0.220875  \n",
              "1  0.220875  0.220875  0.220875  0.220875  0.220875  0.220875  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-518daa93-9ac5-4f80-8c01-120be30fdaef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-54.810024</td>\n",
              "      <td>-80.342186</td>\n",
              "      <td>-60.770203</td>\n",
              "      <td>-41.081482</td>\n",
              "      <td>-21.779583</td>\n",
              "      <td>-3.82353</td>\n",
              "      <td>-0.806820</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-80.342186</td>\n",
              "      <td>-60.770203</td>\n",
              "      <td>-41.081482</td>\n",
              "      <td>-21.779583</td>\n",
              "      <td>-3.823530</td>\n",
              "      <td>-0.80682</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-518daa93-9ac5-4f80-8c01-120be30fdaef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-518daa93-9ac5-4f80-8c01-120be30fdaef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-518daa93-9ac5-4f80-8c01-120be30fdaef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df_good.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "f0xJfadFMOfA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "hIMQw2sULmj9"
      },
      "outputs": [],
      "source": [
        "\n",
        "import matplotlib.pyplot as plot\n",
        "\n",
        "df_ = df_good\n",
        "\n",
        "# You must normalize the data before applying the fit method\n",
        "df_good_normalized=(df_ - df_.mean()) / df_.std()\n",
        "\n",
        "# Normalize bad data with the good data parameters\n",
        "df_bad_normalized=(df_bad - df_.mean()) / df_.std()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wknFhIRBNQ7k"
      },
      "outputs": [],
      "source": [
        "df_good_normalized[\"state\"]=0\n",
        "df_bad_normalized[\"state\"]=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "3W5mi70VM6hL",
        "outputId": "35675c29-64cc-4fbe-b01a-9dedcc7f3381"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              0          1          2          3         4         5  \\\n",
              "0    -10.681306 -16.586266 -14.612051 -11.087981 -6.293341 -1.192618   \n",
              "1    -15.654548 -12.549683  -9.889987  -5.905180 -1.164099 -0.314249   \n",
              "2    -11.842250  -8.489023  -5.260696  -1.083756 -0.302359 -0.015017   \n",
              "3     -8.007214  -4.508142  -0.954188  -0.273732 -0.008793 -0.015017   \n",
              "4     -4.247524  -0.804833  -0.230672   0.002217 -0.008793 -0.015017   \n",
              "...         ...        ...        ...        ...       ...       ...   \n",
              "1053   0.037801   0.029297   0.015806   0.002217 -0.008793 -0.015017   \n",
              "1054   0.037801   0.029297   0.015806   0.002217 -0.008793 -0.015017   \n",
              "1055   0.037801   0.029297   0.015806   0.002217 -0.008793 -0.015017   \n",
              "1056   0.037801   0.029297   0.015806   0.002217 -0.008793 -0.015017   \n",
              "1057   0.037801   0.029297   0.015806   0.002217 -0.008793 -0.015017   \n",
              "\n",
              "             6         7         8         9  ...        11        12  \\\n",
              "0    -0.315574 -0.016425 -0.016425 -0.016425  ... -0.016425 -0.016425   \n",
              "1    -0.016141 -0.016425 -0.016425 -0.016425  ... -0.016425 -0.016425   \n",
              "2    -0.016141 -0.016425 -0.016425 -0.016425  ... -0.016425 -0.016425   \n",
              "3    -0.016141 -0.016425 -0.016425 -0.016425  ... -0.016425 -0.016425   \n",
              "4    -0.016141 -0.016425 -0.016425 -0.016425  ... -0.016425 -0.016425   \n",
              "...        ...       ...       ...       ...  ...       ...       ...   \n",
              "1053 -0.016141 -0.016425 -0.016425 -0.016425  ... -0.016425 -0.016425   \n",
              "1054 -0.016141 -0.016425 -0.016425 -0.016425  ... -0.016425 -0.016425   \n",
              "1055 -0.016141 -0.016425 -0.016425 -0.016425  ... -0.016425 -0.016425   \n",
              "1056 -0.016141 -0.016425 -0.016425 -0.016425  ... -0.016425 -0.016425   \n",
              "1057 -0.016141 -0.016425 -0.016425 -0.016425  ... -0.016425 -0.016425   \n",
              "\n",
              "            13        14        15        16        17        18        19  \\\n",
              "0    -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425   \n",
              "1    -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425   \n",
              "2    -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425   \n",
              "3    -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425   \n",
              "4    -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "1053 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425   \n",
              "1054 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425   \n",
              "1055 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425   \n",
              "1056 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425   \n",
              "1057 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425   \n",
              "\n",
              "      state  \n",
              "0         0  \n",
              "1         0  \n",
              "2         0  \n",
              "3         0  \n",
              "4         0  \n",
              "...     ...  \n",
              "1053      0  \n",
              "1054      0  \n",
              "1055      0  \n",
              "1056      0  \n",
              "1057      0  \n",
              "\n",
              "[1058 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-81bb36a8-23f2-4236-b742-00435016ce69\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-10.681306</td>\n",
              "      <td>-16.586266</td>\n",
              "      <td>-14.612051</td>\n",
              "      <td>-11.087981</td>\n",
              "      <td>-6.293341</td>\n",
              "      <td>-1.192618</td>\n",
              "      <td>-0.315574</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-15.654548</td>\n",
              "      <td>-12.549683</td>\n",
              "      <td>-9.889987</td>\n",
              "      <td>-5.905180</td>\n",
              "      <td>-1.164099</td>\n",
              "      <td>-0.314249</td>\n",
              "      <td>-0.016141</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-11.842250</td>\n",
              "      <td>-8.489023</td>\n",
              "      <td>-5.260696</td>\n",
              "      <td>-1.083756</td>\n",
              "      <td>-0.302359</td>\n",
              "      <td>-0.015017</td>\n",
              "      <td>-0.016141</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-8.007214</td>\n",
              "      <td>-4.508142</td>\n",
              "      <td>-0.954188</td>\n",
              "      <td>-0.273732</td>\n",
              "      <td>-0.008793</td>\n",
              "      <td>-0.015017</td>\n",
              "      <td>-0.016141</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-4.247524</td>\n",
              "      <td>-0.804833</td>\n",
              "      <td>-0.230672</td>\n",
              "      <td>0.002217</td>\n",
              "      <td>-0.008793</td>\n",
              "      <td>-0.015017</td>\n",
              "      <td>-0.016141</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1053</th>\n",
              "      <td>0.037801</td>\n",
              "      <td>0.029297</td>\n",
              "      <td>0.015806</td>\n",
              "      <td>0.002217</td>\n",
              "      <td>-0.008793</td>\n",
              "      <td>-0.015017</td>\n",
              "      <td>-0.016141</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1054</th>\n",
              "      <td>0.037801</td>\n",
              "      <td>0.029297</td>\n",
              "      <td>0.015806</td>\n",
              "      <td>0.002217</td>\n",
              "      <td>-0.008793</td>\n",
              "      <td>-0.015017</td>\n",
              "      <td>-0.016141</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1055</th>\n",
              "      <td>0.037801</td>\n",
              "      <td>0.029297</td>\n",
              "      <td>0.015806</td>\n",
              "      <td>0.002217</td>\n",
              "      <td>-0.008793</td>\n",
              "      <td>-0.015017</td>\n",
              "      <td>-0.016141</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1056</th>\n",
              "      <td>0.037801</td>\n",
              "      <td>0.029297</td>\n",
              "      <td>0.015806</td>\n",
              "      <td>0.002217</td>\n",
              "      <td>-0.008793</td>\n",
              "      <td>-0.015017</td>\n",
              "      <td>-0.016141</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1057</th>\n",
              "      <td>0.037801</td>\n",
              "      <td>0.029297</td>\n",
              "      <td>0.015806</td>\n",
              "      <td>0.002217</td>\n",
              "      <td>-0.008793</td>\n",
              "      <td>-0.015017</td>\n",
              "      <td>-0.016141</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1058 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81bb36a8-23f2-4236-b742-00435016ce69')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-81bb36a8-23f2-4236-b742-00435016ce69 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-81bb36a8-23f2-4236-b742-00435016ce69');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "df_good_normalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9nY0OMtYPT8J"
      },
      "outputs": [],
      "source": [
        "df_all_normalized=pd.concat([df_good_normalized,df_bad_normalized],axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "ClfUnwBRPwgK",
        "outputId": "617649ae-b7fd-43ac-efa2-c22a584a4d6d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             0         1         2         3         4         5         6  \\\n",
              "1263  0.029553  0.020564  0.005651 -0.009153 -0.020888 -0.027346 -0.028478   \n",
              "1264  0.029553  0.020564  0.005651 -0.009153 -0.020888 -0.027346 -0.028478   \n",
              "1265  0.029553  0.020564  0.005651 -0.009153 -0.020888 -0.027346 -0.028478   \n",
              "1266  0.029553  0.020564  0.005651 -0.009153 -0.020888 -0.027346 -0.028478   \n",
              "1267  0.029553  0.020564  0.005651 -0.009153 -0.020888 -0.027346 -0.028478   \n",
              "\n",
              "             7         8         9  ...        11        12        13  \\\n",
              "1263 -0.028763 -0.028763 -0.028763  ... -0.028763 -0.028763 -0.028763   \n",
              "1264 -0.028763 -0.028763 -0.028763  ... -0.028763 -0.028763 -0.028763   \n",
              "1265 -0.028763 -0.028763 -0.028763  ... -0.028763 -0.028763 -0.028763   \n",
              "1266 -0.028763 -0.028763 -0.028763  ... -0.028763 -0.028763 -0.028763   \n",
              "1267 -0.028763 -0.028763 -0.028763  ... -0.028763 -0.028763 -0.028763   \n",
              "\n",
              "            14        15        16        17        18        19  state  \n",
              "1263 -0.028763 -0.028763 -0.028763 -0.028763 -0.028763 -0.028763      1  \n",
              "1264 -0.028763 -0.028763 -0.028763 -0.028763 -0.028763 -0.028763      1  \n",
              "1265 -0.028763 -0.028763 -0.028763 -0.028763 -0.028763 -0.028763      1  \n",
              "1266 -0.028763 -0.028763 -0.028763 -0.028763 -0.028763 -0.028763      1  \n",
              "1267 -0.028763 -0.028763 -0.028763 -0.028763 -0.028763 -0.028763      1  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-588b7933-0bd6-4d9f-ac33-a6c4b2844f59\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1263</th>\n",
              "      <td>0.029553</td>\n",
              "      <td>0.020564</td>\n",
              "      <td>0.005651</td>\n",
              "      <td>-0.009153</td>\n",
              "      <td>-0.020888</td>\n",
              "      <td>-0.027346</td>\n",
              "      <td>-0.028478</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1264</th>\n",
              "      <td>0.029553</td>\n",
              "      <td>0.020564</td>\n",
              "      <td>0.005651</td>\n",
              "      <td>-0.009153</td>\n",
              "      <td>-0.020888</td>\n",
              "      <td>-0.027346</td>\n",
              "      <td>-0.028478</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1265</th>\n",
              "      <td>0.029553</td>\n",
              "      <td>0.020564</td>\n",
              "      <td>0.005651</td>\n",
              "      <td>-0.009153</td>\n",
              "      <td>-0.020888</td>\n",
              "      <td>-0.027346</td>\n",
              "      <td>-0.028478</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1266</th>\n",
              "      <td>0.029553</td>\n",
              "      <td>0.020564</td>\n",
              "      <td>0.005651</td>\n",
              "      <td>-0.009153</td>\n",
              "      <td>-0.020888</td>\n",
              "      <td>-0.027346</td>\n",
              "      <td>-0.028478</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1267</th>\n",
              "      <td>0.029553</td>\n",
              "      <td>0.020564</td>\n",
              "      <td>0.005651</td>\n",
              "      <td>-0.009153</td>\n",
              "      <td>-0.020888</td>\n",
              "      <td>-0.027346</td>\n",
              "      <td>-0.028478</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-588b7933-0bd6-4d9f-ac33-a6c4b2844f59')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-588b7933-0bd6-4d9f-ac33-a6c4b2844f59 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-588b7933-0bd6-4d9f-ac33-a6c4b2844f59');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "df_all_normalized.tail()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n"
      ],
      "metadata": {
        "id": "nVvhP84S_F1y"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_N1_=15\n",
        "_N2_=10\n",
        "_N3_=5\n",
        "_lr_=0.001\n",
        "_batch_size_=3\n",
        "_drop1_=0.0\n",
        "_drop2_=0.0\n",
        "_epochs_=5500\n"
      ],
      "metadata": {
        "id": "XC5_bGE0iyi4"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"lr\": _lr_, \"batch_size\": _batch_size_,\"architecture\": \"AutoencoderNN\", \n",
        "          \"depth\": 2,\n",
        "          \"layer1\":_N1_,  \"layer2\":_N2_,\"layer3\":_N3_,\"layer4\":_N2_,\"layer5\":_N1_,\"layer_out\":20, \n",
        "          \"drop1\":_drop1_,\"drop2\":_drop2_,\n",
        "          \"epochs\":_epochs_\n",
        "          \n",
        "          \n",
        "          }\n",
        "\n",
        "wandb.init(project=\"pid_autoencoder\", entity=\"sipoczlaszlo\",config=config)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503,
          "referenced_widgets": [
            "67a7971beebc423382b8bd33854da0fe",
            "78a3dcd8cc5b432d87da8556d8d12b28",
            "01327c6e47834b51b7ac073f531dab1d",
            "f7d177a00baf4a79ad18daf903c1e426",
            "f9ff02cee5e546818f289597c6fbf2ad",
            "80fb96cba1b44366bcbd25427c52faa0",
            "9f02f4b46e2e46ea84bb539b813dbec3",
            "b7a0dcfacddb41e8bb58facaada21b6d"
          ]
        },
        "id": "nOtKllcviuoj",
        "outputId": "3326813a-e517-4d7d-d754-3c858f01b0a7"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:23g9znj8) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.517 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.001083…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67a7971beebc423382b8bd33854da0fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/MAE</td><td>█▄▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████▃▃▃▃▃▃▃▃▃▃▃</td></tr><tr><td>epoch/loss</td><td>█▄▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████▃▃▃▃▃▃▃▃▃▃▃</td></tr><tr><td>epoch/val_MAE</td><td>█▆▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_loss</td><td>█▆▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/MAE</td><td>0.66965</td></tr><tr><td>epoch/epoch</td><td>5499</td></tr><tr><td>epoch/learning_rate</td><td>0.002</td></tr><tr><td>epoch/loss</td><td>0.66965</td></tr><tr><td>epoch/lr</td><td>0.002</td></tr><tr><td>epoch/val_MAE</td><td>0.38284</td></tr><tr><td>epoch/val_loss</td><td>0.38284</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">astral-oath-6</strong>: <a href=\"https://wandb.ai/sipoczlaszlo/pid_autoencoder/runs/23g9znj8\" target=\"_blank\">https://wandb.ai/sipoczlaszlo/pid_autoencoder/runs/23g9znj8</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20221219_094338-23g9znj8/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:23g9znj8). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221219_095819-1aqqmvmg</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/sipoczlaszlo/pid_autoencoder/runs/1aqqmvmg\" target=\"_blank\">confused-sound-7</a></strong> to <a href=\"https://wandb.ai/sipoczlaszlo/pid_autoencoder\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/sipoczlaszlo/pid_autoencoder/runs/1aqqmvmg?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f4ad7872e50>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "rcPrX4lWP2R_"
      },
      "outputs": [],
      "source": [
        "from keras.engine.base_layer import regularizers\n",
        "from keras.layers import InputLayer, Dense, LSTM, Input, Dropout\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import SGD,Adam,Adamax,Nadam,Ftrl,Adadelta\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from keras.backend import clear_session\n",
        "from tensorflow.keras.losses import mean_absolute_percentage_error, huber,kld\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "clear_session()\n",
        "\n",
        "kernel_reg_1=tf.keras.regularizers.L2(0.1)\n",
        "\n",
        "input_size=20\n",
        "\n",
        "\n",
        "input1=Input(shape=(input_size,))\n",
        "l1_out=Dense(_N1_,activation=\"swish\",kernel_initializer='glorot_uniform',)(input1) # kernel_initializer='lecun_normal'  # L1\n",
        "\n",
        "\n",
        "\n",
        "l3_out=Dense(_N2_,activation=\"swish\",kernel_initializer='glorot_uniform',)(l1_out) #kernel_initializer='lecun_normal',  # L2\n",
        "\n",
        "l5_out=Dense(_N3_,activation=\"swish\",kernel_initializer='glorot_uniform',name=\"encoded\")(l3_out) #kernel_initializer='lecun_normal',  # L3\n",
        "\n",
        "l7_out=Dense(_N2_,activation=\"swish\",kernel_initializer='glorot_uniform')(l5_out) #kernel_initializer='lecun_normal',  # L4\n",
        "\n",
        "l9_out=Dense(_N1_,activation=\"swish\",kernel_initializer='glorot_uniform')(l7_out) #kernel_initializer='lecun_normal',  # L5\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "pred=Dense(input_size, activation=\"sigmoid\",)(l9_out)\n",
        "\n",
        "model = Model(inputs=input1, outputs=pred)\n",
        "optimizer=Adamax(learning_rate=_lr_,) #\n",
        "\n",
        "model.compile(loss='MSE',\n",
        "    optimizer=optimizer,\n",
        "    metrics=[\"MAE\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "yLzRRMnbIk9X"
      },
      "outputs": [],
      "source": [
        "# autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "RGIztQ3tQ3ni"
      },
      "outputs": [],
      "source": [
        "prediktorok=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\"]\n",
        "X_NN=df_all_normalized[prediktorok][:-100]  # \n",
        "y_NN=df_all_normalized[\"state\"][:-100]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_file=\"model_PID__54_loss_0.116_vloss_0.115_acc_0.953_vacc_0.958.hdf5\"\n",
        "#model_file=\"model_PID__94_loss_0.116_vloss_0.115_acc_0.950_vacc_0.966.hdf5\"\n",
        "model_file=\"model_PID__4491_loss_0.115_vloss_0.679_acc_0.954_vacc_0.880.hdf5\""
      ],
      "metadata": {
        "id": "DgjVCU185nNO"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_url=\"https://github.com/sipocz/pid_time_series/raw/main/model3/\"+model_file"
      ],
      "metadata": {
        "id": "iUhe0_4L5ufk"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "__load_file__=False"
      ],
      "metadata": {
        "id": "UIxI3AS6Yw3S"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __load_file__:\n",
        "    ! rm *.hdf5 \n",
        "    ! wget $model_url\n",
        "    model.load_weights(model_file)"
      ],
      "metadata": {
        "id": "ZNjx5XGesZPO"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "rdH49nLKRVoh"
      },
      "outputs": [],
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(X_NN,y_NN,train_size=0.7,shuffle=True,random_state=33)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm *.hdf5 "
      ],
      "metadata": {
        "id": "jJfOOTfGfDXi"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def learning_rate_corrector(epoch,lr):\n",
        "    if epoch > 4000:\n",
        "        lr = 0.002\n",
        "        return lr\n",
        "    if epoch > 3000:\n",
        "        lr = 0.005\n",
        "        return lr\n",
        "    if epoch > 2000:\n",
        "        lr = 0.001\n",
        "        return lr\n",
        "    \n",
        "    if epoch > 500:\n",
        "        lr = 0.001\n",
        "        return lr\n",
        "    return lr\n",
        "    "
      ],
      "metadata": {
        "id": "A-Kv8ORiEfub"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wandb.keras import WandbMetricsLogger\n",
        "fname=\"./model_PID_\"\n",
        "callbacks = [\n",
        "        LearningRateScheduler(learning_rate_corrector,verbose=1),\n",
        "        WandbMetricsLogger(),       \n",
        "        ModelCheckpoint(filepath=fname+\"_{epoch:04.0f}\"+\"_loss_{loss:.3f}_vloss_{val_loss:.3f}_acc_{MAE:.3f}_vacc_{val_MAE:.3f}.hdf5\", monitor='loss',\n",
        "                        verbose=2, save_best_only=True, mode='min')]\n"
      ],
      "metadata": {
        "id": "RNfi--Kfo4HM"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "__learning__=True"
      ],
      "metadata": {
        "id": "O6ofy0moderd"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Z3Z4q14D7eC"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "9Ol0mW6WRlkS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b6ed82ba-1f23-43c8-e90b-2323588e731e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mA streamkimeneten csak az utolsó 5000 sor látható.\u001b[0m\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3220 - MAE: 0.7325\n",
            "Epoch 484: loss improved from 2.32206 to 2.32197, saving model to ./model_PID__0484_loss_2.322_vloss_0.331_acc_0.732_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 2.3220 - MAE: 0.7325 - val_loss: 0.3311 - val_MAE: 0.3883 - lr: 0.0010\n",
            "\n",
            "Epoch 485: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 485/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3219 - MAE: 0.7324\n",
            "Epoch 485: loss improved from 2.32197 to 2.32188, saving model to ./model_PID__0485_loss_2.322_vloss_0.331_acc_0.732_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.3219 - MAE: 0.7324 - val_loss: 0.3311 - val_MAE: 0.3883 - lr: 0.0010\n",
            "\n",
            "Epoch 486: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 486/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3218 - MAE: 0.7323\n",
            "Epoch 486: loss improved from 2.32188 to 2.32179, saving model to ./model_PID__0486_loss_2.322_vloss_0.331_acc_0.732_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 2.3218 - MAE: 0.7323 - val_loss: 0.3312 - val_MAE: 0.3882 - lr: 0.0010\n",
            "\n",
            "Epoch 487: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 487/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3217 - MAE: 0.7322\n",
            "Epoch 487: loss improved from 2.32179 to 2.32170, saving model to ./model_PID__0487_loss_2.322_vloss_0.331_acc_0.732_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 2.3217 - MAE: 0.7322 - val_loss: 0.3312 - val_MAE: 0.3882 - lr: 0.0010\n",
            "\n",
            "Epoch 488: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 488/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3216 - MAE: 0.7321\n",
            "Epoch 488: loss improved from 2.32170 to 2.32161, saving model to ./model_PID__0488_loss_2.322_vloss_0.331_acc_0.732_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.3216 - MAE: 0.7321 - val_loss: 0.3312 - val_MAE: 0.3881 - lr: 0.0010\n",
            "\n",
            "Epoch 489: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 489/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3215 - MAE: 0.7320\n",
            "Epoch 489: loss improved from 2.32161 to 2.32153, saving model to ./model_PID__0489_loss_2.322_vloss_0.331_acc_0.732_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 2.3215 - MAE: 0.7320 - val_loss: 0.3313 - val_MAE: 0.3881 - lr: 0.0010\n",
            "\n",
            "Epoch 490: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 490/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3214 - MAE: 0.7319\n",
            "Epoch 490: loss improved from 2.32153 to 2.32144, saving model to ./model_PID__0490_loss_2.321_vloss_0.331_acc_0.732_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 2.3214 - MAE: 0.7319 - val_loss: 0.3313 - val_MAE: 0.3880 - lr: 0.0010\n",
            "\n",
            "Epoch 491: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 491/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3214 - MAE: 0.7318\n",
            "Epoch 491: loss improved from 2.32144 to 2.32136, saving model to ./model_PID__0491_loss_2.321_vloss_0.331_acc_0.732_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.3214 - MAE: 0.7318 - val_loss: 0.3313 - val_MAE: 0.3879 - lr: 0.0010\n",
            "\n",
            "Epoch 492: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 492/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3213 - MAE: 0.7317\n",
            "Epoch 492: loss improved from 2.32136 to 2.32127, saving model to ./model_PID__0492_loss_2.321_vloss_0.331_acc_0.732_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 2.3213 - MAE: 0.7317 - val_loss: 0.3314 - val_MAE: 0.3879 - lr: 0.0010\n",
            "\n",
            "Epoch 493: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 493/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3212 - MAE: 0.7317\n",
            "Epoch 493: loss improved from 2.32127 to 2.32119, saving model to ./model_PID__0493_loss_2.321_vloss_0.331_acc_0.732_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 2.3212 - MAE: 0.7317 - val_loss: 0.3314 - val_MAE: 0.3878 - lr: 0.0010\n",
            "\n",
            "Epoch 494: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 494/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3211 - MAE: 0.7316\n",
            "Epoch 494: loss improved from 2.32119 to 2.32110, saving model to ./model_PID__0494_loss_2.321_vloss_0.331_acc_0.732_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 2.3211 - MAE: 0.7316 - val_loss: 0.3315 - val_MAE: 0.3878 - lr: 0.0010\n",
            "\n",
            "Epoch 495: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 495/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3210 - MAE: 0.7315\n",
            "Epoch 495: loss improved from 2.32110 to 2.32102, saving model to ./model_PID__0495_loss_2.321_vloss_0.331_acc_0.731_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 2.3210 - MAE: 0.7315 - val_loss: 0.3315 - val_MAE: 0.3877 - lr: 0.0010\n",
            "\n",
            "Epoch 496: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 496/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3209 - MAE: 0.7314\n",
            "Epoch 496: loss improved from 2.32102 to 2.32094, saving model to ./model_PID__0496_loss_2.321_vloss_0.332_acc_0.731_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 2.3209 - MAE: 0.7314 - val_loss: 0.3315 - val_MAE: 0.3877 - lr: 0.0010\n",
            "\n",
            "Epoch 497: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 497/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3209 - MAE: 0.7313\n",
            "Epoch 497: loss improved from 2.32094 to 2.32086, saving model to ./model_PID__0497_loss_2.321_vloss_0.332_acc_0.731_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2.3209 - MAE: 0.7313 - val_loss: 0.3316 - val_MAE: 0.3876 - lr: 0.0010\n",
            "\n",
            "Epoch 498: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 498/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3208 - MAE: 0.7312\n",
            "Epoch 498: loss improved from 2.32086 to 2.32078, saving model to ./model_PID__0498_loss_2.321_vloss_0.332_acc_0.731_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.3208 - MAE: 0.7312 - val_loss: 0.3316 - val_MAE: 0.3876 - lr: 0.0010\n",
            "\n",
            "Epoch 499: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 499/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3207 - MAE: 0.7311\n",
            "Epoch 499: loss improved from 2.32078 to 2.32070, saving model to ./model_PID__0499_loss_2.321_vloss_0.332_acc_0.731_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.3207 - MAE: 0.7311 - val_loss: 0.3316 - val_MAE: 0.3875 - lr: 0.0010\n",
            "\n",
            "Epoch 500: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 500/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3206 - MAE: 0.7311\n",
            "Epoch 500: loss improved from 2.32070 to 2.32062, saving model to ./model_PID__0500_loss_2.321_vloss_0.332_acc_0.731_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.3206 - MAE: 0.7311 - val_loss: 0.3317 - val_MAE: 0.3875 - lr: 0.0010\n",
            "\n",
            "Epoch 501: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 501/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3205 - MAE: 0.7310\n",
            "Epoch 501: loss improved from 2.32062 to 2.32054, saving model to ./model_PID__0501_loss_2.321_vloss_0.332_acc_0.731_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 2.3205 - MAE: 0.7310 - val_loss: 0.3317 - val_MAE: 0.3874 - lr: 0.0010\n",
            "\n",
            "Epoch 502: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 502/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3205 - MAE: 0.7309\n",
            "Epoch 502: loss improved from 2.32054 to 2.32046, saving model to ./model_PID__0502_loss_2.320_vloss_0.332_acc_0.731_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 2.3205 - MAE: 0.7309 - val_loss: 0.3318 - val_MAE: 0.3874 - lr: 0.0010\n",
            "\n",
            "Epoch 503: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 503/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3204 - MAE: 0.7308\n",
            "Epoch 503: loss improved from 2.32046 to 2.32038, saving model to ./model_PID__0503_loss_2.320_vloss_0.332_acc_0.731_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 2.3204 - MAE: 0.7308 - val_loss: 0.3318 - val_MAE: 0.3873 - lr: 0.0010\n",
            "\n",
            "Epoch 504: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 504/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3203 - MAE: 0.7307\n",
            "Epoch 504: loss improved from 2.32038 to 2.32030, saving model to ./model_PID__0504_loss_2.320_vloss_0.332_acc_0.731_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 2.3203 - MAE: 0.7307 - val_loss: 0.3318 - val_MAE: 0.3873 - lr: 0.0010\n",
            "\n",
            "Epoch 505: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 505/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3202 - MAE: 0.7306\n",
            "Epoch 505: loss improved from 2.32030 to 2.32022, saving model to ./model_PID__0505_loss_2.320_vloss_0.332_acc_0.731_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 2.3202 - MAE: 0.7306 - val_loss: 0.3319 - val_MAE: 0.3872 - lr: 0.0010\n",
            "\n",
            "Epoch 506: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 506/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3201 - MAE: 0.7306\n",
            "Epoch 506: loss improved from 2.32022 to 2.32014, saving model to ./model_PID__0506_loss_2.320_vloss_0.332_acc_0.731_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.3201 - MAE: 0.7306 - val_loss: 0.3319 - val_MAE: 0.3872 - lr: 0.0010\n",
            "\n",
            "Epoch 507: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 507/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3201 - MAE: 0.7305\n",
            "Epoch 507: loss improved from 2.32014 to 2.32006, saving model to ./model_PID__0507_loss_2.320_vloss_0.332_acc_0.730_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.3201 - MAE: 0.7305 - val_loss: 0.3320 - val_MAE: 0.3871 - lr: 0.0010\n",
            "\n",
            "Epoch 508: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 508/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3200 - MAE: 0.7304\n",
            "Epoch 508: loss improved from 2.32006 to 2.31998, saving model to ./model_PID__0508_loss_2.320_vloss_0.332_acc_0.730_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 2.3200 - MAE: 0.7304 - val_loss: 0.3320 - val_MAE: 0.3871 - lr: 0.0010\n",
            "\n",
            "Epoch 509: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 509/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3199 - MAE: 0.7303\n",
            "Epoch 509: loss improved from 2.31998 to 2.31991, saving model to ./model_PID__0509_loss_2.320_vloss_0.332_acc_0.730_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 2.3199 - MAE: 0.7303 - val_loss: 0.3320 - val_MAE: 0.3871 - lr: 0.0010\n",
            "\n",
            "Epoch 510: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 510/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3198 - MAE: 0.7302\n",
            "Epoch 510: loss improved from 2.31991 to 2.31983, saving model to ./model_PID__0510_loss_2.320_vloss_0.332_acc_0.730_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.3198 - MAE: 0.7302 - val_loss: 0.3321 - val_MAE: 0.3870 - lr: 0.0010\n",
            "\n",
            "Epoch 511: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 511/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3197 - MAE: 0.7301\n",
            "Epoch 511: loss improved from 2.31983 to 2.31975, saving model to ./model_PID__0511_loss_2.320_vloss_0.332_acc_0.730_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 2.3197 - MAE: 0.7301 - val_loss: 0.3321 - val_MAE: 0.3870 - lr: 0.0010\n",
            "\n",
            "Epoch 512: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 512/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3197 - MAE: 0.7301\n",
            "Epoch 512: loss improved from 2.31975 to 2.31967, saving model to ./model_PID__0512_loss_2.320_vloss_0.332_acc_0.730_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 2.3197 - MAE: 0.7301 - val_loss: 0.3322 - val_MAE: 0.3869 - lr: 0.0010\n",
            "\n",
            "Epoch 513: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 513/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3196 - MAE: 0.7300\n",
            "Epoch 513: loss improved from 2.31967 to 2.31959, saving model to ./model_PID__0513_loss_2.320_vloss_0.332_acc_0.730_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 2.3196 - MAE: 0.7300 - val_loss: 0.3322 - val_MAE: 0.3869 - lr: 0.0010\n",
            "\n",
            "Epoch 514: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 514/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3195 - MAE: 0.7299\n",
            "Epoch 514: loss improved from 2.31959 to 2.31951, saving model to ./model_PID__0514_loss_2.320_vloss_0.332_acc_0.730_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2.3195 - MAE: 0.7299 - val_loss: 0.3322 - val_MAE: 0.3869 - lr: 0.0010\n",
            "\n",
            "Epoch 515: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 515/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3194 - MAE: 0.7298\n",
            "Epoch 515: loss improved from 2.31951 to 2.31943, saving model to ./model_PID__0515_loss_2.319_vloss_0.332_acc_0.730_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 2.3194 - MAE: 0.7298 - val_loss: 0.3323 - val_MAE: 0.3868 - lr: 0.0010\n",
            "\n",
            "Epoch 516: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 516/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3194 - MAE: 0.7297\n",
            "Epoch 516: loss improved from 2.31943 to 2.31936, saving model to ./model_PID__0516_loss_2.319_vloss_0.332_acc_0.730_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.3194 - MAE: 0.7297 - val_loss: 0.3323 - val_MAE: 0.3868 - lr: 0.0010\n",
            "\n",
            "Epoch 517: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 517/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3193 - MAE: 0.7296\n",
            "Epoch 517: loss improved from 2.31936 to 2.31928, saving model to ./model_PID__0517_loss_2.319_vloss_0.332_acc_0.730_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 2.3193 - MAE: 0.7296 - val_loss: 0.3324 - val_MAE: 0.3868 - lr: 0.0010\n",
            "\n",
            "Epoch 518: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 518/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3192 - MAE: 0.7296\n",
            "Epoch 518: loss improved from 2.31928 to 2.31920, saving model to ./model_PID__0518_loss_2.319_vloss_0.332_acc_0.730_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.3192 - MAE: 0.7296 - val_loss: 0.3324 - val_MAE: 0.3867 - lr: 0.0010\n",
            "\n",
            "Epoch 519: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 519/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3191 - MAE: 0.7295\n",
            "Epoch 519: loss improved from 2.31920 to 2.31912, saving model to ./model_PID__0519_loss_2.319_vloss_0.332_acc_0.729_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 2.3191 - MAE: 0.7295 - val_loss: 0.3324 - val_MAE: 0.3867 - lr: 0.0010\n",
            "\n",
            "Epoch 520: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 520/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3190 - MAE: 0.7294\n",
            "Epoch 520: loss improved from 2.31912 to 2.31904, saving model to ./model_PID__0520_loss_2.319_vloss_0.332_acc_0.729_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 2.3190 - MAE: 0.7294 - val_loss: 0.3325 - val_MAE: 0.3866 - lr: 0.0010\n",
            "\n",
            "Epoch 521: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 521/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3190 - MAE: 0.7293\n",
            "Epoch 521: loss improved from 2.31904 to 2.31896, saving model to ./model_PID__0521_loss_2.319_vloss_0.333_acc_0.729_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 2.3190 - MAE: 0.7293 - val_loss: 0.3325 - val_MAE: 0.3866 - lr: 0.0010\n",
            "\n",
            "Epoch 522: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 522/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3189 - MAE: 0.7292\n",
            "Epoch 522: loss improved from 2.31896 to 2.31888, saving model to ./model_PID__0522_loss_2.319_vloss_0.333_acc_0.729_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 2.3189 - MAE: 0.7292 - val_loss: 0.3326 - val_MAE: 0.3866 - lr: 0.0010\n",
            "\n",
            "Epoch 523: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 523/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3188 - MAE: 0.7292\n",
            "Epoch 523: loss improved from 2.31888 to 2.31880, saving model to ./model_PID__0523_loss_2.319_vloss_0.333_acc_0.729_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 2.3188 - MAE: 0.7292 - val_loss: 0.3326 - val_MAE: 0.3865 - lr: 0.0010\n",
            "\n",
            "Epoch 524: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 524/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3187 - MAE: 0.7291\n",
            "Epoch 524: loss improved from 2.31880 to 2.31872, saving model to ./model_PID__0524_loss_2.319_vloss_0.333_acc_0.729_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.3187 - MAE: 0.7291 - val_loss: 0.3327 - val_MAE: 0.3865 - lr: 0.0010\n",
            "\n",
            "Epoch 525: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 525/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3186 - MAE: 0.7290\n",
            "Epoch 525: loss improved from 2.31872 to 2.31864, saving model to ./model_PID__0525_loss_2.319_vloss_0.333_acc_0.729_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.3186 - MAE: 0.7290 - val_loss: 0.3327 - val_MAE: 0.3865 - lr: 0.0010\n",
            "\n",
            "Epoch 526: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 526/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3186 - MAE: 0.7289\n",
            "Epoch 526: loss improved from 2.31864 to 2.31856, saving model to ./model_PID__0526_loss_2.319_vloss_0.333_acc_0.729_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 2.3186 - MAE: 0.7289 - val_loss: 0.3327 - val_MAE: 0.3864 - lr: 0.0010\n",
            "\n",
            "Epoch 527: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 527/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3185 - MAE: 0.7288\n",
            "Epoch 527: loss improved from 2.31856 to 2.31848, saving model to ./model_PID__0527_loss_2.318_vloss_0.333_acc_0.729_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.3185 - MAE: 0.7288 - val_loss: 0.3328 - val_MAE: 0.3864 - lr: 0.0010\n",
            "\n",
            "Epoch 528: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 528/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3184 - MAE: 0.7288\n",
            "Epoch 528: loss improved from 2.31848 to 2.31840, saving model to ./model_PID__0528_loss_2.318_vloss_0.333_acc_0.729_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 2.3184 - MAE: 0.7288 - val_loss: 0.3328 - val_MAE: 0.3864 - lr: 0.0010\n",
            "\n",
            "Epoch 529: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 529/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3183 - MAE: 0.7287\n",
            "Epoch 529: loss improved from 2.31840 to 2.31832, saving model to ./model_PID__0529_loss_2.318_vloss_0.333_acc_0.729_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 2.3183 - MAE: 0.7287 - val_loss: 0.3328 - val_MAE: 0.3863 - lr: 0.0010\n",
            "\n",
            "Epoch 530: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 530/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3182 - MAE: 0.7286\n",
            "Epoch 530: loss improved from 2.31832 to 2.31824, saving model to ./model_PID__0530_loss_2.318_vloss_0.333_acc_0.729_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 2.3182 - MAE: 0.7286 - val_loss: 0.3329 - val_MAE: 0.3863 - lr: 0.0010\n",
            "\n",
            "Epoch 531: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 531/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3182 - MAE: 0.7285\n",
            "Epoch 531: loss improved from 2.31824 to 2.31816, saving model to ./model_PID__0531_loss_2.318_vloss_0.333_acc_0.729_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 2.3182 - MAE: 0.7285 - val_loss: 0.3329 - val_MAE: 0.3863 - lr: 0.0010\n",
            "\n",
            "Epoch 532: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 532/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3181 - MAE: 0.7284\n",
            "Epoch 532: loss improved from 2.31816 to 2.31807, saving model to ./model_PID__0532_loss_2.318_vloss_0.333_acc_0.728_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 2.3181 - MAE: 0.7284 - val_loss: 0.3330 - val_MAE: 0.3862 - lr: 0.0010\n",
            "\n",
            "Epoch 533: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 533/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3180 - MAE: 0.7284\n",
            "Epoch 533: loss improved from 2.31807 to 2.31800, saving model to ./model_PID__0533_loss_2.318_vloss_0.333_acc_0.728_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 2.3180 - MAE: 0.7284 - val_loss: 0.3330 - val_MAE: 0.3862 - lr: 0.0010\n",
            "\n",
            "Epoch 534: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 534/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3179 - MAE: 0.7283\n",
            "Epoch 534: loss improved from 2.31800 to 2.31792, saving model to ./model_PID__0534_loss_2.318_vloss_0.333_acc_0.728_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 2.3179 - MAE: 0.7283 - val_loss: 0.3330 - val_MAE: 0.3862 - lr: 0.0010\n",
            "\n",
            "Epoch 535: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 535/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3178 - MAE: 0.7282\n",
            "Epoch 535: loss improved from 2.31792 to 2.31784, saving model to ./model_PID__0535_loss_2.318_vloss_0.333_acc_0.728_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 2.3178 - MAE: 0.7282 - val_loss: 0.3331 - val_MAE: 0.3861 - lr: 0.0010\n",
            "\n",
            "Epoch 536: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 536/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3178 - MAE: 0.7281\n",
            "Epoch 536: loss improved from 2.31784 to 2.31776, saving model to ./model_PID__0536_loss_2.318_vloss_0.333_acc_0.728_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 2.3178 - MAE: 0.7281 - val_loss: 0.3331 - val_MAE: 0.3861 - lr: 0.0010\n",
            "\n",
            "Epoch 537: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 537/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3177 - MAE: 0.7281\n",
            "Epoch 537: loss improved from 2.31776 to 2.31768, saving model to ./model_PID__0537_loss_2.318_vloss_0.333_acc_0.728_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 2.3177 - MAE: 0.7281 - val_loss: 0.3331 - val_MAE: 0.3861 - lr: 0.0010\n",
            "\n",
            "Epoch 538: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 538/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3176 - MAE: 0.7280\n",
            "Epoch 538: loss improved from 2.31768 to 2.31760, saving model to ./model_PID__0538_loss_2.318_vloss_0.333_acc_0.728_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.3176 - MAE: 0.7280 - val_loss: 0.3331 - val_MAE: 0.3860 - lr: 0.0010\n",
            "\n",
            "Epoch 539: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 539/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3175 - MAE: 0.7279\n",
            "Epoch 539: loss improved from 2.31760 to 2.31752, saving model to ./model_PID__0539_loss_2.318_vloss_0.333_acc_0.728_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 2.3175 - MAE: 0.7279 - val_loss: 0.3332 - val_MAE: 0.3860 - lr: 0.0010\n",
            "\n",
            "Epoch 540: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 540/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3174 - MAE: 0.7278\n",
            "Epoch 540: loss improved from 2.31752 to 2.31744, saving model to ./model_PID__0540_loss_2.317_vloss_0.333_acc_0.728_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 2.3174 - MAE: 0.7278 - val_loss: 0.3332 - val_MAE: 0.3860 - lr: 0.0010\n",
            "\n",
            "Epoch 541: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 541/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3174 - MAE: 0.7278\n",
            "Epoch 541: loss improved from 2.31744 to 2.31736, saving model to ./model_PID__0541_loss_2.317_vloss_0.333_acc_0.728_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 2.3174 - MAE: 0.7278 - val_loss: 0.3332 - val_MAE: 0.3859 - lr: 0.0010\n",
            "\n",
            "Epoch 542: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 542/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3173 - MAE: 0.7277\n",
            "Epoch 542: loss improved from 2.31736 to 2.31728, saving model to ./model_PID__0542_loss_2.317_vloss_0.333_acc_0.728_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 2.3173 - MAE: 0.7277 - val_loss: 0.3333 - val_MAE: 0.3859 - lr: 0.0010\n",
            "\n",
            "Epoch 543: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 543/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3172 - MAE: 0.7276\n",
            "Epoch 543: loss improved from 2.31728 to 2.31721, saving model to ./model_PID__0543_loss_2.317_vloss_0.333_acc_0.728_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 2.3172 - MAE: 0.7276 - val_loss: 0.3333 - val_MAE: 0.3858 - lr: 0.0010\n",
            "\n",
            "Epoch 544: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 544/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3171 - MAE: 0.7275\n",
            "Epoch 544: loss improved from 2.31721 to 2.31713, saving model to ./model_PID__0544_loss_2.317_vloss_0.333_acc_0.728_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.3171 - MAE: 0.7275 - val_loss: 0.3333 - val_MAE: 0.3858 - lr: 0.0010\n",
            "\n",
            "Epoch 545: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 545/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3170 - MAE: 0.7275\n",
            "Epoch 545: loss improved from 2.31713 to 2.31705, saving model to ./model_PID__0545_loss_2.317_vloss_0.333_acc_0.727_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 2.3170 - MAE: 0.7275 - val_loss: 0.3333 - val_MAE: 0.3858 - lr: 0.0010\n",
            "\n",
            "Epoch 546: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 546/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3170 - MAE: 0.7274\n",
            "Epoch 546: loss improved from 2.31705 to 2.31697, saving model to ./model_PID__0546_loss_2.317_vloss_0.333_acc_0.727_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 2.3170 - MAE: 0.7274 - val_loss: 0.3333 - val_MAE: 0.3857 - lr: 0.0010\n",
            "\n",
            "Epoch 547: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 547/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3169 - MAE: 0.7273\n",
            "Epoch 547: loss improved from 2.31697 to 2.31689, saving model to ./model_PID__0547_loss_2.317_vloss_0.333_acc_0.727_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 2.3169 - MAE: 0.7273 - val_loss: 0.3334 - val_MAE: 0.3857 - lr: 0.0010\n",
            "\n",
            "Epoch 548: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 548/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3168 - MAE: 0.7272\n",
            "Epoch 548: loss improved from 2.31689 to 2.31681, saving model to ./model_PID__0548_loss_2.317_vloss_0.333_acc_0.727_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 2.3168 - MAE: 0.7272 - val_loss: 0.3334 - val_MAE: 0.3857 - lr: 0.0010\n",
            "\n",
            "Epoch 549: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 549/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3167 - MAE: 0.7272\n",
            "Epoch 549: loss improved from 2.31681 to 2.31673, saving model to ./model_PID__0549_loss_2.317_vloss_0.333_acc_0.727_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.3167 - MAE: 0.7272 - val_loss: 0.3334 - val_MAE: 0.3856 - lr: 0.0010\n",
            "\n",
            "Epoch 550: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 550/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3166 - MAE: 0.7271\n",
            "Epoch 550: loss improved from 2.31673 to 2.31665, saving model to ./model_PID__0550_loss_2.317_vloss_0.333_acc_0.727_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 2.3166 - MAE: 0.7271 - val_loss: 0.3334 - val_MAE: 0.3856 - lr: 0.0010\n",
            "\n",
            "Epoch 551: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 551/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3166 - MAE: 0.7270\n",
            "Epoch 551: loss improved from 2.31665 to 2.31657, saving model to ./model_PID__0551_loss_2.317_vloss_0.333_acc_0.727_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 2.3166 - MAE: 0.7270 - val_loss: 0.3335 - val_MAE: 0.3856 - lr: 0.0010\n",
            "\n",
            "Epoch 552: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 552/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3165 - MAE: 0.7269\n",
            "Epoch 552: loss improved from 2.31657 to 2.31649, saving model to ./model_PID__0552_loss_2.316_vloss_0.333_acc_0.727_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 2.3165 - MAE: 0.7269 - val_loss: 0.3335 - val_MAE: 0.3855 - lr: 0.0010\n",
            "\n",
            "Epoch 553: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 553/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3164 - MAE: 0.7269\n",
            "Epoch 553: loss improved from 2.31649 to 2.31640, saving model to ./model_PID__0553_loss_2.316_vloss_0.333_acc_0.727_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.3164 - MAE: 0.7269 - val_loss: 0.3335 - val_MAE: 0.3855 - lr: 0.0010\n",
            "\n",
            "Epoch 554: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 554/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3163 - MAE: 0.7268\n",
            "Epoch 554: loss improved from 2.31640 to 2.31632, saving model to ./model_PID__0554_loss_2.316_vloss_0.334_acc_0.727_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 2.3163 - MAE: 0.7268 - val_loss: 0.3335 - val_MAE: 0.3855 - lr: 0.0010\n",
            "\n",
            "Epoch 555: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 555/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3162 - MAE: 0.7267\n",
            "Epoch 555: loss improved from 2.31632 to 2.31624, saving model to ./model_PID__0555_loss_2.316_vloss_0.334_acc_0.727_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 2.3162 - MAE: 0.7267 - val_loss: 0.3335 - val_MAE: 0.3854 - lr: 0.0010\n",
            "\n",
            "Epoch 556: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 556/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3162 - MAE: 0.7267\n",
            "Epoch 556: loss improved from 2.31624 to 2.31615, saving model to ./model_PID__0556_loss_2.316_vloss_0.334_acc_0.727_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 2.3162 - MAE: 0.7267 - val_loss: 0.3336 - val_MAE: 0.3854 - lr: 0.0010\n",
            "\n",
            "Epoch 557: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 557/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3161 - MAE: 0.7266\n",
            "Epoch 557: loss improved from 2.31615 to 2.31607, saving model to ./model_PID__0557_loss_2.316_vloss_0.334_acc_0.727_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 2.3161 - MAE: 0.7266 - val_loss: 0.3336 - val_MAE: 0.3854 - lr: 0.0010\n",
            "\n",
            "Epoch 558: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 558/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3160 - MAE: 0.7265\n",
            "Epoch 558: loss improved from 2.31607 to 2.31598, saving model to ./model_PID__0558_loss_2.316_vloss_0.334_acc_0.727_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2.3160 - MAE: 0.7265 - val_loss: 0.3336 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 559: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 559/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3159 - MAE: 0.7264\n",
            "Epoch 559: loss improved from 2.31598 to 2.31589, saving model to ./model_PID__0559_loss_2.316_vloss_0.334_acc_0.726_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 2.3159 - MAE: 0.7264 - val_loss: 0.3336 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 560: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 560/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3158 - MAE: 0.7264\n",
            "Epoch 560: loss improved from 2.31589 to 2.31580, saving model to ./model_PID__0560_loss_2.316_vloss_0.334_acc_0.726_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 2.3158 - MAE: 0.7264 - val_loss: 0.3337 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 561: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 561/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3157 - MAE: 0.7263\n",
            "Epoch 561: loss improved from 2.31580 to 2.31571, saving model to ./model_PID__0561_loss_2.316_vloss_0.334_acc_0.726_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 2.3157 - MAE: 0.7263 - val_loss: 0.3337 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 562: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 562/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3156 - MAE: 0.7262\n",
            "Epoch 562: loss improved from 2.31571 to 2.31562, saving model to ./model_PID__0562_loss_2.316_vloss_0.334_acc_0.726_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.3156 - MAE: 0.7262 - val_loss: 0.3337 - val_MAE: 0.3852 - lr: 0.0010\n",
            "\n",
            "Epoch 563: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 563/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3155 - MAE: 0.7262\n",
            "Epoch 563: loss improved from 2.31562 to 2.31553, saving model to ./model_PID__0563_loss_2.316_vloss_0.334_acc_0.726_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.3155 - MAE: 0.7262 - val_loss: 0.3338 - val_MAE: 0.3852 - lr: 0.0010\n",
            "\n",
            "Epoch 564: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 564/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3154 - MAE: 0.7261\n",
            "Epoch 564: loss improved from 2.31553 to 2.31543, saving model to ./model_PID__0564_loss_2.315_vloss_0.334_acc_0.726_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 2.3154 - MAE: 0.7261 - val_loss: 0.3338 - val_MAE: 0.3852 - lr: 0.0010\n",
            "\n",
            "Epoch 565: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 565/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3153 - MAE: 0.7260\n",
            "Epoch 565: loss improved from 2.31543 to 2.31534, saving model to ./model_PID__0565_loss_2.315_vloss_0.334_acc_0.726_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 2.3153 - MAE: 0.7260 - val_loss: 0.3338 - val_MAE: 0.3852 - lr: 0.0010\n",
            "\n",
            "Epoch 566: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 566/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3152 - MAE: 0.7259\n",
            "Epoch 566: loss improved from 2.31534 to 2.31524, saving model to ./model_PID__0566_loss_2.315_vloss_0.334_acc_0.726_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 2.3152 - MAE: 0.7259 - val_loss: 0.3339 - val_MAE: 0.3852 - lr: 0.0010\n",
            "\n",
            "Epoch 567: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 567/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3151 - MAE: 0.7259\n",
            "Epoch 567: loss improved from 2.31524 to 2.31514, saving model to ./model_PID__0567_loss_2.315_vloss_0.334_acc_0.726_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 2.3151 - MAE: 0.7259 - val_loss: 0.3339 - val_MAE: 0.3852 - lr: 0.0010\n",
            "\n",
            "Epoch 568: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 568/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3150 - MAE: 0.7258\n",
            "Epoch 568: loss improved from 2.31514 to 2.31504, saving model to ./model_PID__0568_loss_2.315_vloss_0.334_acc_0.726_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 2.3150 - MAE: 0.7258 - val_loss: 0.3340 - val_MAE: 0.3852 - lr: 0.0010\n",
            "\n",
            "Epoch 569: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 569/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3149 - MAE: 0.7257\n",
            "Epoch 569: loss improved from 2.31504 to 2.31494, saving model to ./model_PID__0569_loss_2.315_vloss_0.334_acc_0.726_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 2.3149 - MAE: 0.7257 - val_loss: 0.3340 - val_MAE: 0.3852 - lr: 0.0010\n",
            "\n",
            "Epoch 570: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 570/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3148 - MAE: 0.7256\n",
            "Epoch 570: loss improved from 2.31494 to 2.31484, saving model to ./model_PID__0570_loss_2.315_vloss_0.334_acc_0.726_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 2.3148 - MAE: 0.7256 - val_loss: 0.3341 - val_MAE: 0.3852 - lr: 0.0010\n",
            "\n",
            "Epoch 571: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 571/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3147 - MAE: 0.7256\n",
            "Epoch 571: loss improved from 2.31484 to 2.31473, saving model to ./model_PID__0571_loss_2.315_vloss_0.334_acc_0.726_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 2.3147 - MAE: 0.7256 - val_loss: 0.3341 - val_MAE: 0.3852 - lr: 0.0010\n",
            "\n",
            "Epoch 572: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 572/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3146 - MAE: 0.7255\n",
            "Epoch 572: loss improved from 2.31473 to 2.31463, saving model to ./model_PID__0572_loss_2.315_vloss_0.334_acc_0.725_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 2.3146 - MAE: 0.7255 - val_loss: 0.3342 - val_MAE: 0.3852 - lr: 0.0010\n",
            "\n",
            "Epoch 573: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 573/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3145 - MAE: 0.7254\n",
            "Epoch 573: loss improved from 2.31463 to 2.31452, saving model to ./model_PID__0573_loss_2.315_vloss_0.334_acc_0.725_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 2.3145 - MAE: 0.7254 - val_loss: 0.3342 - val_MAE: 0.3852 - lr: 0.0010\n",
            "\n",
            "Epoch 574: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 574/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3144 - MAE: 0.7253\n",
            "Epoch 574: loss improved from 2.31452 to 2.31441, saving model to ./model_PID__0574_loss_2.314_vloss_0.334_acc_0.725_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 2.3144 - MAE: 0.7253 - val_loss: 0.3343 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 575: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 575/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3143 - MAE: 0.7252\n",
            "Epoch 575: loss improved from 2.31441 to 2.31430, saving model to ./model_PID__0575_loss_2.314_vloss_0.334_acc_0.725_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.3143 - MAE: 0.7252 - val_loss: 0.3343 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 576: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 576/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3142 - MAE: 0.7252\n",
            "Epoch 576: loss improved from 2.31430 to 2.31418, saving model to ./model_PID__0576_loss_2.314_vloss_0.334_acc_0.725_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 2.3142 - MAE: 0.7252 - val_loss: 0.3344 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 577: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 577/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3141 - MAE: 0.7251\n",
            "Epoch 577: loss improved from 2.31418 to 2.31407, saving model to ./model_PID__0577_loss_2.314_vloss_0.334_acc_0.725_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 2.3141 - MAE: 0.7251 - val_loss: 0.3344 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 578: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 578/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3139 - MAE: 0.7250\n",
            "Epoch 578: loss improved from 2.31407 to 2.31395, saving model to ./model_PID__0578_loss_2.314_vloss_0.334_acc_0.725_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 2.3139 - MAE: 0.7250 - val_loss: 0.3345 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 579: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 579/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3138 - MAE: 0.7249\n",
            "Epoch 579: loss improved from 2.31395 to 2.31383, saving model to ./model_PID__0579_loss_2.314_vloss_0.335_acc_0.725_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 2.3138 - MAE: 0.7249 - val_loss: 0.3345 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 580: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 580/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3137 - MAE: 0.7249\n",
            "Epoch 580: loss improved from 2.31383 to 2.31371, saving model to ./model_PID__0580_loss_2.314_vloss_0.335_acc_0.725_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 2.3137 - MAE: 0.7249 - val_loss: 0.3346 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 581: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 581/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3136 - MAE: 0.7248\n",
            "Epoch 581: loss improved from 2.31371 to 2.31359, saving model to ./model_PID__0581_loss_2.314_vloss_0.335_acc_0.725_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 2.3136 - MAE: 0.7248 - val_loss: 0.3346 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 582: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 582/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3135 - MAE: 0.7247\n",
            "Epoch 582: loss improved from 2.31359 to 2.31346, saving model to ./model_PID__0582_loss_2.313_vloss_0.335_acc_0.725_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 2.3135 - MAE: 0.7247 - val_loss: 0.3346 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 583: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 583/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3133 - MAE: 0.7247\n",
            "Epoch 583: loss improved from 2.31346 to 2.31333, saving model to ./model_PID__0583_loss_2.313_vloss_0.335_acc_0.725_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 2.3133 - MAE: 0.7247 - val_loss: 0.3347 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 584: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 584/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3132 - MAE: 0.7246\n",
            "Epoch 584: loss improved from 2.31333 to 2.31321, saving model to ./model_PID__0584_loss_2.313_vloss_0.335_acc_0.725_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.3132 - MAE: 0.7246 - val_loss: 0.3347 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 585: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 585/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3131 - MAE: 0.7245\n",
            "Epoch 585: loss improved from 2.31321 to 2.31308, saving model to ./model_PID__0585_loss_2.313_vloss_0.335_acc_0.725_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 2.3131 - MAE: 0.7245 - val_loss: 0.3347 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 586: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 586/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3129 - MAE: 0.7245\n",
            "Epoch 586: loss improved from 2.31308 to 2.31294, saving model to ./model_PID__0586_loss_2.313_vloss_0.335_acc_0.724_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 2.3129 - MAE: 0.7245 - val_loss: 0.3348 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 587: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 587/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3128 - MAE: 0.7244\n",
            "Epoch 587: loss improved from 2.31294 to 2.31281, saving model to ./model_PID__0587_loss_2.313_vloss_0.335_acc_0.724_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 2.3128 - MAE: 0.7244 - val_loss: 0.3348 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 588: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 588/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3127 - MAE: 0.7244\n",
            "Epoch 588: loss improved from 2.31281 to 2.31267, saving model to ./model_PID__0588_loss_2.313_vloss_0.335_acc_0.724_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 2.3127 - MAE: 0.7244 - val_loss: 0.3348 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 589: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 589/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3125 - MAE: 0.7243\n",
            "Epoch 589: loss improved from 2.31267 to 2.31254, saving model to ./model_PID__0589_loss_2.313_vloss_0.335_acc_0.724_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 2.3125 - MAE: 0.7243 - val_loss: 0.3349 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 590: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 590/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3124 - MAE: 0.7242\n",
            "Epoch 590: loss improved from 2.31254 to 2.31240, saving model to ./model_PID__0590_loss_2.312_vloss_0.335_acc_0.724_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 2.3124 - MAE: 0.7242 - val_loss: 0.3350 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 591: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 591/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3123 - MAE: 0.7242\n",
            "Epoch 591: loss improved from 2.31240 to 2.31226, saving model to ./model_PID__0591_loss_2.312_vloss_0.335_acc_0.724_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 2.3123 - MAE: 0.7242 - val_loss: 0.3350 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 592: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 592/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3121 - MAE: 0.7241\n",
            "Epoch 592: loss improved from 2.31226 to 2.31212, saving model to ./model_PID__0592_loss_2.312_vloss_0.335_acc_0.724_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 2.3121 - MAE: 0.7241 - val_loss: 0.3351 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 593: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 593/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3120 - MAE: 0.7240\n",
            "Epoch 593: loss improved from 2.31212 to 2.31198, saving model to ./model_PID__0593_loss_2.312_vloss_0.335_acc_0.724_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 2.3120 - MAE: 0.7240 - val_loss: 0.3351 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 594: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 594/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3118 - MAE: 0.7240\n",
            "Epoch 594: loss improved from 2.31198 to 2.31184, saving model to ./model_PID__0594_loss_2.312_vloss_0.335_acc_0.724_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 2.3118 - MAE: 0.7240 - val_loss: 0.3352 - val_MAE: 0.3854 - lr: 0.0010\n",
            "\n",
            "Epoch 595: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 595/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3117 - MAE: 0.7239\n",
            "Epoch 595: loss improved from 2.31184 to 2.31170, saving model to ./model_PID__0595_loss_2.312_vloss_0.335_acc_0.724_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 2.3117 - MAE: 0.7239 - val_loss: 0.3353 - val_MAE: 0.3854 - lr: 0.0010\n",
            "\n",
            "Epoch 596: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 596/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3116 - MAE: 0.7238\n",
            "Epoch 596: loss improved from 2.31170 to 2.31157, saving model to ./model_PID__0596_loss_2.312_vloss_0.335_acc_0.724_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.3116 - MAE: 0.7238 - val_loss: 0.3354 - val_MAE: 0.3854 - lr: 0.0010\n",
            "\n",
            "Epoch 597: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 597/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3114 - MAE: 0.7238\n",
            "Epoch 597: loss improved from 2.31157 to 2.31144, saving model to ./model_PID__0597_loss_2.311_vloss_0.335_acc_0.724_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 2.3114 - MAE: 0.7238 - val_loss: 0.3354 - val_MAE: 0.3854 - lr: 0.0010\n",
            "\n",
            "Epoch 598: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 598/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3113 - MAE: 0.7237\n",
            "Epoch 598: loss improved from 2.31144 to 2.31131, saving model to ./model_PID__0598_loss_2.311_vloss_0.335_acc_0.724_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 2.3113 - MAE: 0.7237 - val_loss: 0.3355 - val_MAE: 0.3854 - lr: 0.0010\n",
            "\n",
            "Epoch 599: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 599/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3112 - MAE: 0.7237\n",
            "Epoch 599: loss improved from 2.31131 to 2.31119, saving model to ./model_PID__0599_loss_2.311_vloss_0.336_acc_0.724_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2.3112 - MAE: 0.7237 - val_loss: 0.3355 - val_MAE: 0.3855 - lr: 0.0010\n",
            "\n",
            "Epoch 600: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 600/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3111 - MAE: 0.7236\n",
            "Epoch 600: loss improved from 2.31119 to 2.31106, saving model to ./model_PID__0600_loss_2.311_vloss_0.336_acc_0.724_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 2.3111 - MAE: 0.7236 - val_loss: 0.3356 - val_MAE: 0.3855 - lr: 0.0010\n",
            "\n",
            "Epoch 601: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 601/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3109 - MAE: 0.7235\n",
            "Epoch 601: loss improved from 2.31106 to 2.31094, saving model to ./model_PID__0601_loss_2.311_vloss_0.336_acc_0.724_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 2.3109 - MAE: 0.7235 - val_loss: 0.3357 - val_MAE: 0.3855 - lr: 0.0010\n",
            "\n",
            "Epoch 602: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 602/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3108 - MAE: 0.7235\n",
            "Epoch 602: loss improved from 2.31094 to 2.31083, saving model to ./model_PID__0602_loss_2.311_vloss_0.336_acc_0.723_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 2.3108 - MAE: 0.7235 - val_loss: 0.3357 - val_MAE: 0.3855 - lr: 0.0010\n",
            "\n",
            "Epoch 603: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 603/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3107 - MAE: 0.7234\n",
            "Epoch 603: loss improved from 2.31083 to 2.31071, saving model to ./model_PID__0603_loss_2.311_vloss_0.336_acc_0.723_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 2.3107 - MAE: 0.7234 - val_loss: 0.3358 - val_MAE: 0.3855 - lr: 0.0010\n",
            "\n",
            "Epoch 604: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 604/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3106 - MAE: 0.7234\n",
            "Epoch 604: loss improved from 2.31071 to 2.31060, saving model to ./model_PID__0604_loss_2.311_vloss_0.336_acc_0.723_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 2.3106 - MAE: 0.7234 - val_loss: 0.3358 - val_MAE: 0.3855 - lr: 0.0010\n",
            "\n",
            "Epoch 605: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 605/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3105 - MAE: 0.7233\n",
            "Epoch 605: loss improved from 2.31060 to 2.31049, saving model to ./model_PID__0605_loss_2.310_vloss_0.336_acc_0.723_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 2.3105 - MAE: 0.7233 - val_loss: 0.3359 - val_MAE: 0.3855 - lr: 0.0010\n",
            "\n",
            "Epoch 606: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 606/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3104 - MAE: 0.7233\n",
            "Epoch 606: loss improved from 2.31049 to 2.31039, saving model to ./model_PID__0606_loss_2.310_vloss_0.336_acc_0.723_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 2.3104 - MAE: 0.7233 - val_loss: 0.3359 - val_MAE: 0.3855 - lr: 0.0010\n",
            "\n",
            "Epoch 607: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 607/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3103 - MAE: 0.7232\n",
            "Epoch 607: loss improved from 2.31039 to 2.31028, saving model to ./model_PID__0607_loss_2.310_vloss_0.336_acc_0.723_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 2.3103 - MAE: 0.7232 - val_loss: 0.3360 - val_MAE: 0.3855 - lr: 0.0010\n",
            "\n",
            "Epoch 608: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 608/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3102 - MAE: 0.7232\n",
            "Epoch 608: loss improved from 2.31028 to 2.31019, saving model to ./model_PID__0608_loss_2.310_vloss_0.336_acc_0.723_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 2.3102 - MAE: 0.7232 - val_loss: 0.3360 - val_MAE: 0.3855 - lr: 0.0010\n",
            "\n",
            "Epoch 609: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 609/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3101 - MAE: 0.7231\n",
            "Epoch 609: loss improved from 2.31019 to 2.31009, saving model to ./model_PID__0609_loss_2.310_vloss_0.336_acc_0.723_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 2.3101 - MAE: 0.7231 - val_loss: 0.3361 - val_MAE: 0.3855 - lr: 0.0010\n",
            "\n",
            "Epoch 610: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 610/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3100 - MAE: 0.7231\n",
            "Epoch 610: loss improved from 2.31009 to 2.31000, saving model to ./model_PID__0610_loss_2.310_vloss_0.336_acc_0.723_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 2.3100 - MAE: 0.7231 - val_loss: 0.3361 - val_MAE: 0.3855 - lr: 0.0010\n",
            "\n",
            "Epoch 611: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 611/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3099 - MAE: 0.7230\n",
            "Epoch 611: loss improved from 2.31000 to 2.30991, saving model to ./model_PID__0611_loss_2.310_vloss_0.336_acc_0.723_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.3099 - MAE: 0.7230 - val_loss: 0.3362 - val_MAE: 0.3855 - lr: 0.0010\n",
            "\n",
            "Epoch 612: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 612/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3098 - MAE: 0.7230\n",
            "Epoch 612: loss improved from 2.30991 to 2.30982, saving model to ./model_PID__0612_loss_2.310_vloss_0.336_acc_0.723_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 2.3098 - MAE: 0.7230 - val_loss: 0.3362 - val_MAE: 0.3855 - lr: 0.0010\n",
            "\n",
            "Epoch 613: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 613/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3097 - MAE: 0.7229\n",
            "Epoch 613: loss improved from 2.30982 to 2.30974, saving model to ./model_PID__0613_loss_2.310_vloss_0.336_acc_0.723_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 2.3097 - MAE: 0.7229 - val_loss: 0.3363 - val_MAE: 0.3855 - lr: 0.0010\n",
            "\n",
            "Epoch 614: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 614/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3097 - MAE: 0.7229\n",
            "Epoch 614: loss improved from 2.30974 to 2.30966, saving model to ./model_PID__0614_loss_2.310_vloss_0.336_acc_0.723_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 2.3097 - MAE: 0.7229 - val_loss: 0.3363 - val_MAE: 0.3855 - lr: 0.0010\n",
            "\n",
            "Epoch 615: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 615/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3096 - MAE: 0.7228\n",
            "Epoch 615: loss improved from 2.30966 to 2.30959, saving model to ./model_PID__0615_loss_2.310_vloss_0.336_acc_0.723_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 2.3096 - MAE: 0.7228 - val_loss: 0.3364 - val_MAE: 0.3855 - lr: 0.0010\n",
            "\n",
            "Epoch 616: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 616/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3095 - MAE: 0.7228\n",
            "Epoch 616: loss improved from 2.30959 to 2.30951, saving model to ./model_PID__0616_loss_2.310_vloss_0.336_acc_0.723_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 2.3095 - MAE: 0.7228 - val_loss: 0.3364 - val_MAE: 0.3855 - lr: 0.0010\n",
            "\n",
            "Epoch 617: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 617/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3094 - MAE: 0.7227\n",
            "Epoch 617: loss improved from 2.30951 to 2.30944, saving model to ./model_PID__0617_loss_2.309_vloss_0.336_acc_0.723_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.3094 - MAE: 0.7227 - val_loss: 0.3364 - val_MAE: 0.3854 - lr: 0.0010\n",
            "\n",
            "Epoch 618: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 618/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3094 - MAE: 0.7227\n",
            "Epoch 618: loss improved from 2.30944 to 2.30936, saving model to ./model_PID__0618_loss_2.309_vloss_0.336_acc_0.723_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 2.3094 - MAE: 0.7227 - val_loss: 0.3365 - val_MAE: 0.3854 - lr: 0.0010\n",
            "\n",
            "Epoch 619: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 619/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3093 - MAE: 0.7226\n",
            "Epoch 619: loss improved from 2.30936 to 2.30929, saving model to ./model_PID__0619_loss_2.309_vloss_0.337_acc_0.723_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 2.3093 - MAE: 0.7226 - val_loss: 0.3365 - val_MAE: 0.3854 - lr: 0.0010\n",
            "\n",
            "Epoch 620: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 620/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3092 - MAE: 0.7226\n",
            "Epoch 620: loss improved from 2.30929 to 2.30922, saving model to ./model_PID__0620_loss_2.309_vloss_0.337_acc_0.723_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 2.3092 - MAE: 0.7226 - val_loss: 0.3366 - val_MAE: 0.3854 - lr: 0.0010\n",
            "\n",
            "Epoch 621: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 621/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3091 - MAE: 0.7225\n",
            "Epoch 621: loss improved from 2.30922 to 2.30915, saving model to ./model_PID__0621_loss_2.309_vloss_0.337_acc_0.723_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 2.3091 - MAE: 0.7225 - val_loss: 0.3366 - val_MAE: 0.3854 - lr: 0.0010\n",
            "\n",
            "Epoch 622: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 622/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3091 - MAE: 0.7225\n",
            "Epoch 622: loss improved from 2.30915 to 2.30908, saving model to ./model_PID__0622_loss_2.309_vloss_0.337_acc_0.722_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 2.3091 - MAE: 0.7225 - val_loss: 0.3366 - val_MAE: 0.3854 - lr: 0.0010\n",
            "\n",
            "Epoch 623: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 623/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3090 - MAE: 0.7224\n",
            "Epoch 623: loss improved from 2.30908 to 2.30901, saving model to ./model_PID__0623_loss_2.309_vloss_0.337_acc_0.722_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 2.3090 - MAE: 0.7224 - val_loss: 0.3367 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 624: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 624/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3089 - MAE: 0.7224\n",
            "Epoch 624: loss improved from 2.30901 to 2.30893, saving model to ./model_PID__0624_loss_2.309_vloss_0.337_acc_0.722_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 2.3089 - MAE: 0.7224 - val_loss: 0.3367 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 625: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 625/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3089 - MAE: 0.7223\n",
            "Epoch 625: loss improved from 2.30893 to 2.30886, saving model to ./model_PID__0625_loss_2.309_vloss_0.337_acc_0.722_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 2.3089 - MAE: 0.7223 - val_loss: 0.3367 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 626: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 626/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3088 - MAE: 0.7223\n",
            "Epoch 626: loss improved from 2.30886 to 2.30879, saving model to ./model_PID__0626_loss_2.309_vloss_0.337_acc_0.722_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 2.3088 - MAE: 0.7223 - val_loss: 0.3368 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 627: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 627/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3087 - MAE: 0.7222\n",
            "Epoch 627: loss improved from 2.30879 to 2.30871, saving model to ./model_PID__0627_loss_2.309_vloss_0.337_acc_0.722_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 2.3087 - MAE: 0.7222 - val_loss: 0.3368 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 628: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 628/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3086 - MAE: 0.7222\n",
            "Epoch 628: loss improved from 2.30871 to 2.30864, saving model to ./model_PID__0628_loss_2.309_vloss_0.337_acc_0.722_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 2.3086 - MAE: 0.7222 - val_loss: 0.3368 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 629: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 629/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3086 - MAE: 0.7221\n",
            "Epoch 629: loss improved from 2.30864 to 2.30856, saving model to ./model_PID__0629_loss_2.309_vloss_0.337_acc_0.722_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.3086 - MAE: 0.7221 - val_loss: 0.3369 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 630: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 630/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3085 - MAE: 0.7221\n",
            "Epoch 630: loss improved from 2.30856 to 2.30848, saving model to ./model_PID__0630_loss_2.308_vloss_0.337_acc_0.722_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 2.3085 - MAE: 0.7221 - val_loss: 0.3369 - val_MAE: 0.3852 - lr: 0.0010\n",
            "\n",
            "Epoch 631: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 631/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3084 - MAE: 0.7221\n",
            "Epoch 631: loss improved from 2.30848 to 2.30840, saving model to ./model_PID__0631_loss_2.308_vloss_0.337_acc_0.722_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 2.3084 - MAE: 0.7221 - val_loss: 0.3369 - val_MAE: 0.3852 - lr: 0.0010\n",
            "\n",
            "Epoch 632: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 632/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3083 - MAE: 0.7220\n",
            "Epoch 632: loss improved from 2.30840 to 2.30832, saving model to ./model_PID__0632_loss_2.308_vloss_0.337_acc_0.722_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 2.3083 - MAE: 0.7220 - val_loss: 0.3370 - val_MAE: 0.3852 - lr: 0.0010\n",
            "\n",
            "Epoch 633: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 633/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3082 - MAE: 0.7220\n",
            "Epoch 633: loss improved from 2.30832 to 2.30824, saving model to ./model_PID__0633_loss_2.308_vloss_0.337_acc_0.722_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 2.3082 - MAE: 0.7220 - val_loss: 0.3370 - val_MAE: 0.3852 - lr: 0.0010\n",
            "\n",
            "Epoch 634: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 634/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3082 - MAE: 0.7219\n",
            "Epoch 634: loss improved from 2.30824 to 2.30815, saving model to ./model_PID__0634_loss_2.308_vloss_0.337_acc_0.722_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.3082 - MAE: 0.7219 - val_loss: 0.3370 - val_MAE: 0.3852 - lr: 0.0010\n",
            "\n",
            "Epoch 635: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 635/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3081 - MAE: 0.7219\n",
            "Epoch 635: loss improved from 2.30815 to 2.30807, saving model to ./model_PID__0635_loss_2.308_vloss_0.337_acc_0.722_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 2.3081 - MAE: 0.7219 - val_loss: 0.3371 - val_MAE: 0.3852 - lr: 0.0010\n",
            "\n",
            "Epoch 636: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 636/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3080 - MAE: 0.7218\n",
            "Epoch 636: loss improved from 2.30807 to 2.30798, saving model to ./model_PID__0636_loss_2.308_vloss_0.337_acc_0.722_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 2.3080 - MAE: 0.7218 - val_loss: 0.3371 - val_MAE: 0.3852 - lr: 0.0010\n",
            "\n",
            "Epoch 637: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 637/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3079 - MAE: 0.7218\n",
            "Epoch 637: loss improved from 2.30798 to 2.30790, saving model to ./model_PID__0637_loss_2.308_vloss_0.337_acc_0.722_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 2.3079 - MAE: 0.7218 - val_loss: 0.3371 - val_MAE: 0.3851 - lr: 0.0010\n",
            "\n",
            "Epoch 638: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 638/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3078 - MAE: 0.7217\n",
            "Epoch 638: loss improved from 2.30790 to 2.30781, saving model to ./model_PID__0638_loss_2.308_vloss_0.337_acc_0.722_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 2.3078 - MAE: 0.7217 - val_loss: 0.3372 - val_MAE: 0.3851 - lr: 0.0010\n",
            "\n",
            "Epoch 639: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 639/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3077 - MAE: 0.7217\n",
            "Epoch 639: loss improved from 2.30781 to 2.30773, saving model to ./model_PID__0639_loss_2.308_vloss_0.337_acc_0.722_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 2.3077 - MAE: 0.7217 - val_loss: 0.3372 - val_MAE: 0.3851 - lr: 0.0010\n",
            "\n",
            "Epoch 640: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 640/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3076 - MAE: 0.7216\n",
            "Epoch 640: loss improved from 2.30773 to 2.30765, saving model to ./model_PID__0640_loss_2.308_vloss_0.337_acc_0.722_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 2.3076 - MAE: 0.7216 - val_loss: 0.3372 - val_MAE: 0.3851 - lr: 0.0010\n",
            "\n",
            "Epoch 641: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 641/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3076 - MAE: 0.7216\n",
            "Epoch 641: loss improved from 2.30765 to 2.30757, saving model to ./model_PID__0641_loss_2.308_vloss_0.337_acc_0.722_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 2.3076 - MAE: 0.7216 - val_loss: 0.3373 - val_MAE: 0.3851 - lr: 0.0010\n",
            "\n",
            "Epoch 642: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 642/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3075 - MAE: 0.7215\n",
            "Epoch 642: loss improved from 2.30757 to 2.30749, saving model to ./model_PID__0642_loss_2.307_vloss_0.337_acc_0.722_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 2.3075 - MAE: 0.7215 - val_loss: 0.3373 - val_MAE: 0.3851 - lr: 0.0010\n",
            "\n",
            "Epoch 643: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 643/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3074 - MAE: 0.7215\n",
            "Epoch 643: loss improved from 2.30749 to 2.30741, saving model to ./model_PID__0643_loss_2.307_vloss_0.337_acc_0.722_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 2.3074 - MAE: 0.7215 - val_loss: 0.3373 - val_MAE: 0.3851 - lr: 0.0010\n",
            "\n",
            "Epoch 644: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 644/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3073 - MAE: 0.7215\n",
            "Epoch 644: loss improved from 2.30741 to 2.30733, saving model to ./model_PID__0644_loss_2.307_vloss_0.337_acc_0.721_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.3073 - MAE: 0.7215 - val_loss: 0.3374 - val_MAE: 0.3851 - lr: 0.0010\n",
            "\n",
            "Epoch 645: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 645/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3073 - MAE: 0.7214\n",
            "Epoch 645: loss improved from 2.30733 to 2.30726, saving model to ./model_PID__0645_loss_2.307_vloss_0.337_acc_0.721_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 2.3073 - MAE: 0.7214 - val_loss: 0.3374 - val_MAE: 0.3851 - lr: 0.0010\n",
            "\n",
            "Epoch 646: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 646/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3072 - MAE: 0.7214\n",
            "Epoch 646: loss improved from 2.30726 to 2.30719, saving model to ./model_PID__0646_loss_2.307_vloss_0.337_acc_0.721_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.3072 - MAE: 0.7214 - val_loss: 0.3374 - val_MAE: 0.3851 - lr: 0.0010\n",
            "\n",
            "Epoch 647: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 647/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3071 - MAE: 0.7213\n",
            "Epoch 647: loss improved from 2.30719 to 2.30712, saving model to ./model_PID__0647_loss_2.307_vloss_0.337_acc_0.721_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2.3071 - MAE: 0.7213 - val_loss: 0.3374 - val_MAE: 0.3850 - lr: 0.0010\n",
            "\n",
            "Epoch 648: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 648/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3071 - MAE: 0.7213\n",
            "Epoch 648: loss improved from 2.30712 to 2.30705, saving model to ./model_PID__0648_loss_2.307_vloss_0.337_acc_0.721_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 2.3071 - MAE: 0.7213 - val_loss: 0.3375 - val_MAE: 0.3850 - lr: 0.0010\n",
            "\n",
            "Epoch 649: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 649/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3070 - MAE: 0.7212\n",
            "Epoch 649: loss improved from 2.30705 to 2.30698, saving model to ./model_PID__0649_loss_2.307_vloss_0.337_acc_0.721_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 2.3070 - MAE: 0.7212 - val_loss: 0.3375 - val_MAE: 0.3850 - lr: 0.0010\n",
            "\n",
            "Epoch 650: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 650/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3069 - MAE: 0.7212\n",
            "Epoch 650: loss improved from 2.30698 to 2.30692, saving model to ./model_PID__0650_loss_2.307_vloss_0.338_acc_0.721_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 2.3069 - MAE: 0.7212 - val_loss: 0.3375 - val_MAE: 0.3850 - lr: 0.0010\n",
            "\n",
            "Epoch 651: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 651/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3069 - MAE: 0.7211\n",
            "Epoch 651: loss improved from 2.30692 to 2.30686, saving model to ./model_PID__0651_loss_2.307_vloss_0.338_acc_0.721_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2.3069 - MAE: 0.7211 - val_loss: 0.3375 - val_MAE: 0.3850 - lr: 0.0010\n",
            "\n",
            "Epoch 652: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 652/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3068 - MAE: 0.7211\n",
            "Epoch 652: loss improved from 2.30686 to 2.30680, saving model to ./model_PID__0652_loss_2.307_vloss_0.338_acc_0.721_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 2.3068 - MAE: 0.7211 - val_loss: 0.3376 - val_MAE: 0.3850 - lr: 0.0010\n",
            "\n",
            "Epoch 653: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 653/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3067 - MAE: 0.7210\n",
            "Epoch 653: loss improved from 2.30680 to 2.30674, saving model to ./model_PID__0653_loss_2.307_vloss_0.338_acc_0.721_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 2.3067 - MAE: 0.7210 - val_loss: 0.3376 - val_MAE: 0.3850 - lr: 0.0010\n",
            "\n",
            "Epoch 654: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 654/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3067 - MAE: 0.7210\n",
            "Epoch 654: loss improved from 2.30674 to 2.30668, saving model to ./model_PID__0654_loss_2.307_vloss_0.338_acc_0.721_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 2.3067 - MAE: 0.7210 - val_loss: 0.3376 - val_MAE: 0.3850 - lr: 0.0010\n",
            "\n",
            "Epoch 655: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 655/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3066 - MAE: 0.7210\n",
            "Epoch 655: loss improved from 2.30668 to 2.30662, saving model to ./model_PID__0655_loss_2.307_vloss_0.338_acc_0.721_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 2.3066 - MAE: 0.7210 - val_loss: 0.3377 - val_MAE: 0.3850 - lr: 0.0010\n",
            "\n",
            "Epoch 656: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 656/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3066 - MAE: 0.7209\n",
            "Epoch 656: loss improved from 2.30662 to 2.30656, saving model to ./model_PID__0656_loss_2.307_vloss_0.338_acc_0.721_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.3066 - MAE: 0.7209 - val_loss: 0.3377 - val_MAE: 0.3850 - lr: 0.0010\n",
            "\n",
            "Epoch 657: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 657/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3065 - MAE: 0.7209\n",
            "Epoch 657: loss improved from 2.30656 to 2.30651, saving model to ./model_PID__0657_loss_2.307_vloss_0.338_acc_0.721_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 2.3065 - MAE: 0.7209 - val_loss: 0.3377 - val_MAE: 0.3849 - lr: 0.0010\n",
            "\n",
            "Epoch 658: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 658/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3065 - MAE: 0.7208\n",
            "Epoch 658: loss improved from 2.30651 to 2.30645, saving model to ./model_PID__0658_loss_2.306_vloss_0.338_acc_0.721_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 2.3065 - MAE: 0.7208 - val_loss: 0.3377 - val_MAE: 0.3849 - lr: 0.0010\n",
            "\n",
            "Epoch 659: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 659/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3064 - MAE: 0.7208\n",
            "Epoch 659: loss improved from 2.30645 to 2.30640, saving model to ./model_PID__0659_loss_2.306_vloss_0.338_acc_0.721_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 2.3064 - MAE: 0.7208 - val_loss: 0.3378 - val_MAE: 0.3849 - lr: 0.0010\n",
            "\n",
            "Epoch 660: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 660/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3063 - MAE: 0.7207\n",
            "Epoch 660: loss improved from 2.30640 to 2.30634, saving model to ./model_PID__0660_loss_2.306_vloss_0.338_acc_0.721_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 2.3063 - MAE: 0.7207 - val_loss: 0.3378 - val_MAE: 0.3849 - lr: 0.0010\n",
            "\n",
            "Epoch 661: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 661/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3063 - MAE: 0.7207\n",
            "Epoch 661: loss improved from 2.30634 to 2.30629, saving model to ./model_PID__0661_loss_2.306_vloss_0.338_acc_0.721_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 2.3063 - MAE: 0.7207 - val_loss: 0.3378 - val_MAE: 0.3849 - lr: 0.0010\n",
            "\n",
            "Epoch 662: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 662/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3062 - MAE: 0.7206\n",
            "Epoch 662: loss improved from 2.30629 to 2.30624, saving model to ./model_PID__0662_loss_2.306_vloss_0.338_acc_0.721_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 2.3062 - MAE: 0.7206 - val_loss: 0.3378 - val_MAE: 0.3849 - lr: 0.0010\n",
            "\n",
            "Epoch 663: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 663/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3062 - MAE: 0.7206\n",
            "Epoch 663: loss improved from 2.30624 to 2.30619, saving model to ./model_PID__0663_loss_2.306_vloss_0.338_acc_0.721_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 2.3062 - MAE: 0.7206 - val_loss: 0.3379 - val_MAE: 0.3849 - lr: 0.0010\n",
            "\n",
            "Epoch 664: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 664/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3061 - MAE: 0.7205\n",
            "Epoch 664: loss improved from 2.30619 to 2.30614, saving model to ./model_PID__0664_loss_2.306_vloss_0.338_acc_0.721_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 2.3061 - MAE: 0.7205 - val_loss: 0.3379 - val_MAE: 0.3849 - lr: 0.0010\n",
            "\n",
            "Epoch 665: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 665/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3061 - MAE: 0.7205\n",
            "Epoch 665: loss improved from 2.30614 to 2.30609, saving model to ./model_PID__0665_loss_2.306_vloss_0.338_acc_0.720_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 2.3061 - MAE: 0.7205 - val_loss: 0.3379 - val_MAE: 0.3849 - lr: 0.0010\n",
            "\n",
            "Epoch 666: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 666/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3060 - MAE: 0.7204\n",
            "Epoch 666: loss improved from 2.30609 to 2.30604, saving model to ./model_PID__0666_loss_2.306_vloss_0.338_acc_0.720_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 2.3060 - MAE: 0.7204 - val_loss: 0.3380 - val_MAE: 0.3849 - lr: 0.0010\n",
            "\n",
            "Epoch 667: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 667/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3060 - MAE: 0.7204\n",
            "Epoch 667: loss improved from 2.30604 to 2.30599, saving model to ./model_PID__0667_loss_2.306_vloss_0.338_acc_0.720_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 2.3060 - MAE: 0.7204 - val_loss: 0.3380 - val_MAE: 0.3849 - lr: 0.0010\n",
            "\n",
            "Epoch 668: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 668/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3059 - MAE: 0.7203\n",
            "Epoch 668: loss improved from 2.30599 to 2.30595, saving model to ./model_PID__0668_loss_2.306_vloss_0.338_acc_0.720_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 2.3059 - MAE: 0.7203 - val_loss: 0.3380 - val_MAE: 0.3848 - lr: 0.0010\n",
            "\n",
            "Epoch 669: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 669/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3059 - MAE: 0.7203\n",
            "Epoch 669: loss improved from 2.30595 to 2.30590, saving model to ./model_PID__0669_loss_2.306_vloss_0.338_acc_0.720_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 2.3059 - MAE: 0.7203 - val_loss: 0.3380 - val_MAE: 0.3848 - lr: 0.0010\n",
            "\n",
            "Epoch 670: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 670/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3059 - MAE: 0.7203\n",
            "Epoch 670: loss improved from 2.30590 to 2.30585, saving model to ./model_PID__0670_loss_2.306_vloss_0.338_acc_0.720_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 2.3059 - MAE: 0.7203 - val_loss: 0.3381 - val_MAE: 0.3848 - lr: 0.0010\n",
            "\n",
            "Epoch 671: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 671/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3058 - MAE: 0.7202\n",
            "Epoch 671: loss improved from 2.30585 to 2.30581, saving model to ./model_PID__0671_loss_2.306_vloss_0.338_acc_0.720_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 2.3058 - MAE: 0.7202 - val_loss: 0.3381 - val_MAE: 0.3848 - lr: 0.0010\n",
            "\n",
            "Epoch 672: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 672/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3058 - MAE: 0.7202\n",
            "Epoch 672: loss improved from 2.30581 to 2.30576, saving model to ./model_PID__0672_loss_2.306_vloss_0.338_acc_0.720_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 2.3058 - MAE: 0.7202 - val_loss: 0.3381 - val_MAE: 0.3848 - lr: 0.0010\n",
            "\n",
            "Epoch 673: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 673/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3057 - MAE: 0.7201\n",
            "Epoch 673: loss improved from 2.30576 to 2.30572, saving model to ./model_PID__0673_loss_2.306_vloss_0.338_acc_0.720_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.3057 - MAE: 0.7201 - val_loss: 0.3382 - val_MAE: 0.3848 - lr: 0.0010\n",
            "\n",
            "Epoch 674: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 674/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3057 - MAE: 0.7201\n",
            "Epoch 674: loss improved from 2.30572 to 2.30567, saving model to ./model_PID__0674_loss_2.306_vloss_0.338_acc_0.720_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 2.3057 - MAE: 0.7201 - val_loss: 0.3382 - val_MAE: 0.3848 - lr: 0.0010\n",
            "\n",
            "Epoch 675: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 675/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3056 - MAE: 0.7200\n",
            "Epoch 675: loss improved from 2.30567 to 2.30563, saving model to ./model_PID__0675_loss_2.306_vloss_0.338_acc_0.720_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 2.3056 - MAE: 0.7200 - val_loss: 0.3382 - val_MAE: 0.3848 - lr: 0.0010\n",
            "\n",
            "Epoch 676: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 676/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3056 - MAE: 0.7200\n",
            "Epoch 676: loss improved from 2.30563 to 2.30559, saving model to ./model_PID__0676_loss_2.306_vloss_0.338_acc_0.720_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 2.3056 - MAE: 0.7200 - val_loss: 0.3382 - val_MAE: 0.3848 - lr: 0.0010\n",
            "\n",
            "Epoch 677: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 677/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3055 - MAE: 0.7199\n",
            "Epoch 677: loss improved from 2.30559 to 2.30554, saving model to ./model_PID__0677_loss_2.306_vloss_0.338_acc_0.720_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 2.3055 - MAE: 0.7199 - val_loss: 0.3383 - val_MAE: 0.3847 - lr: 0.0010\n",
            "\n",
            "Epoch 678: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 678/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3055 - MAE: 0.7199\n",
            "Epoch 678: loss improved from 2.30554 to 2.30550, saving model to ./model_PID__0678_loss_2.306_vloss_0.338_acc_0.720_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2.3055 - MAE: 0.7199 - val_loss: 0.3383 - val_MAE: 0.3847 - lr: 0.0010\n",
            "\n",
            "Epoch 679: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 679/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3055 - MAE: 0.7199\n",
            "Epoch 679: loss improved from 2.30550 to 2.30546, saving model to ./model_PID__0679_loss_2.305_vloss_0.338_acc_0.720_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 2.3055 - MAE: 0.7199 - val_loss: 0.3383 - val_MAE: 0.3847 - lr: 0.0010\n",
            "\n",
            "Epoch 680: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 680/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3054 - MAE: 0.7198\n",
            "Epoch 680: loss improved from 2.30546 to 2.30542, saving model to ./model_PID__0680_loss_2.305_vloss_0.338_acc_0.720_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.3054 - MAE: 0.7198 - val_loss: 0.3383 - val_MAE: 0.3847 - lr: 0.0010\n",
            "\n",
            "Epoch 681: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 681/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3054 - MAE: 0.7198\n",
            "Epoch 681: loss improved from 2.30542 to 2.30538, saving model to ./model_PID__0681_loss_2.305_vloss_0.338_acc_0.720_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 2.3054 - MAE: 0.7198 - val_loss: 0.3383 - val_MAE: 0.3847 - lr: 0.0010\n",
            "\n",
            "Epoch 682: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 682/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3053 - MAE: 0.7197\n",
            "Epoch 682: loss improved from 2.30538 to 2.30533, saving model to ./model_PID__0682_loss_2.305_vloss_0.338_acc_0.720_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 2.3053 - MAE: 0.7197 - val_loss: 0.3384 - val_MAE: 0.3847 - lr: 0.0010\n",
            "\n",
            "Epoch 683: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 683/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3053 - MAE: 0.7197\n",
            "Epoch 683: loss improved from 2.30533 to 2.30529, saving model to ./model_PID__0683_loss_2.305_vloss_0.338_acc_0.720_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 2.3053 - MAE: 0.7197 - val_loss: 0.3384 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 684: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 684/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3053 - MAE: 0.7196\n",
            "Epoch 684: loss improved from 2.30529 to 2.30525, saving model to ./model_PID__0684_loss_2.305_vloss_0.338_acc_0.720_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 2.3053 - MAE: 0.7196 - val_loss: 0.3384 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 685: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 685/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3052 - MAE: 0.7196\n",
            "Epoch 685: loss improved from 2.30525 to 2.30521, saving model to ./model_PID__0685_loss_2.305_vloss_0.338_acc_0.720_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 2.3052 - MAE: 0.7196 - val_loss: 0.3384 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 686: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 686/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3052 - MAE: 0.7196\n",
            "Epoch 686: loss improved from 2.30521 to 2.30517, saving model to ./model_PID__0686_loss_2.305_vloss_0.338_acc_0.720_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 2.3052 - MAE: 0.7196 - val_loss: 0.3385 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 687: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 687/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3051 - MAE: 0.7195\n",
            "Epoch 687: loss improved from 2.30517 to 2.30513, saving model to ./model_PID__0687_loss_2.305_vloss_0.338_acc_0.720_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 2.3051 - MAE: 0.7195 - val_loss: 0.3385 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 688: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 688/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3051 - MAE: 0.7195\n",
            "Epoch 688: loss improved from 2.30513 to 2.30509, saving model to ./model_PID__0688_loss_2.305_vloss_0.339_acc_0.719_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 2.3051 - MAE: 0.7195 - val_loss: 0.3385 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 689: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 689/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3051 - MAE: 0.7194\n",
            "Epoch 689: loss improved from 2.30509 to 2.30505, saving model to ./model_PID__0689_loss_2.305_vloss_0.339_acc_0.719_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 2.3051 - MAE: 0.7194 - val_loss: 0.3385 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 690: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 690/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3050 - MAE: 0.7194\n",
            "Epoch 690: loss improved from 2.30505 to 2.30501, saving model to ./model_PID__0690_loss_2.305_vloss_0.339_acc_0.719_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 2.3050 - MAE: 0.7194 - val_loss: 0.3386 - val_MAE: 0.3845 - lr: 0.0010\n",
            "\n",
            "Epoch 691: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 691/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3050 - MAE: 0.7194\n",
            "Epoch 691: loss improved from 2.30501 to 2.30497, saving model to ./model_PID__0691_loss_2.305_vloss_0.339_acc_0.719_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 2.3050 - MAE: 0.7194 - val_loss: 0.3386 - val_MAE: 0.3845 - lr: 0.0010\n",
            "\n",
            "Epoch 692: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 692/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3049 - MAE: 0.7193\n",
            "Epoch 692: loss improved from 2.30497 to 2.30493, saving model to ./model_PID__0692_loss_2.305_vloss_0.339_acc_0.719_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 2.3049 - MAE: 0.7193 - val_loss: 0.3386 - val_MAE: 0.3845 - lr: 0.0010\n",
            "\n",
            "Epoch 693: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 693/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3049 - MAE: 0.7193\n",
            "Epoch 693: loss improved from 2.30493 to 2.30489, saving model to ./model_PID__0693_loss_2.305_vloss_0.339_acc_0.719_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.3049 - MAE: 0.7193 - val_loss: 0.3386 - val_MAE: 0.3845 - lr: 0.0010\n",
            "\n",
            "Epoch 694: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 694/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3049 - MAE: 0.7192\n",
            "Epoch 694: loss improved from 2.30489 to 2.30485, saving model to ./model_PID__0694_loss_2.305_vloss_0.339_acc_0.719_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.3049 - MAE: 0.7192 - val_loss: 0.3387 - val_MAE: 0.3845 - lr: 0.0010\n",
            "\n",
            "Epoch 695: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 695/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3048 - MAE: 0.7192\n",
            "Epoch 695: loss improved from 2.30485 to 2.30481, saving model to ./model_PID__0695_loss_2.305_vloss_0.339_acc_0.719_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 2.3048 - MAE: 0.7192 - val_loss: 0.3387 - val_MAE: 0.3845 - lr: 0.0010\n",
            "\n",
            "Epoch 696: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 696/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3048 - MAE: 0.7191\n",
            "Epoch 696: loss improved from 2.30481 to 2.30477, saving model to ./model_PID__0696_loss_2.305_vloss_0.339_acc_0.719_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.3048 - MAE: 0.7191 - val_loss: 0.3387 - val_MAE: 0.3845 - lr: 0.0010\n",
            "\n",
            "Epoch 697: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 697/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3047 - MAE: 0.7191\n",
            "Epoch 697: loss improved from 2.30477 to 2.30473, saving model to ./model_PID__0697_loss_2.305_vloss_0.339_acc_0.719_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 2.3047 - MAE: 0.7191 - val_loss: 0.3387 - val_MAE: 0.3844 - lr: 0.0010\n",
            "\n",
            "Epoch 698: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 698/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3047 - MAE: 0.7191\n",
            "Epoch 698: loss improved from 2.30473 to 2.30470, saving model to ./model_PID__0698_loss_2.305_vloss_0.339_acc_0.719_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 2.3047 - MAE: 0.7191 - val_loss: 0.3387 - val_MAE: 0.3844 - lr: 0.0010\n",
            "\n",
            "Epoch 699: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 699/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3047 - MAE: 0.7190\n",
            "Epoch 699: loss improved from 2.30470 to 2.30466, saving model to ./model_PID__0699_loss_2.305_vloss_0.339_acc_0.719_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 2.3047 - MAE: 0.7190 - val_loss: 0.3388 - val_MAE: 0.3844 - lr: 0.0010\n",
            "\n",
            "Epoch 700: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 700/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3046 - MAE: 0.7190\n",
            "Epoch 700: loss improved from 2.30466 to 2.30462, saving model to ./model_PID__0700_loss_2.305_vloss_0.339_acc_0.719_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.3046 - MAE: 0.7190 - val_loss: 0.3388 - val_MAE: 0.3844 - lr: 0.0010\n",
            "\n",
            "Epoch 701: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 701/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3046 - MAE: 0.7190\n",
            "Epoch 701: loss improved from 2.30462 to 2.30458, saving model to ./model_PID__0701_loss_2.305_vloss_0.339_acc_0.719_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.3046 - MAE: 0.7190 - val_loss: 0.3388 - val_MAE: 0.3844 - lr: 0.0010\n",
            "\n",
            "Epoch 702: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 702/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3045 - MAE: 0.7189\n",
            "Epoch 702: loss improved from 2.30458 to 2.30454, saving model to ./model_PID__0702_loss_2.305_vloss_0.339_acc_0.719_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 2.3045 - MAE: 0.7189 - val_loss: 0.3388 - val_MAE: 0.3844 - lr: 0.0010\n",
            "\n",
            "Epoch 703: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 703/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3045 - MAE: 0.7189\n",
            "Epoch 703: loss improved from 2.30454 to 2.30450, saving model to ./model_PID__0703_loss_2.305_vloss_0.339_acc_0.719_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 2.3045 - MAE: 0.7189 - val_loss: 0.3389 - val_MAE: 0.3844 - lr: 0.0010\n",
            "\n",
            "Epoch 704: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 704/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3045 - MAE: 0.7188\n",
            "Epoch 704: loss improved from 2.30450 to 2.30446, saving model to ./model_PID__0704_loss_2.304_vloss_0.339_acc_0.719_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2.3045 - MAE: 0.7188 - val_loss: 0.3389 - val_MAE: 0.3843 - lr: 0.0010\n",
            "\n",
            "Epoch 705: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 705/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3044 - MAE: 0.7188\n",
            "Epoch 705: loss improved from 2.30446 to 2.30442, saving model to ./model_PID__0705_loss_2.304_vloss_0.339_acc_0.719_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 2.3044 - MAE: 0.7188 - val_loss: 0.3389 - val_MAE: 0.3843 - lr: 0.0010\n",
            "\n",
            "Epoch 706: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 706/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3044 - MAE: 0.7188\n",
            "Epoch 706: loss improved from 2.30442 to 2.30439, saving model to ./model_PID__0706_loss_2.304_vloss_0.339_acc_0.719_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 2.3044 - MAE: 0.7188 - val_loss: 0.3389 - val_MAE: 0.3843 - lr: 0.0010\n",
            "\n",
            "Epoch 707: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 707/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3043 - MAE: 0.7187\n",
            "Epoch 707: loss improved from 2.30439 to 2.30435, saving model to ./model_PID__0707_loss_2.304_vloss_0.339_acc_0.719_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.3043 - MAE: 0.7187 - val_loss: 0.3389 - val_MAE: 0.3843 - lr: 0.0010\n",
            "\n",
            "Epoch 708: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 708/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3043 - MAE: 0.7187\n",
            "Epoch 708: loss improved from 2.30435 to 2.30431, saving model to ./model_PID__0708_loss_2.304_vloss_0.339_acc_0.719_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.3043 - MAE: 0.7187 - val_loss: 0.3390 - val_MAE: 0.3843 - lr: 0.0010\n",
            "\n",
            "Epoch 709: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 709/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3043 - MAE: 0.7187\n",
            "Epoch 709: loss improved from 2.30431 to 2.30427, saving model to ./model_PID__0709_loss_2.304_vloss_0.339_acc_0.719_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.3043 - MAE: 0.7187 - val_loss: 0.3390 - val_MAE: 0.3843 - lr: 0.0010\n",
            "\n",
            "Epoch 710: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 710/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3042 - MAE: 0.7186\n",
            "Epoch 710: loss improved from 2.30427 to 2.30423, saving model to ./model_PID__0710_loss_2.304_vloss_0.339_acc_0.719_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 2.3042 - MAE: 0.7186 - val_loss: 0.3390 - val_MAE: 0.3843 - lr: 0.0010\n",
            "\n",
            "Epoch 711: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 711/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3042 - MAE: 0.7186\n",
            "Epoch 711: loss improved from 2.30423 to 2.30419, saving model to ./model_PID__0711_loss_2.304_vloss_0.339_acc_0.719_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.3042 - MAE: 0.7186 - val_loss: 0.3390 - val_MAE: 0.3842 - lr: 0.0010\n",
            "\n",
            "Epoch 712: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 712/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3042 - MAE: 0.7186\n",
            "Epoch 712: loss improved from 2.30419 to 2.30416, saving model to ./model_PID__0712_loss_2.304_vloss_0.339_acc_0.719_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 2.3042 - MAE: 0.7186 - val_loss: 0.3390 - val_MAE: 0.3842 - lr: 0.0010\n",
            "\n",
            "Epoch 713: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 713/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3041 - MAE: 0.7185\n",
            "Epoch 713: loss improved from 2.30416 to 2.30412, saving model to ./model_PID__0713_loss_2.304_vloss_0.339_acc_0.719_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 2.3041 - MAE: 0.7185 - val_loss: 0.3391 - val_MAE: 0.3842 - lr: 0.0010\n",
            "\n",
            "Epoch 714: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 714/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3041 - MAE: 0.7185\n",
            "Epoch 714: loss improved from 2.30412 to 2.30408, saving model to ./model_PID__0714_loss_2.304_vloss_0.339_acc_0.718_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 2.3041 - MAE: 0.7185 - val_loss: 0.3391 - val_MAE: 0.3842 - lr: 0.0010\n",
            "\n",
            "Epoch 715: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 715/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3040 - MAE: 0.7184\n",
            "Epoch 715: loss improved from 2.30408 to 2.30404, saving model to ./model_PID__0715_loss_2.304_vloss_0.339_acc_0.718_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 2.3040 - MAE: 0.7184 - val_loss: 0.3391 - val_MAE: 0.3842 - lr: 0.0010\n",
            "\n",
            "Epoch 716: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 716/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3040 - MAE: 0.7184\n",
            "Epoch 716: loss improved from 2.30404 to 2.30401, saving model to ./model_PID__0716_loss_2.304_vloss_0.339_acc_0.718_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 2.3040 - MAE: 0.7184 - val_loss: 0.3391 - val_MAE: 0.3842 - lr: 0.0010\n",
            "\n",
            "Epoch 717: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 717/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3040 - MAE: 0.7184\n",
            "Epoch 717: loss improved from 2.30401 to 2.30397, saving model to ./model_PID__0717_loss_2.304_vloss_0.339_acc_0.718_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 2.3040 - MAE: 0.7184 - val_loss: 0.3391 - val_MAE: 0.3842 - lr: 0.0010\n",
            "\n",
            "Epoch 718: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 718/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3039 - MAE: 0.7183\n",
            "Epoch 718: loss improved from 2.30397 to 2.30393, saving model to ./model_PID__0718_loss_2.304_vloss_0.339_acc_0.718_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.3039 - MAE: 0.7183 - val_loss: 0.3392 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 719: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 719/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3039 - MAE: 0.7183\n",
            "Epoch 719: loss improved from 2.30393 to 2.30390, saving model to ./model_PID__0719_loss_2.304_vloss_0.339_acc_0.718_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 2.3039 - MAE: 0.7183 - val_loss: 0.3392 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 720: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 720/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3039 - MAE: 0.7183\n",
            "Epoch 720: loss improved from 2.30390 to 2.30386, saving model to ./model_PID__0720_loss_2.304_vloss_0.339_acc_0.718_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 2.3039 - MAE: 0.7183 - val_loss: 0.3392 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 721: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 721/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3038 - MAE: 0.7182\n",
            "Epoch 721: loss improved from 2.30386 to 2.30382, saving model to ./model_PID__0721_loss_2.304_vloss_0.339_acc_0.718_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 2.3038 - MAE: 0.7182 - val_loss: 0.3392 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 722: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 722/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3038 - MAE: 0.7182\n",
            "Epoch 722: loss improved from 2.30382 to 2.30379, saving model to ./model_PID__0722_loss_2.304_vloss_0.339_acc_0.718_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 2.3038 - MAE: 0.7182 - val_loss: 0.3392 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 723: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 723/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3037 - MAE: 0.7182\n",
            "Epoch 723: loss improved from 2.30379 to 2.30375, saving model to ./model_PID__0723_loss_2.304_vloss_0.339_acc_0.718_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 2.3037 - MAE: 0.7182 - val_loss: 0.3393 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 724: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 724/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3037 - MAE: 0.7181\n",
            "Epoch 724: loss improved from 2.30375 to 2.30371, saving model to ./model_PID__0724_loss_2.304_vloss_0.339_acc_0.718_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 2.3037 - MAE: 0.7181 - val_loss: 0.3393 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 725: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 725/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3037 - MAE: 0.7181\n",
            "Epoch 725: loss improved from 2.30371 to 2.30368, saving model to ./model_PID__0725_loss_2.304_vloss_0.339_acc_0.718_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 2.3037 - MAE: 0.7181 - val_loss: 0.3393 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 726: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 726/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3036 - MAE: 0.7181\n",
            "Epoch 726: loss improved from 2.30368 to 2.30364, saving model to ./model_PID__0726_loss_2.304_vloss_0.339_acc_0.718_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 2.3036 - MAE: 0.7181 - val_loss: 0.3393 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 727: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 727/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3036 - MAE: 0.7180\n",
            "Epoch 727: loss improved from 2.30364 to 2.30360, saving model to ./model_PID__0727_loss_2.304_vloss_0.339_acc_0.718_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.3036 - MAE: 0.7180 - val_loss: 0.3393 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 728: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 728/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3036 - MAE: 0.7180\n",
            "Epoch 728: loss improved from 2.30360 to 2.30357, saving model to ./model_PID__0728_loss_2.304_vloss_0.339_acc_0.718_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 2.3036 - MAE: 0.7180 - val_loss: 0.3394 - val_MAE: 0.3840 - lr: 0.0010\n",
            "\n",
            "Epoch 729: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 729/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3035 - MAE: 0.7180\n",
            "Epoch 729: loss improved from 2.30357 to 2.30353, saving model to ./model_PID__0729_loss_2.304_vloss_0.339_acc_0.718_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 2.3035 - MAE: 0.7180 - val_loss: 0.3394 - val_MAE: 0.3840 - lr: 0.0010\n",
            "\n",
            "Epoch 730: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 730/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3035 - MAE: 0.7179\n",
            "Epoch 730: loss improved from 2.30353 to 2.30349, saving model to ./model_PID__0730_loss_2.303_vloss_0.339_acc_0.718_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 2.3035 - MAE: 0.7179 - val_loss: 0.3394 - val_MAE: 0.3840 - lr: 0.0010\n",
            "\n",
            "Epoch 731: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 731/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3035 - MAE: 0.7179\n",
            "Epoch 731: loss improved from 2.30349 to 2.30346, saving model to ./model_PID__0731_loss_2.303_vloss_0.339_acc_0.718_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 2.3035 - MAE: 0.7179 - val_loss: 0.3394 - val_MAE: 0.3840 - lr: 0.0010\n",
            "\n",
            "Epoch 732: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 732/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3034 - MAE: 0.7179\n",
            "Epoch 732: loss improved from 2.30346 to 2.30342, saving model to ./model_PID__0732_loss_2.303_vloss_0.339_acc_0.718_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 2.3034 - MAE: 0.7179 - val_loss: 0.3394 - val_MAE: 0.3840 - lr: 0.0010\n",
            "\n",
            "Epoch 733: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 733/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3034 - MAE: 0.7178\n",
            "Epoch 733: loss improved from 2.30342 to 2.30339, saving model to ./model_PID__0733_loss_2.303_vloss_0.339_acc_0.718_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 2.3034 - MAE: 0.7178 - val_loss: 0.3395 - val_MAE: 0.3840 - lr: 0.0010\n",
            "\n",
            "Epoch 734: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 734/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3033 - MAE: 0.7178\n",
            "Epoch 734: loss improved from 2.30339 to 2.30335, saving model to ./model_PID__0734_loss_2.303_vloss_0.339_acc_0.718_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 2.3033 - MAE: 0.7178 - val_loss: 0.3395 - val_MAE: 0.3840 - lr: 0.0010\n",
            "\n",
            "Epoch 735: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 735/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3033 - MAE: 0.7178\n",
            "Epoch 735: loss improved from 2.30335 to 2.30331, saving model to ./model_PID__0735_loss_2.303_vloss_0.340_acc_0.718_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 2.3033 - MAE: 0.7178 - val_loss: 0.3395 - val_MAE: 0.3840 - lr: 0.0010\n",
            "\n",
            "Epoch 736: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 736/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3033 - MAE: 0.7177\n",
            "Epoch 736: loss improved from 2.30331 to 2.30328, saving model to ./model_PID__0736_loss_2.303_vloss_0.340_acc_0.718_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 2.3033 - MAE: 0.7177 - val_loss: 0.3395 - val_MAE: 0.3840 - lr: 0.0010\n",
            "\n",
            "Epoch 737: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 737/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3032 - MAE: 0.7177\n",
            "Epoch 737: loss improved from 2.30328 to 2.30324, saving model to ./model_PID__0737_loss_2.303_vloss_0.340_acc_0.718_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 2.3032 - MAE: 0.7177 - val_loss: 0.3395 - val_MAE: 0.3840 - lr: 0.0010\n",
            "\n",
            "Epoch 738: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 738/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3032 - MAE: 0.7177\n",
            "Epoch 738: loss improved from 2.30324 to 2.30320, saving model to ./model_PID__0738_loss_2.303_vloss_0.340_acc_0.718_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2.3032 - MAE: 0.7177 - val_loss: 0.3396 - val_MAE: 0.3840 - lr: 0.0010\n",
            "\n",
            "Epoch 739: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 739/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3032 - MAE: 0.7176\n",
            "Epoch 739: loss improved from 2.30320 to 2.30317, saving model to ./model_PID__0739_loss_2.303_vloss_0.340_acc_0.718_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 2.3032 - MAE: 0.7176 - val_loss: 0.3396 - val_MAE: 0.3840 - lr: 0.0010\n",
            "\n",
            "Epoch 740: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 740/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3031 - MAE: 0.7176\n",
            "Epoch 740: loss improved from 2.30317 to 2.30313, saving model to ./model_PID__0740_loss_2.303_vloss_0.340_acc_0.718_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 2.3031 - MAE: 0.7176 - val_loss: 0.3396 - val_MAE: 0.3840 - lr: 0.0010\n",
            "\n",
            "Epoch 741: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 741/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3031 - MAE: 0.7176\n",
            "Epoch 741: loss improved from 2.30313 to 2.30309, saving model to ./model_PID__0741_loss_2.303_vloss_0.340_acc_0.718_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.3031 - MAE: 0.7176 - val_loss: 0.3396 - val_MAE: 0.3840 - lr: 0.0010\n",
            "\n",
            "Epoch 742: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 742/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3031 - MAE: 0.7175\n",
            "Epoch 742: loss improved from 2.30309 to 2.30305, saving model to ./model_PID__0742_loss_2.303_vloss_0.340_acc_0.718_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 2.3031 - MAE: 0.7175 - val_loss: 0.3397 - val_MAE: 0.3840 - lr: 0.0010\n",
            "\n",
            "Epoch 743: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 743/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3030 - MAE: 0.7175\n",
            "Epoch 743: loss improved from 2.30305 to 2.30302, saving model to ./model_PID__0743_loss_2.303_vloss_0.340_acc_0.718_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 2.3030 - MAE: 0.7175 - val_loss: 0.3397 - val_MAE: 0.3840 - lr: 0.0010\n",
            "\n",
            "Epoch 744: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 744/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3030 - MAE: 0.7175\n",
            "Epoch 744: loss improved from 2.30302 to 2.30298, saving model to ./model_PID__0744_loss_2.303_vloss_0.340_acc_0.717_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.3030 - MAE: 0.7175 - val_loss: 0.3397 - val_MAE: 0.3840 - lr: 0.0010\n",
            "\n",
            "Epoch 745: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 745/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3029 - MAE: 0.7175\n",
            "Epoch 745: loss improved from 2.30298 to 2.30294, saving model to ./model_PID__0745_loss_2.303_vloss_0.340_acc_0.717_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 2.3029 - MAE: 0.7175 - val_loss: 0.3397 - val_MAE: 0.3840 - lr: 0.0010\n",
            "\n",
            "Epoch 746: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 746/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3029 - MAE: 0.7174\n",
            "Epoch 746: loss improved from 2.30294 to 2.30290, saving model to ./model_PID__0746_loss_2.303_vloss_0.340_acc_0.717_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 2.3029 - MAE: 0.7174 - val_loss: 0.3397 - val_MAE: 0.3840 - lr: 0.0010\n",
            "\n",
            "Epoch 747: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 747/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3029 - MAE: 0.7174\n",
            "Epoch 747: loss improved from 2.30290 to 2.30286, saving model to ./model_PID__0747_loss_2.303_vloss_0.340_acc_0.717_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 2.3029 - MAE: 0.7174 - val_loss: 0.3398 - val_MAE: 0.3840 - lr: 0.0010\n",
            "\n",
            "Epoch 748: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 748/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3028 - MAE: 0.7174\n",
            "Epoch 748: loss improved from 2.30286 to 2.30281, saving model to ./model_PID__0748_loss_2.303_vloss_0.340_acc_0.717_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.3028 - MAE: 0.7174 - val_loss: 0.3398 - val_MAE: 0.3840 - lr: 0.0010\n",
            "\n",
            "Epoch 749: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 749/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3028 - MAE: 0.7173\n",
            "Epoch 749: loss improved from 2.30281 to 2.30277, saving model to ./model_PID__0749_loss_2.303_vloss_0.340_acc_0.717_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 2.3028 - MAE: 0.7173 - val_loss: 0.3398 - val_MAE: 0.3840 - lr: 0.0010\n",
            "\n",
            "Epoch 750: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 750/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3027 - MAE: 0.7173\n",
            "Epoch 750: loss improved from 2.30277 to 2.30273, saving model to ./model_PID__0750_loss_2.303_vloss_0.340_acc_0.717_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 2.3027 - MAE: 0.7173 - val_loss: 0.3398 - val_MAE: 0.3839 - lr: 0.0010\n",
            "\n",
            "Epoch 751: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 751/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3027 - MAE: 0.7173\n",
            "Epoch 751: loss improved from 2.30273 to 2.30268, saving model to ./model_PID__0751_loss_2.303_vloss_0.340_acc_0.717_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.3027 - MAE: 0.7173 - val_loss: 0.3398 - val_MAE: 0.3839 - lr: 0.0010\n",
            "\n",
            "Epoch 752: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 752/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3026 - MAE: 0.7173\n",
            "Epoch 752: loss improved from 2.30268 to 2.30263, saving model to ./model_PID__0752_loss_2.303_vloss_0.340_acc_0.717_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 2.3026 - MAE: 0.7173 - val_loss: 0.3399 - val_MAE: 0.3839 - lr: 0.0010\n",
            "\n",
            "Epoch 753: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 753/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3026 - MAE: 0.7172\n",
            "Epoch 753: loss improved from 2.30263 to 2.30258, saving model to ./model_PID__0753_loss_2.303_vloss_0.340_acc_0.717_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 2.3026 - MAE: 0.7172 - val_loss: 0.3399 - val_MAE: 0.3839 - lr: 0.0010\n",
            "\n",
            "Epoch 754: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 754/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3025 - MAE: 0.7172\n",
            "Epoch 754: loss improved from 2.30258 to 2.30253, saving model to ./model_PID__0754_loss_2.303_vloss_0.340_acc_0.717_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 2.3025 - MAE: 0.7172 - val_loss: 0.3399 - val_MAE: 0.3839 - lr: 0.0010\n",
            "\n",
            "Epoch 755: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 755/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3025 - MAE: 0.7172\n",
            "Epoch 755: loss improved from 2.30253 to 2.30248, saving model to ./model_PID__0755_loss_2.302_vloss_0.340_acc_0.717_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.3025 - MAE: 0.7172 - val_loss: 0.3399 - val_MAE: 0.3839 - lr: 0.0010\n",
            "\n",
            "Epoch 756: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 756/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3024 - MAE: 0.7171\n",
            "Epoch 756: loss improved from 2.30248 to 2.30242, saving model to ./model_PID__0756_loss_2.302_vloss_0.340_acc_0.717_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 2.3024 - MAE: 0.7171 - val_loss: 0.3400 - val_MAE: 0.3840 - lr: 0.0010\n",
            "\n",
            "Epoch 757: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 757/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3024 - MAE: 0.7171\n",
            "Epoch 757: loss improved from 2.30242 to 2.30237, saving model to ./model_PID__0757_loss_2.302_vloss_0.340_acc_0.717_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 2.3024 - MAE: 0.7171 - val_loss: 0.3400 - val_MAE: 0.3840 - lr: 0.0010\n",
            "\n",
            "Epoch 758: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 758/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3023 - MAE: 0.7171\n",
            "Epoch 758: loss improved from 2.30237 to 2.30232, saving model to ./model_PID__0758_loss_2.302_vloss_0.340_acc_0.717_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 2.3023 - MAE: 0.7171 - val_loss: 0.3400 - val_MAE: 0.3840 - lr: 0.0010\n",
            "\n",
            "Epoch 759: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 759/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3023 - MAE: 0.7171\n",
            "Epoch 759: loss improved from 2.30232 to 2.30227, saving model to ./model_PID__0759_loss_2.302_vloss_0.340_acc_0.717_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 2.3023 - MAE: 0.7171 - val_loss: 0.3401 - val_MAE: 0.3840 - lr: 0.0010\n",
            "\n",
            "Epoch 760: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 760/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3022 - MAE: 0.7170\n",
            "Epoch 760: loss improved from 2.30227 to 2.30222, saving model to ./model_PID__0760_loss_2.302_vloss_0.340_acc_0.717_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 2.3022 - MAE: 0.7170 - val_loss: 0.3401 - val_MAE: 0.3840 - lr: 0.0010\n",
            "\n",
            "Epoch 761: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 761/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3022 - MAE: 0.7170\n",
            "Epoch 761: loss improved from 2.30222 to 2.30217, saving model to ./model_PID__0761_loss_2.302_vloss_0.340_acc_0.717_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 2.3022 - MAE: 0.7170 - val_loss: 0.3401 - val_MAE: 0.3840 - lr: 0.0010\n",
            "\n",
            "Epoch 762: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 762/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3021 - MAE: 0.7170\n",
            "Epoch 762: loss improved from 2.30217 to 2.30213, saving model to ./model_PID__0762_loss_2.302_vloss_0.340_acc_0.717_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 2.3021 - MAE: 0.7170 - val_loss: 0.3402 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 763: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 763/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3021 - MAE: 0.7169\n",
            "Epoch 763: loss improved from 2.30213 to 2.30208, saving model to ./model_PID__0763_loss_2.302_vloss_0.340_acc_0.717_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 2.3021 - MAE: 0.7169 - val_loss: 0.3402 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 764: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 764/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3020 - MAE: 0.7169\n",
            "Epoch 764: loss improved from 2.30208 to 2.30204, saving model to ./model_PID__0764_loss_2.302_vloss_0.340_acc_0.717_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 2.3020 - MAE: 0.7169 - val_loss: 0.3402 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 765: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 765/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3020 - MAE: 0.7169\n",
            "Epoch 765: loss improved from 2.30204 to 2.30200, saving model to ./model_PID__0765_loss_2.302_vloss_0.340_acc_0.717_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 2.3020 - MAE: 0.7169 - val_loss: 0.3403 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 766: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 766/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3020 - MAE: 0.7168\n",
            "Epoch 766: loss improved from 2.30200 to 2.30196, saving model to ./model_PID__0766_loss_2.302_vloss_0.340_acc_0.717_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 2.3020 - MAE: 0.7168 - val_loss: 0.3403 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 767: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 767/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3019 - MAE: 0.7168\n",
            "Epoch 767: loss improved from 2.30196 to 2.30192, saving model to ./model_PID__0767_loss_2.302_vloss_0.340_acc_0.717_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 2.3019 - MAE: 0.7168 - val_loss: 0.3403 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 768: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 768/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3019 - MAE: 0.7168\n",
            "Epoch 768: loss improved from 2.30192 to 2.30188, saving model to ./model_PID__0768_loss_2.302_vloss_0.340_acc_0.717_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 2.3019 - MAE: 0.7168 - val_loss: 0.3403 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 769: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 769/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3018 - MAE: 0.7167\n",
            "Epoch 769: loss improved from 2.30188 to 2.30184, saving model to ./model_PID__0769_loss_2.302_vloss_0.340_acc_0.717_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 2.3018 - MAE: 0.7167 - val_loss: 0.3403 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 770: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 770/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3018 - MAE: 0.7167\n",
            "Epoch 770: loss improved from 2.30184 to 2.30181, saving model to ./model_PID__0770_loss_2.302_vloss_0.340_acc_0.717_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 2.3018 - MAE: 0.7167 - val_loss: 0.3403 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 771: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 771/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3018 - MAE: 0.7167\n",
            "Epoch 771: loss improved from 2.30181 to 2.30177, saving model to ./model_PID__0771_loss_2.302_vloss_0.340_acc_0.717_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 2.3018 - MAE: 0.7167 - val_loss: 0.3404 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 772: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 772/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3017 - MAE: 0.7166\n",
            "Epoch 772: loss improved from 2.30177 to 2.30173, saving model to ./model_PID__0772_loss_2.302_vloss_0.340_acc_0.717_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2.3017 - MAE: 0.7166 - val_loss: 0.3404 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 773: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 773/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3017 - MAE: 0.7166\n",
            "Epoch 773: loss improved from 2.30173 to 2.30169, saving model to ./model_PID__0773_loss_2.302_vloss_0.340_acc_0.717_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 2.3017 - MAE: 0.7166 - val_loss: 0.3404 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 774: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 774/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3017 - MAE: 0.7166\n",
            "Epoch 774: loss improved from 2.30169 to 2.30166, saving model to ./model_PID__0774_loss_2.302_vloss_0.340_acc_0.717_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.3017 - MAE: 0.7166 - val_loss: 0.3404 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 775: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 775/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3016 - MAE: 0.7165\n",
            "Epoch 775: loss improved from 2.30166 to 2.30162, saving model to ./model_PID__0775_loss_2.302_vloss_0.340_acc_0.717_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.3016 - MAE: 0.7165 - val_loss: 0.3404 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 776: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 776/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3016 - MAE: 0.7165\n",
            "Epoch 776: loss improved from 2.30162 to 2.30158, saving model to ./model_PID__0776_loss_2.302_vloss_0.340_acc_0.716_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 2.3016 - MAE: 0.7165 - val_loss: 0.3405 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 777: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 777/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3015 - MAE: 0.7165\n",
            "Epoch 777: loss improved from 2.30158 to 2.30155, saving model to ./model_PID__0777_loss_2.302_vloss_0.340_acc_0.716_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 2.3015 - MAE: 0.7165 - val_loss: 0.3405 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 778: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 778/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3015 - MAE: 0.7164\n",
            "Epoch 778: loss improved from 2.30155 to 2.30151, saving model to ./model_PID__0778_loss_2.302_vloss_0.341_acc_0.716_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 2.3015 - MAE: 0.7164 - val_loss: 0.3405 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 779: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 779/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3015 - MAE: 0.7164\n",
            "Epoch 779: loss improved from 2.30151 to 2.30148, saving model to ./model_PID__0779_loss_2.301_vloss_0.341_acc_0.716_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 2.3015 - MAE: 0.7164 - val_loss: 0.3405 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 780: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 780/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3014 - MAE: 0.7163\n",
            "Epoch 780: loss improved from 2.30148 to 2.30144, saving model to ./model_PID__0780_loss_2.301_vloss_0.341_acc_0.716_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 2.3014 - MAE: 0.7163 - val_loss: 0.3406 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 781: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 781/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3014 - MAE: 0.7163\n",
            "Epoch 781: loss improved from 2.30144 to 2.30140, saving model to ./model_PID__0781_loss_2.301_vloss_0.341_acc_0.716_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2.3014 - MAE: 0.7163 - val_loss: 0.3406 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 782: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 782/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3014 - MAE: 0.7163\n",
            "Epoch 782: loss improved from 2.30140 to 2.30137, saving model to ./model_PID__0782_loss_2.301_vloss_0.341_acc_0.716_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 2.3014 - MAE: 0.7163 - val_loss: 0.3406 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 783: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 783/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3013 - MAE: 0.7162\n",
            "Epoch 783: loss improved from 2.30137 to 2.30133, saving model to ./model_PID__0783_loss_2.301_vloss_0.341_acc_0.716_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 2.3013 - MAE: 0.7162 - val_loss: 0.3407 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 784: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 784/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3013 - MAE: 0.7162\n",
            "Epoch 784: loss improved from 2.30133 to 2.30130, saving model to ./model_PID__0784_loss_2.301_vloss_0.341_acc_0.716_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 2.3013 - MAE: 0.7162 - val_loss: 0.3407 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 785: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 785/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3013 - MAE: 0.7162\n",
            "Epoch 785: loss improved from 2.30130 to 2.30126, saving model to ./model_PID__0785_loss_2.301_vloss_0.341_acc_0.716_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 2.3013 - MAE: 0.7162 - val_loss: 0.3407 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 786: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 786/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3012 - MAE: 0.7161\n",
            "Epoch 786: loss improved from 2.30126 to 2.30123, saving model to ./model_PID__0786_loss_2.301_vloss_0.341_acc_0.716_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 2.3012 - MAE: 0.7161 - val_loss: 0.3407 - val_MAE: 0.3841 - lr: 0.0010\n",
            "\n",
            "Epoch 787: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 787/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3012 - MAE: 0.7161\n",
            "Epoch 787: loss improved from 2.30123 to 2.30119, saving model to ./model_PID__0787_loss_2.301_vloss_0.341_acc_0.716_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 2.3012 - MAE: 0.7161 - val_loss: 0.3408 - val_MAE: 0.3842 - lr: 0.0010\n",
            "\n",
            "Epoch 788: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 788/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3012 - MAE: 0.7161\n",
            "Epoch 788: loss improved from 2.30119 to 2.30116, saving model to ./model_PID__0788_loss_2.301_vloss_0.341_acc_0.716_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.3012 - MAE: 0.7161 - val_loss: 0.3408 - val_MAE: 0.3842 - lr: 0.0010\n",
            "\n",
            "Epoch 789: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 789/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3011 - MAE: 0.7160\n",
            "Epoch 789: loss improved from 2.30116 to 2.30112, saving model to ./model_PID__0789_loss_2.301_vloss_0.341_acc_0.716_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.3011 - MAE: 0.7160 - val_loss: 0.3408 - val_MAE: 0.3842 - lr: 0.0010\n",
            "\n",
            "Epoch 790: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 790/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3011 - MAE: 0.7160\n",
            "Epoch 790: loss improved from 2.30112 to 2.30109, saving model to ./model_PID__0790_loss_2.301_vloss_0.341_acc_0.716_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 2.3011 - MAE: 0.7160 - val_loss: 0.3408 - val_MAE: 0.3842 - lr: 0.0010\n",
            "\n",
            "Epoch 791: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 791/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3011 - MAE: 0.7160\n",
            "Epoch 791: loss improved from 2.30109 to 2.30105, saving model to ./model_PID__0791_loss_2.301_vloss_0.341_acc_0.716_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 2.3011 - MAE: 0.7160 - val_loss: 0.3409 - val_MAE: 0.3842 - lr: 0.0010\n",
            "\n",
            "Epoch 792: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 792/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3010 - MAE: 0.7160\n",
            "Epoch 792: loss improved from 2.30105 to 2.30102, saving model to ./model_PID__0792_loss_2.301_vloss_0.341_acc_0.716_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 2.3010 - MAE: 0.7160 - val_loss: 0.3409 - val_MAE: 0.3842 - lr: 0.0010\n",
            "\n",
            "Epoch 793: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 793/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3010 - MAE: 0.7159\n",
            "Epoch 793: loss improved from 2.30102 to 2.30098, saving model to ./model_PID__0793_loss_2.301_vloss_0.341_acc_0.716_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 2.3010 - MAE: 0.7159 - val_loss: 0.3409 - val_MAE: 0.3842 - lr: 0.0010\n",
            "\n",
            "Epoch 794: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 794/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3010 - MAE: 0.7159\n",
            "Epoch 794: loss improved from 2.30098 to 2.30095, saving model to ./model_PID__0794_loss_2.301_vloss_0.341_acc_0.716_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 2.3010 - MAE: 0.7159 - val_loss: 0.3409 - val_MAE: 0.3842 - lr: 0.0010\n",
            "\n",
            "Epoch 795: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 795/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3009 - MAE: 0.7159\n",
            "Epoch 795: loss improved from 2.30095 to 2.30092, saving model to ./model_PID__0795_loss_2.301_vloss_0.341_acc_0.716_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 2.3009 - MAE: 0.7159 - val_loss: 0.3409 - val_MAE: 0.3842 - lr: 0.0010\n",
            "\n",
            "Epoch 796: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 796/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3009 - MAE: 0.7158\n",
            "Epoch 796: loss improved from 2.30092 to 2.30088, saving model to ./model_PID__0796_loss_2.301_vloss_0.341_acc_0.716_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 2.3009 - MAE: 0.7158 - val_loss: 0.3410 - val_MAE: 0.3842 - lr: 0.0010\n",
            "\n",
            "Epoch 797: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 797/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3008 - MAE: 0.7158\n",
            "Epoch 797: loss improved from 2.30088 to 2.30085, saving model to ./model_PID__0797_loss_2.301_vloss_0.341_acc_0.716_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 2.3008 - MAE: 0.7158 - val_loss: 0.3410 - val_MAE: 0.3842 - lr: 0.0010\n",
            "\n",
            "Epoch 798: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 798/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3008 - MAE: 0.7158\n",
            "Epoch 798: loss improved from 2.30085 to 2.30081, saving model to ./model_PID__0798_loss_2.301_vloss_0.341_acc_0.716_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 2.3008 - MAE: 0.7158 - val_loss: 0.3410 - val_MAE: 0.3842 - lr: 0.0010\n",
            "\n",
            "Epoch 799: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 799/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3008 - MAE: 0.7158\n",
            "Epoch 799: loss improved from 2.30081 to 2.30078, saving model to ./model_PID__0799_loss_2.301_vloss_0.341_acc_0.716_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 2.3008 - MAE: 0.7158 - val_loss: 0.3410 - val_MAE: 0.3842 - lr: 0.0010\n",
            "\n",
            "Epoch 800: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 800/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3007 - MAE: 0.7157\n",
            "Epoch 800: loss improved from 2.30078 to 2.30075, saving model to ./model_PID__0800_loss_2.301_vloss_0.341_acc_0.716_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 2.3007 - MAE: 0.7157 - val_loss: 0.3411 - val_MAE: 0.3842 - lr: 0.0010\n",
            "\n",
            "Epoch 801: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 801/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3007 - MAE: 0.7157\n",
            "Epoch 801: loss improved from 2.30075 to 2.30071, saving model to ./model_PID__0801_loss_2.301_vloss_0.341_acc_0.716_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 2.3007 - MAE: 0.7157 - val_loss: 0.3411 - val_MAE: 0.3842 - lr: 0.0010\n",
            "\n",
            "Epoch 802: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 802/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3007 - MAE: 0.7157\n",
            "Epoch 802: loss improved from 2.30071 to 2.30068, saving model to ./model_PID__0802_loss_2.301_vloss_0.341_acc_0.716_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.3007 - MAE: 0.7157 - val_loss: 0.3411 - val_MAE: 0.3842 - lr: 0.0010\n",
            "\n",
            "Epoch 803: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 803/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3006 - MAE: 0.7156\n",
            "Epoch 803: loss improved from 2.30068 to 2.30065, saving model to ./model_PID__0803_loss_2.301_vloss_0.341_acc_0.716_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 2.3006 - MAE: 0.7156 - val_loss: 0.3411 - val_MAE: 0.3842 - lr: 0.0010\n",
            "\n",
            "Epoch 804: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 804/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3006 - MAE: 0.7156\n",
            "Epoch 804: loss improved from 2.30065 to 2.30061, saving model to ./model_PID__0804_loss_2.301_vloss_0.341_acc_0.716_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 2.3006 - MAE: 0.7156 - val_loss: 0.3411 - val_MAE: 0.3842 - lr: 0.0010\n",
            "\n",
            "Epoch 805: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 805/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3006 - MAE: 0.7156\n",
            "Epoch 805: loss improved from 2.30061 to 2.30058, saving model to ./model_PID__0805_loss_2.301_vloss_0.341_acc_0.716_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 2.3006 - MAE: 0.7156 - val_loss: 0.3412 - val_MAE: 0.3842 - lr: 0.0010\n",
            "\n",
            "Epoch 806: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 806/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3005 - MAE: 0.7156\n",
            "Epoch 806: loss improved from 2.30058 to 2.30054, saving model to ./model_PID__0806_loss_2.301_vloss_0.341_acc_0.716_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 2.3005 - MAE: 0.7156 - val_loss: 0.3412 - val_MAE: 0.3842 - lr: 0.0010\n",
            "\n",
            "Epoch 807: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 807/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3005 - MAE: 0.7155\n",
            "Epoch 807: loss improved from 2.30054 to 2.30051, saving model to ./model_PID__0807_loss_2.301_vloss_0.341_acc_0.716_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 2.3005 - MAE: 0.7155 - val_loss: 0.3412 - val_MAE: 0.3842 - lr: 0.0010\n",
            "\n",
            "Epoch 808: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 808/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3005 - MAE: 0.7155\n",
            "Epoch 808: loss improved from 2.30051 to 2.30047, saving model to ./model_PID__0808_loss_2.300_vloss_0.341_acc_0.715_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 2.3005 - MAE: 0.7155 - val_loss: 0.3412 - val_MAE: 0.3842 - lr: 0.0010\n",
            "\n",
            "Epoch 809: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 809/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3004 - MAE: 0.7155\n",
            "Epoch 809: loss improved from 2.30047 to 2.30044, saving model to ./model_PID__0809_loss_2.300_vloss_0.341_acc_0.715_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 2.3004 - MAE: 0.7155 - val_loss: 0.3413 - val_MAE: 0.3842 - lr: 0.0010\n",
            "\n",
            "Epoch 810: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 810/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3004 - MAE: 0.7154\n",
            "Epoch 810: loss improved from 2.30044 to 2.30041, saving model to ./model_PID__0810_loss_2.300_vloss_0.341_acc_0.715_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 2.3004 - MAE: 0.7154 - val_loss: 0.3413 - val_MAE: 0.3843 - lr: 0.0010\n",
            "\n",
            "Epoch 811: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 811/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3004 - MAE: 0.7154\n",
            "Epoch 811: loss improved from 2.30041 to 2.30037, saving model to ./model_PID__0811_loss_2.300_vloss_0.341_acc_0.715_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 2.3004 - MAE: 0.7154 - val_loss: 0.3413 - val_MAE: 0.3843 - lr: 0.0010\n",
            "\n",
            "Epoch 812: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 812/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3003 - MAE: 0.7154\n",
            "Epoch 812: loss improved from 2.30037 to 2.30034, saving model to ./model_PID__0812_loss_2.300_vloss_0.341_acc_0.715_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 2.3003 - MAE: 0.7154 - val_loss: 0.3414 - val_MAE: 0.3843 - lr: 0.0010\n",
            "\n",
            "Epoch 813: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 813/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3003 - MAE: 0.7154\n",
            "Epoch 813: loss improved from 2.30034 to 2.30030, saving model to ./model_PID__0813_loss_2.300_vloss_0.341_acc_0.715_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 2.3003 - MAE: 0.7154 - val_loss: 0.3414 - val_MAE: 0.3843 - lr: 0.0010\n",
            "\n",
            "Epoch 814: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 814/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3003 - MAE: 0.7153\n",
            "Epoch 814: loss improved from 2.30030 to 2.30027, saving model to ./model_PID__0814_loss_2.300_vloss_0.341_acc_0.715_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 2.3003 - MAE: 0.7153 - val_loss: 0.3414 - val_MAE: 0.3843 - lr: 0.0010\n",
            "\n",
            "Epoch 815: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 815/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3002 - MAE: 0.7153\n",
            "Epoch 815: loss improved from 2.30027 to 2.30023, saving model to ./model_PID__0815_loss_2.300_vloss_0.341_acc_0.715_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 2.3002 - MAE: 0.7153 - val_loss: 0.3414 - val_MAE: 0.3843 - lr: 0.0010\n",
            "\n",
            "Epoch 816: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 816/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3002 - MAE: 0.7153\n",
            "Epoch 816: loss improved from 2.30023 to 2.30020, saving model to ./model_PID__0816_loss_2.300_vloss_0.341_acc_0.715_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 2.3002 - MAE: 0.7153 - val_loss: 0.3415 - val_MAE: 0.3843 - lr: 0.0010\n",
            "\n",
            "Epoch 817: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 817/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3002 - MAE: 0.7153\n",
            "Epoch 817: loss improved from 2.30020 to 2.30016, saving model to ./model_PID__0817_loss_2.300_vloss_0.341_acc_0.715_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 2.3002 - MAE: 0.7153 - val_loss: 0.3415 - val_MAE: 0.3843 - lr: 0.0010\n",
            "\n",
            "Epoch 818: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 818/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3001 - MAE: 0.7152\n",
            "Epoch 818: loss improved from 2.30016 to 2.30013, saving model to ./model_PID__0818_loss_2.300_vloss_0.342_acc_0.715_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 2.3001 - MAE: 0.7152 - val_loss: 0.3415 - val_MAE: 0.3843 - lr: 0.0010\n",
            "\n",
            "Epoch 819: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 819/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3001 - MAE: 0.7152\n",
            "Epoch 819: loss improved from 2.30013 to 2.30009, saving model to ./model_PID__0819_loss_2.300_vloss_0.342_acc_0.715_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.3001 - MAE: 0.7152 - val_loss: 0.3415 - val_MAE: 0.3843 - lr: 0.0010\n",
            "\n",
            "Epoch 820: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 820/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3001 - MAE: 0.7152\n",
            "Epoch 820: loss improved from 2.30009 to 2.30006, saving model to ./model_PID__0820_loss_2.300_vloss_0.342_acc_0.715_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 2.3001 - MAE: 0.7152 - val_loss: 0.3416 - val_MAE: 0.3844 - lr: 0.0010\n",
            "\n",
            "Epoch 821: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 821/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3000 - MAE: 0.7152\n",
            "Epoch 821: loss improved from 2.30006 to 2.30002, saving model to ./model_PID__0821_loss_2.300_vloss_0.342_acc_0.715_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 2.3000 - MAE: 0.7152 - val_loss: 0.3416 - val_MAE: 0.3844 - lr: 0.0010\n",
            "\n",
            "Epoch 822: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 822/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3000 - MAE: 0.7151\n",
            "Epoch 822: loss improved from 2.30002 to 2.29999, saving model to ./model_PID__0822_loss_2.300_vloss_0.342_acc_0.715_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 2.3000 - MAE: 0.7151 - val_loss: 0.3416 - val_MAE: 0.3844 - lr: 0.0010\n",
            "\n",
            "Epoch 823: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 823/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.3000 - MAE: 0.7151\n",
            "Epoch 823: loss improved from 2.29999 to 2.29995, saving model to ./model_PID__0823_loss_2.300_vloss_0.342_acc_0.715_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 2.3000 - MAE: 0.7151 - val_loss: 0.3416 - val_MAE: 0.3844 - lr: 0.0010\n",
            "\n",
            "Epoch 824: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 824/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2999 - MAE: 0.7151\n",
            "Epoch 824: loss improved from 2.29995 to 2.29992, saving model to ./model_PID__0824_loss_2.300_vloss_0.342_acc_0.715_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 2.2999 - MAE: 0.7151 - val_loss: 0.3417 - val_MAE: 0.3844 - lr: 0.0010\n",
            "\n",
            "Epoch 825: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 825/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2999 - MAE: 0.7151\n",
            "Epoch 825: loss improved from 2.29992 to 2.29988, saving model to ./model_PID__0825_loss_2.300_vloss_0.342_acc_0.715_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.2999 - MAE: 0.7151 - val_loss: 0.3417 - val_MAE: 0.3844 - lr: 0.0010\n",
            "\n",
            "Epoch 826: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 826/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2998 - MAE: 0.7150\n",
            "Epoch 826: loss improved from 2.29988 to 2.29984, saving model to ./model_PID__0826_loss_2.300_vloss_0.342_acc_0.715_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 2.2998 - MAE: 0.7150 - val_loss: 0.3417 - val_MAE: 0.3844 - lr: 0.0010\n",
            "\n",
            "Epoch 827: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 827/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2998 - MAE: 0.7150\n",
            "Epoch 827: loss improved from 2.29984 to 2.29981, saving model to ./model_PID__0827_loss_2.300_vloss_0.342_acc_0.715_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.2998 - MAE: 0.7150 - val_loss: 0.3417 - val_MAE: 0.3844 - lr: 0.0010\n",
            "\n",
            "Epoch 828: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 828/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2998 - MAE: 0.7150\n",
            "Epoch 828: loss improved from 2.29981 to 2.29977, saving model to ./model_PID__0828_loss_2.300_vloss_0.342_acc_0.715_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 2.2998 - MAE: 0.7150 - val_loss: 0.3417 - val_MAE: 0.3844 - lr: 0.0010\n",
            "\n",
            "Epoch 829: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 829/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2997 - MAE: 0.7150\n",
            "Epoch 829: loss improved from 2.29977 to 2.29974, saving model to ./model_PID__0829_loss_2.300_vloss_0.342_acc_0.715_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 2.2997 - MAE: 0.7150 - val_loss: 0.3418 - val_MAE: 0.3844 - lr: 0.0010\n",
            "\n",
            "Epoch 830: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 830/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2997 - MAE: 0.7149\n",
            "Epoch 830: loss improved from 2.29974 to 2.29970, saving model to ./model_PID__0830_loss_2.300_vloss_0.342_acc_0.715_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 2.2997 - MAE: 0.7149 - val_loss: 0.3418 - val_MAE: 0.3844 - lr: 0.0010\n",
            "\n",
            "Epoch 831: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 831/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2997 - MAE: 0.7149\n",
            "Epoch 831: loss improved from 2.29970 to 2.29966, saving model to ./model_PID__0831_loss_2.300_vloss_0.342_acc_0.715_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 2.2997 - MAE: 0.7149 - val_loss: 0.3418 - val_MAE: 0.3844 - lr: 0.0010\n",
            "\n",
            "Epoch 832: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 832/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2996 - MAE: 0.7149\n",
            "Epoch 832: loss improved from 2.29966 to 2.29963, saving model to ./model_PID__0832_loss_2.300_vloss_0.342_acc_0.715_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 2.2996 - MAE: 0.7149 - val_loss: 0.3418 - val_MAE: 0.3844 - lr: 0.0010\n",
            "\n",
            "Epoch 833: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 833/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2996 - MAE: 0.7149\n",
            "Epoch 833: loss improved from 2.29963 to 2.29959, saving model to ./model_PID__0833_loss_2.300_vloss_0.342_acc_0.715_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 2.2996 - MAE: 0.7149 - val_loss: 0.3418 - val_MAE: 0.3845 - lr: 0.0010\n",
            "\n",
            "Epoch 834: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 834/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2996 - MAE: 0.7148\n",
            "Epoch 834: loss improved from 2.29959 to 2.29956, saving model to ./model_PID__0834_loss_2.300_vloss_0.342_acc_0.715_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 2.2996 - MAE: 0.7148 - val_loss: 0.3419 - val_MAE: 0.3845 - lr: 0.0010\n",
            "\n",
            "Epoch 835: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 835/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2995 - MAE: 0.7148\n",
            "Epoch 835: loss improved from 2.29956 to 2.29952, saving model to ./model_PID__0835_loss_2.300_vloss_0.342_acc_0.715_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.2995 - MAE: 0.7148 - val_loss: 0.3419 - val_MAE: 0.3845 - lr: 0.0010\n",
            "\n",
            "Epoch 836: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 836/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2995 - MAE: 0.7148\n",
            "Epoch 836: loss improved from 2.29952 to 2.29948, saving model to ./model_PID__0836_loss_2.299_vloss_0.342_acc_0.715_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 2.2995 - MAE: 0.7148 - val_loss: 0.3419 - val_MAE: 0.3845 - lr: 0.0010\n",
            "\n",
            "Epoch 837: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 837/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2994 - MAE: 0.7148\n",
            "Epoch 837: loss improved from 2.29948 to 2.29945, saving model to ./model_PID__0837_loss_2.299_vloss_0.342_acc_0.715_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 2.2994 - MAE: 0.7148 - val_loss: 0.3419 - val_MAE: 0.3845 - lr: 0.0010\n",
            "\n",
            "Epoch 838: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 838/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2994 - MAE: 0.7147\n",
            "Epoch 838: loss improved from 2.29945 to 2.29941, saving model to ./model_PID__0838_loss_2.299_vloss_0.342_acc_0.715_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 2.2994 - MAE: 0.7147 - val_loss: 0.3420 - val_MAE: 0.3845 - lr: 0.0010\n",
            "\n",
            "Epoch 839: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 839/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2994 - MAE: 0.7147\n",
            "Epoch 839: loss improved from 2.29941 to 2.29938, saving model to ./model_PID__0839_loss_2.299_vloss_0.342_acc_0.715_vacc_0.384.hdf5\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 2.2994 - MAE: 0.7147 - val_loss: 0.3420 - val_MAE: 0.3845 - lr: 0.0010\n",
            "\n",
            "Epoch 840: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 840/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2993 - MAE: 0.7147\n",
            "Epoch 840: loss improved from 2.29938 to 2.29934, saving model to ./model_PID__0840_loss_2.299_vloss_0.342_acc_0.715_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 2.2993 - MAE: 0.7147 - val_loss: 0.3420 - val_MAE: 0.3845 - lr: 0.0010\n",
            "\n",
            "Epoch 841: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 841/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2993 - MAE: 0.7147\n",
            "Epoch 841: loss improved from 2.29934 to 2.29931, saving model to ./model_PID__0841_loss_2.299_vloss_0.342_acc_0.715_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.2993 - MAE: 0.7147 - val_loss: 0.3420 - val_MAE: 0.3845 - lr: 0.0010\n",
            "\n",
            "Epoch 842: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 842/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2993 - MAE: 0.7146\n",
            "Epoch 842: loss improved from 2.29931 to 2.29927, saving model to ./model_PID__0842_loss_2.299_vloss_0.342_acc_0.715_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.2993 - MAE: 0.7146 - val_loss: 0.3420 - val_MAE: 0.3845 - lr: 0.0010\n",
            "\n",
            "Epoch 843: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 843/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2992 - MAE: 0.7146\n",
            "Epoch 843: loss improved from 2.29927 to 2.29924, saving model to ./model_PID__0843_loss_2.299_vloss_0.342_acc_0.715_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 2.2992 - MAE: 0.7146 - val_loss: 0.3421 - val_MAE: 0.3845 - lr: 0.0010\n",
            "\n",
            "Epoch 844: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 844/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2992 - MAE: 0.7146\n",
            "Epoch 844: loss improved from 2.29924 to 2.29920, saving model to ./model_PID__0844_loss_2.299_vloss_0.342_acc_0.715_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 2.2992 - MAE: 0.7146 - val_loss: 0.3421 - val_MAE: 0.3845 - lr: 0.0010\n",
            "\n",
            "Epoch 845: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 845/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2992 - MAE: 0.7146\n",
            "Epoch 845: loss improved from 2.29920 to 2.29917, saving model to ./model_PID__0845_loss_2.299_vloss_0.342_acc_0.715_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 2.2992 - MAE: 0.7146 - val_loss: 0.3421 - val_MAE: 0.3845 - lr: 0.0010\n",
            "\n",
            "Epoch 846: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 846/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2991 - MAE: 0.7145\n",
            "Epoch 846: loss improved from 2.29917 to 2.29914, saving model to ./model_PID__0846_loss_2.299_vloss_0.342_acc_0.715_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 2.2991 - MAE: 0.7145 - val_loss: 0.3421 - val_MAE: 0.3845 - lr: 0.0010\n",
            "\n",
            "Epoch 847: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 847/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2991 - MAE: 0.7145\n",
            "Epoch 847: loss improved from 2.29914 to 2.29910, saving model to ./model_PID__0847_loss_2.299_vloss_0.342_acc_0.715_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 2.2991 - MAE: 0.7145 - val_loss: 0.3421 - val_MAE: 0.3845 - lr: 0.0010\n",
            "\n",
            "Epoch 848: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 848/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2991 - MAE: 0.7145\n",
            "Epoch 848: loss improved from 2.29910 to 2.29907, saving model to ./model_PID__0848_loss_2.299_vloss_0.342_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 2.2991 - MAE: 0.7145 - val_loss: 0.3422 - val_MAE: 0.3845 - lr: 0.0010\n",
            "\n",
            "Epoch 849: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 849/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2990 - MAE: 0.7145\n",
            "Epoch 849: loss improved from 2.29907 to 2.29903, saving model to ./model_PID__0849_loss_2.299_vloss_0.342_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 2.2990 - MAE: 0.7145 - val_loss: 0.3422 - val_MAE: 0.3845 - lr: 0.0010\n",
            "\n",
            "Epoch 850: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 850/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2990 - MAE: 0.7144\n",
            "Epoch 850: loss improved from 2.29903 to 2.29900, saving model to ./model_PID__0850_loss_2.299_vloss_0.342_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 2.2990 - MAE: 0.7144 - val_loss: 0.3422 - val_MAE: 0.3845 - lr: 0.0010\n",
            "\n",
            "Epoch 851: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 851/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2990 - MAE: 0.7144\n",
            "Epoch 851: loss improved from 2.29900 to 2.29897, saving model to ./model_PID__0851_loss_2.299_vloss_0.342_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 2.2990 - MAE: 0.7144 - val_loss: 0.3422 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 852: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 852/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2989 - MAE: 0.7144\n",
            "Epoch 852: loss improved from 2.29897 to 2.29893, saving model to ./model_PID__0852_loss_2.299_vloss_0.342_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 2.2989 - MAE: 0.7144 - val_loss: 0.3422 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 853: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 853/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2989 - MAE: 0.7143\n",
            "Epoch 853: loss improved from 2.29893 to 2.29890, saving model to ./model_PID__0853_loss_2.299_vloss_0.342_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.2989 - MAE: 0.7143 - val_loss: 0.3423 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 854: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 854/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2989 - MAE: 0.7143\n",
            "Epoch 854: loss improved from 2.29890 to 2.29887, saving model to ./model_PID__0854_loss_2.299_vloss_0.342_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 2.2989 - MAE: 0.7143 - val_loss: 0.3423 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 855: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 855/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2988 - MAE: 0.7143\n",
            "Epoch 855: loss improved from 2.29887 to 2.29883, saving model to ./model_PID__0855_loss_2.299_vloss_0.342_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 2.2988 - MAE: 0.7143 - val_loss: 0.3423 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 856: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 856/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2988 - MAE: 0.7143\n",
            "Epoch 856: loss improved from 2.29883 to 2.29880, saving model to ./model_PID__0856_loss_2.299_vloss_0.342_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.2988 - MAE: 0.7143 - val_loss: 0.3423 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 857: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 857/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2988 - MAE: 0.7142\n",
            "Epoch 857: loss improved from 2.29880 to 2.29877, saving model to ./model_PID__0857_loss_2.299_vloss_0.342_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 2.2988 - MAE: 0.7142 - val_loss: 0.3423 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 858: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 858/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2987 - MAE: 0.7142\n",
            "Epoch 858: loss improved from 2.29877 to 2.29873, saving model to ./model_PID__0858_loss_2.299_vloss_0.342_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 2.2987 - MAE: 0.7142 - val_loss: 0.3424 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 859: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 859/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2987 - MAE: 0.7142\n",
            "Epoch 859: loss improved from 2.29873 to 2.29870, saving model to ./model_PID__0859_loss_2.299_vloss_0.342_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 2.2987 - MAE: 0.7142 - val_loss: 0.3424 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 860: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 860/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2987 - MAE: 0.7142\n",
            "Epoch 860: loss improved from 2.29870 to 2.29867, saving model to ./model_PID__0860_loss_2.299_vloss_0.342_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 2.2987 - MAE: 0.7142 - val_loss: 0.3424 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 861: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 861/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2986 - MAE: 0.7141\n",
            "Epoch 861: loss improved from 2.29867 to 2.29864, saving model to ./model_PID__0861_loss_2.299_vloss_0.342_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 2.2986 - MAE: 0.7141 - val_loss: 0.3424 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 862: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 862/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2986 - MAE: 0.7141\n",
            "Epoch 862: loss improved from 2.29864 to 2.29860, saving model to ./model_PID__0862_loss_2.299_vloss_0.342_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 2.2986 - MAE: 0.7141 - val_loss: 0.3424 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 863: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 863/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2986 - MAE: 0.7141\n",
            "Epoch 863: loss improved from 2.29860 to 2.29857, saving model to ./model_PID__0863_loss_2.299_vloss_0.342_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 2.2986 - MAE: 0.7141 - val_loss: 0.3425 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 864: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 864/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2985 - MAE: 0.7141\n",
            "Epoch 864: loss improved from 2.29857 to 2.29854, saving model to ./model_PID__0864_loss_2.299_vloss_0.342_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 2.2985 - MAE: 0.7141 - val_loss: 0.3425 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 865: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 865/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2985 - MAE: 0.7140\n",
            "Epoch 865: loss improved from 2.29854 to 2.29850, saving model to ./model_PID__0865_loss_2.299_vloss_0.343_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 2.2985 - MAE: 0.7140 - val_loss: 0.3425 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 866: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 866/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2985 - MAE: 0.7140\n",
            "Epoch 866: loss improved from 2.29850 to 2.29847, saving model to ./model_PID__0866_loss_2.298_vloss_0.343_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 2.2985 - MAE: 0.7140 - val_loss: 0.3425 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 867: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 867/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2984 - MAE: 0.7140\n",
            "Epoch 867: loss improved from 2.29847 to 2.29844, saving model to ./model_PID__0867_loss_2.298_vloss_0.343_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.2984 - MAE: 0.7140 - val_loss: 0.3425 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 868: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 868/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2984 - MAE: 0.7139\n",
            "Epoch 868: loss improved from 2.29844 to 2.29840, saving model to ./model_PID__0868_loss_2.298_vloss_0.343_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 2.2984 - MAE: 0.7139 - val_loss: 0.3426 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 869: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 869/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2984 - MAE: 0.7139\n",
            "Epoch 869: loss improved from 2.29840 to 2.29837, saving model to ./model_PID__0869_loss_2.298_vloss_0.343_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.2984 - MAE: 0.7139 - val_loss: 0.3426 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 870: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 870/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2983 - MAE: 0.7139\n",
            "Epoch 870: loss improved from 2.29837 to 2.29834, saving model to ./model_PID__0870_loss_2.298_vloss_0.343_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.2983 - MAE: 0.7139 - val_loss: 0.3426 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 871: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 871/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2983 - MAE: 0.7139\n",
            "Epoch 871: loss improved from 2.29834 to 2.29830, saving model to ./model_PID__0871_loss_2.298_vloss_0.343_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 2.2983 - MAE: 0.7139 - val_loss: 0.3426 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 872: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 872/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2983 - MAE: 0.7138\n",
            "Epoch 872: loss improved from 2.29830 to 2.29827, saving model to ./model_PID__0872_loss_2.298_vloss_0.343_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 2.2983 - MAE: 0.7138 - val_loss: 0.3426 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 873: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 873/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2982 - MAE: 0.7138\n",
            "Epoch 873: loss improved from 2.29827 to 2.29824, saving model to ./model_PID__0873_loss_2.298_vloss_0.343_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 2.2982 - MAE: 0.7138 - val_loss: 0.3427 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 874: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 874/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2982 - MAE: 0.7138\n",
            "Epoch 874: loss improved from 2.29824 to 2.29821, saving model to ./model_PID__0874_loss_2.298_vloss_0.343_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.2982 - MAE: 0.7138 - val_loss: 0.3427 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 875: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 875/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2982 - MAE: 0.7138\n",
            "Epoch 875: loss improved from 2.29821 to 2.29817, saving model to ./model_PID__0875_loss_2.298_vloss_0.343_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 2.2982 - MAE: 0.7138 - val_loss: 0.3427 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 876: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 876/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2981 - MAE: 0.7137\n",
            "Epoch 876: loss improved from 2.29817 to 2.29814, saving model to ./model_PID__0876_loss_2.298_vloss_0.343_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.2981 - MAE: 0.7137 - val_loss: 0.3427 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 877: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 877/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2981 - MAE: 0.7137\n",
            "Epoch 877: loss improved from 2.29814 to 2.29811, saving model to ./model_PID__0877_loss_2.298_vloss_0.343_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 2.2981 - MAE: 0.7137 - val_loss: 0.3427 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 878: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 878/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2981 - MAE: 0.7137\n",
            "Epoch 878: loss improved from 2.29811 to 2.29807, saving model to ./model_PID__0878_loss_2.298_vloss_0.343_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 2.2981 - MAE: 0.7137 - val_loss: 0.3428 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 879: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 879/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2980 - MAE: 0.7137\n",
            "Epoch 879: loss improved from 2.29807 to 2.29804, saving model to ./model_PID__0879_loss_2.298_vloss_0.343_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 2.2980 - MAE: 0.7137 - val_loss: 0.3428 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 880: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 880/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2980 - MAE: 0.7136\n",
            "Epoch 880: loss improved from 2.29804 to 2.29800, saving model to ./model_PID__0880_loss_2.298_vloss_0.343_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 2.2980 - MAE: 0.7136 - val_loss: 0.3428 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 881: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 881/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2980 - MAE: 0.7136\n",
            "Epoch 881: loss improved from 2.29800 to 2.29797, saving model to ./model_PID__0881_loss_2.298_vloss_0.343_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 2.2980 - MAE: 0.7136 - val_loss: 0.3428 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 882: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 882/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2979 - MAE: 0.7136\n",
            "Epoch 882: loss improved from 2.29797 to 2.29794, saving model to ./model_PID__0882_loss_2.298_vloss_0.343_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 2.2979 - MAE: 0.7136 - val_loss: 0.3428 - val_MAE: 0.3846 - lr: 0.0010\n",
            "\n",
            "Epoch 883: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 883/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2979 - MAE: 0.7135\n",
            "Epoch 883: loss improved from 2.29794 to 2.29790, saving model to ./model_PID__0883_loss_2.298_vloss_0.343_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 2.2979 - MAE: 0.7135 - val_loss: 0.3429 - val_MAE: 0.3847 - lr: 0.0010\n",
            "\n",
            "Epoch 884: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 884/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2979 - MAE: 0.7135\n",
            "Epoch 884: loss improved from 2.29790 to 2.29787, saving model to ./model_PID__0884_loss_2.298_vloss_0.343_acc_0.714_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 2.2979 - MAE: 0.7135 - val_loss: 0.3429 - val_MAE: 0.3847 - lr: 0.0010\n",
            "\n",
            "Epoch 885: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 885/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2978 - MAE: 0.7135\n",
            "Epoch 885: loss improved from 2.29787 to 2.29783, saving model to ./model_PID__0885_loss_2.298_vloss_0.343_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 2.2978 - MAE: 0.7135 - val_loss: 0.3429 - val_MAE: 0.3847 - lr: 0.0010\n",
            "\n",
            "Epoch 886: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 886/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2978 - MAE: 0.7135\n",
            "Epoch 886: loss improved from 2.29783 to 2.29780, saving model to ./model_PID__0886_loss_2.298_vloss_0.343_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 2.2978 - MAE: 0.7135 - val_loss: 0.3429 - val_MAE: 0.3847 - lr: 0.0010\n",
            "\n",
            "Epoch 887: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 887/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2978 - MAE: 0.7134\n",
            "Epoch 887: loss improved from 2.29780 to 2.29776, saving model to ./model_PID__0887_loss_2.298_vloss_0.343_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 2.2978 - MAE: 0.7134 - val_loss: 0.3429 - val_MAE: 0.3847 - lr: 0.0010\n",
            "\n",
            "Epoch 888: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 888/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2977 - MAE: 0.7134\n",
            "Epoch 888: loss improved from 2.29776 to 2.29773, saving model to ./model_PID__0888_loss_2.298_vloss_0.343_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 2.2977 - MAE: 0.7134 - val_loss: 0.3430 - val_MAE: 0.3847 - lr: 0.0010\n",
            "\n",
            "Epoch 889: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 889/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2977 - MAE: 0.7134\n",
            "Epoch 889: loss improved from 2.29773 to 2.29769, saving model to ./model_PID__0889_loss_2.298_vloss_0.343_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 2.2977 - MAE: 0.7134 - val_loss: 0.3430 - val_MAE: 0.3847 - lr: 0.0010\n",
            "\n",
            "Epoch 890: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 890/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2977 - MAE: 0.7134\n",
            "Epoch 890: loss improved from 2.29769 to 2.29766, saving model to ./model_PID__0890_loss_2.298_vloss_0.343_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 2.2977 - MAE: 0.7134 - val_loss: 0.3430 - val_MAE: 0.3847 - lr: 0.0010\n",
            "\n",
            "Epoch 891: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 891/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2976 - MAE: 0.7133\n",
            "Epoch 891: loss improved from 2.29766 to 2.29762, saving model to ./model_PID__0891_loss_2.298_vloss_0.343_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 2.2976 - MAE: 0.7133 - val_loss: 0.3430 - val_MAE: 0.3847 - lr: 0.0010\n",
            "\n",
            "Epoch 892: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 892/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2976 - MAE: 0.7133\n",
            "Epoch 892: loss improved from 2.29762 to 2.29759, saving model to ./model_PID__0892_loss_2.298_vloss_0.343_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 2.2976 - MAE: 0.7133 - val_loss: 0.3430 - val_MAE: 0.3847 - lr: 0.0010\n",
            "\n",
            "Epoch 893: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 893/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2976 - MAE: 0.7133\n",
            "Epoch 893: loss improved from 2.29759 to 2.29755, saving model to ./model_PID__0893_loss_2.298_vloss_0.343_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 2.2976 - MAE: 0.7133 - val_loss: 0.3431 - val_MAE: 0.3847 - lr: 0.0010\n",
            "\n",
            "Epoch 894: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 894/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2975 - MAE: 0.7133\n",
            "Epoch 894: loss improved from 2.29755 to 2.29752, saving model to ./model_PID__0894_loss_2.298_vloss_0.343_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 2.2975 - MAE: 0.7133 - val_loss: 0.3431 - val_MAE: 0.3847 - lr: 0.0010\n",
            "\n",
            "Epoch 895: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 895/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2975 - MAE: 0.7132\n",
            "Epoch 895: loss improved from 2.29752 to 2.29748, saving model to ./model_PID__0895_loss_2.297_vloss_0.343_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 2.2975 - MAE: 0.7132 - val_loss: 0.3431 - val_MAE: 0.3847 - lr: 0.0010\n",
            "\n",
            "Epoch 896: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 896/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2974 - MAE: 0.7132\n",
            "Epoch 896: loss improved from 2.29748 to 2.29744, saving model to ./model_PID__0896_loss_2.297_vloss_0.343_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 2.2974 - MAE: 0.7132 - val_loss: 0.3431 - val_MAE: 0.3847 - lr: 0.0010\n",
            "\n",
            "Epoch 897: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 897/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2974 - MAE: 0.7132\n",
            "Epoch 897: loss improved from 2.29744 to 2.29741, saving model to ./model_PID__0897_loss_2.297_vloss_0.343_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 2.2974 - MAE: 0.7132 - val_loss: 0.3431 - val_MAE: 0.3847 - lr: 0.0010\n",
            "\n",
            "Epoch 898: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 898/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2974 - MAE: 0.7132\n",
            "Epoch 898: loss improved from 2.29741 to 2.29737, saving model to ./model_PID__0898_loss_2.297_vloss_0.343_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 2.2974 - MAE: 0.7132 - val_loss: 0.3431 - val_MAE: 0.3847 - lr: 0.0010\n",
            "\n",
            "Epoch 899: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 899/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2973 - MAE: 0.7131\n",
            "Epoch 899: loss improved from 2.29737 to 2.29734, saving model to ./model_PID__0899_loss_2.297_vloss_0.343_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 2.2973 - MAE: 0.7131 - val_loss: 0.3432 - val_MAE: 0.3847 - lr: 0.0010\n",
            "\n",
            "Epoch 900: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 900/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2973 - MAE: 0.7131\n",
            "Epoch 900: loss improved from 2.29734 to 2.29730, saving model to ./model_PID__0900_loss_2.297_vloss_0.343_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 2.2973 - MAE: 0.7131 - val_loss: 0.3432 - val_MAE: 0.3847 - lr: 0.0010\n",
            "\n",
            "Epoch 901: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 901/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2973 - MAE: 0.7131\n",
            "Epoch 901: loss improved from 2.29730 to 2.29726, saving model to ./model_PID__0901_loss_2.297_vloss_0.343_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 2.2973 - MAE: 0.7131 - val_loss: 0.3432 - val_MAE: 0.3847 - lr: 0.0010\n",
            "\n",
            "Epoch 902: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 902/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2972 - MAE: 0.7131\n",
            "Epoch 902: loss improved from 2.29726 to 2.29722, saving model to ./model_PID__0902_loss_2.297_vloss_0.343_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 2.2972 - MAE: 0.7131 - val_loss: 0.3432 - val_MAE: 0.3847 - lr: 0.0010\n",
            "\n",
            "Epoch 903: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 903/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2972 - MAE: 0.7130\n",
            "Epoch 903: loss improved from 2.29722 to 2.29719, saving model to ./model_PID__0903_loss_2.297_vloss_0.343_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 2.2972 - MAE: 0.7130 - val_loss: 0.3432 - val_MAE: 0.3847 - lr: 0.0010\n",
            "\n",
            "Epoch 904: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 904/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2971 - MAE: 0.7130\n",
            "Epoch 904: loss improved from 2.29719 to 2.29715, saving model to ./model_PID__0904_loss_2.297_vloss_0.343_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 2.2971 - MAE: 0.7130 - val_loss: 0.3433 - val_MAE: 0.3847 - lr: 0.0010\n",
            "\n",
            "Epoch 905: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 905/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2971 - MAE: 0.7130\n",
            "Epoch 905: loss improved from 2.29715 to 2.29711, saving model to ./model_PID__0905_loss_2.297_vloss_0.343_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 2.2971 - MAE: 0.7130 - val_loss: 0.3433 - val_MAE: 0.3847 - lr: 0.0010\n",
            "\n",
            "Epoch 906: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 906/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2971 - MAE: 0.7130\n",
            "Epoch 906: loss improved from 2.29711 to 2.29707, saving model to ./model_PID__0906_loss_2.297_vloss_0.343_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 2.2971 - MAE: 0.7130 - val_loss: 0.3433 - val_MAE: 0.3848 - lr: 0.0010\n",
            "\n",
            "Epoch 907: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 907/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2970 - MAE: 0.7129\n",
            "Epoch 907: loss improved from 2.29707 to 2.29703, saving model to ./model_PID__0907_loss_2.297_vloss_0.343_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.2970 - MAE: 0.7129 - val_loss: 0.3433 - val_MAE: 0.3848 - lr: 0.0010\n",
            "\n",
            "Epoch 908: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 908/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2970 - MAE: 0.7129\n",
            "Epoch 908: loss improved from 2.29703 to 2.29699, saving model to ./model_PID__0908_loss_2.297_vloss_0.343_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.2970 - MAE: 0.7129 - val_loss: 0.3433 - val_MAE: 0.3848 - lr: 0.0010\n",
            "\n",
            "Epoch 909: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 909/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2970 - MAE: 0.7129\n",
            "Epoch 909: loss improved from 2.29699 to 2.29695, saving model to ./model_PID__0909_loss_2.297_vloss_0.343_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 2.2970 - MAE: 0.7129 - val_loss: 0.3434 - val_MAE: 0.3848 - lr: 0.0010\n",
            "\n",
            "Epoch 910: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 910/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2969 - MAE: 0.7128\n",
            "Epoch 910: loss improved from 2.29695 to 2.29692, saving model to ./model_PID__0910_loss_2.297_vloss_0.343_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 2.2969 - MAE: 0.7128 - val_loss: 0.3434 - val_MAE: 0.3848 - lr: 0.0010\n",
            "\n",
            "Epoch 911: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 911/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2969 - MAE: 0.7128\n",
            "Epoch 911: loss improved from 2.29692 to 2.29688, saving model to ./model_PID__0911_loss_2.297_vloss_0.343_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 2.2969 - MAE: 0.7128 - val_loss: 0.3434 - val_MAE: 0.3848 - lr: 0.0010\n",
            "\n",
            "Epoch 912: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 912/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2968 - MAE: 0.7128\n",
            "Epoch 912: loss improved from 2.29688 to 2.29684, saving model to ./model_PID__0912_loss_2.297_vloss_0.343_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 2.2968 - MAE: 0.7128 - val_loss: 0.3434 - val_MAE: 0.3848 - lr: 0.0010\n",
            "\n",
            "Epoch 913: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 913/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2968 - MAE: 0.7128\n",
            "Epoch 913: loss improved from 2.29684 to 2.29680, saving model to ./model_PID__0913_loss_2.297_vloss_0.343_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 2.2968 - MAE: 0.7128 - val_loss: 0.3434 - val_MAE: 0.3848 - lr: 0.0010\n",
            "\n",
            "Epoch 914: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 914/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2968 - MAE: 0.7127\n",
            "Epoch 914: loss improved from 2.29680 to 2.29676, saving model to ./model_PID__0914_loss_2.297_vloss_0.343_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 2.2968 - MAE: 0.7127 - val_loss: 0.3434 - val_MAE: 0.3848 - lr: 0.0010\n",
            "\n",
            "Epoch 915: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 915/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2967 - MAE: 0.7127\n",
            "Epoch 915: loss improved from 2.29676 to 2.29671, saving model to ./model_PID__0915_loss_2.297_vloss_0.343_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 2.2967 - MAE: 0.7127 - val_loss: 0.3435 - val_MAE: 0.3848 - lr: 0.0010\n",
            "\n",
            "Epoch 916: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 916/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2967 - MAE: 0.7127\n",
            "Epoch 916: loss improved from 2.29671 to 2.29667, saving model to ./model_PID__0916_loss_2.297_vloss_0.343_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 2.2967 - MAE: 0.7127 - val_loss: 0.3435 - val_MAE: 0.3848 - lr: 0.0010\n",
            "\n",
            "Epoch 917: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 917/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2966 - MAE: 0.7127\n",
            "Epoch 917: loss improved from 2.29667 to 2.29663, saving model to ./model_PID__0917_loss_2.297_vloss_0.343_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 2.2966 - MAE: 0.7127 - val_loss: 0.3435 - val_MAE: 0.3848 - lr: 0.0010\n",
            "\n",
            "Epoch 918: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 918/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2966 - MAE: 0.7126\n",
            "Epoch 918: loss improved from 2.29663 to 2.29659, saving model to ./model_PID__0918_loss_2.297_vloss_0.344_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 2.2966 - MAE: 0.7126 - val_loss: 0.3435 - val_MAE: 0.3848 - lr: 0.0010\n",
            "\n",
            "Epoch 919: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 919/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2965 - MAE: 0.7126\n",
            "Epoch 919: loss improved from 2.29659 to 2.29655, saving model to ./model_PID__0919_loss_2.297_vloss_0.344_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 2.2965 - MAE: 0.7126 - val_loss: 0.3435 - val_MAE: 0.3848 - lr: 0.0010\n",
            "\n",
            "Epoch 920: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 920/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2965 - MAE: 0.7126\n",
            "Epoch 920: loss improved from 2.29655 to 2.29651, saving model to ./model_PID__0920_loss_2.297_vloss_0.344_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 2.2965 - MAE: 0.7126 - val_loss: 0.3436 - val_MAE: 0.3848 - lr: 0.0010\n",
            "\n",
            "Epoch 921: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 921/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2965 - MAE: 0.7126\n",
            "Epoch 921: loss improved from 2.29651 to 2.29646, saving model to ./model_PID__0921_loss_2.296_vloss_0.344_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 2.2965 - MAE: 0.7126 - val_loss: 0.3436 - val_MAE: 0.3848 - lr: 0.0010\n",
            "\n",
            "Epoch 922: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 922/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2964 - MAE: 0.7125\n",
            "Epoch 922: loss improved from 2.29646 to 2.29642, saving model to ./model_PID__0922_loss_2.296_vloss_0.344_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 2.2964 - MAE: 0.7125 - val_loss: 0.3436 - val_MAE: 0.3848 - lr: 0.0010\n",
            "\n",
            "Epoch 923: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 923/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2964 - MAE: 0.7125\n",
            "Epoch 923: loss improved from 2.29642 to 2.29638, saving model to ./model_PID__0923_loss_2.296_vloss_0.344_acc_0.713_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.2964 - MAE: 0.7125 - val_loss: 0.3436 - val_MAE: 0.3848 - lr: 0.0010\n",
            "\n",
            "Epoch 924: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 924/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2963 - MAE: 0.7125\n",
            "Epoch 924: loss improved from 2.29638 to 2.29633, saving model to ./model_PID__0924_loss_2.296_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 2.2963 - MAE: 0.7125 - val_loss: 0.3436 - val_MAE: 0.3849 - lr: 0.0010\n",
            "\n",
            "Epoch 925: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 925/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2963 - MAE: 0.7125\n",
            "Epoch 925: loss improved from 2.29633 to 2.29629, saving model to ./model_PID__0925_loss_2.296_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 2.2963 - MAE: 0.7125 - val_loss: 0.3436 - val_MAE: 0.3849 - lr: 0.0010\n",
            "\n",
            "Epoch 926: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 926/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2962 - MAE: 0.7124\n",
            "Epoch 926: loss improved from 2.29629 to 2.29625, saving model to ./model_PID__0926_loss_2.296_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 2.2962 - MAE: 0.7124 - val_loss: 0.3437 - val_MAE: 0.3849 - lr: 0.0010\n",
            "\n",
            "Epoch 927: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 927/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2962 - MAE: 0.7124\n",
            "Epoch 927: loss improved from 2.29625 to 2.29620, saving model to ./model_PID__0927_loss_2.296_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 2.2962 - MAE: 0.7124 - val_loss: 0.3437 - val_MAE: 0.3849 - lr: 0.0010\n",
            "\n",
            "Epoch 928: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 928/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2962 - MAE: 0.7124\n",
            "Epoch 928: loss improved from 2.29620 to 2.29616, saving model to ./model_PID__0928_loss_2.296_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2.2962 - MAE: 0.7124 - val_loss: 0.3437 - val_MAE: 0.3849 - lr: 0.0010\n",
            "\n",
            "Epoch 929: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 929/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2961 - MAE: 0.7124\n",
            "Epoch 929: loss improved from 2.29616 to 2.29611, saving model to ./model_PID__0929_loss_2.296_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 2.2961 - MAE: 0.7124 - val_loss: 0.3437 - val_MAE: 0.3849 - lr: 0.0010\n",
            "\n",
            "Epoch 930: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 930/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2961 - MAE: 0.7123\n",
            "Epoch 930: loss improved from 2.29611 to 2.29607, saving model to ./model_PID__0930_loss_2.296_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.2961 - MAE: 0.7123 - val_loss: 0.3437 - val_MAE: 0.3849 - lr: 0.0010\n",
            "\n",
            "Epoch 931: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 931/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2960 - MAE: 0.7123\n",
            "Epoch 931: loss improved from 2.29607 to 2.29602, saving model to ./model_PID__0931_loss_2.296_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 2.2960 - MAE: 0.7123 - val_loss: 0.3437 - val_MAE: 0.3849 - lr: 0.0010\n",
            "\n",
            "Epoch 932: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 932/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2960 - MAE: 0.7123\n",
            "Epoch 932: loss improved from 2.29602 to 2.29597, saving model to ./model_PID__0932_loss_2.296_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 2.2960 - MAE: 0.7123 - val_loss: 0.3438 - val_MAE: 0.3849 - lr: 0.0010\n",
            "\n",
            "Epoch 933: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 933/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2959 - MAE: 0.7123\n",
            "Epoch 933: loss improved from 2.29597 to 2.29593, saving model to ./model_PID__0933_loss_2.296_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 2.2959 - MAE: 0.7123 - val_loss: 0.3438 - val_MAE: 0.3849 - lr: 0.0010\n",
            "\n",
            "Epoch 934: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 934/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2959 - MAE: 0.7122\n",
            "Epoch 934: loss improved from 2.29593 to 2.29588, saving model to ./model_PID__0934_loss_2.296_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2.2959 - MAE: 0.7122 - val_loss: 0.3438 - val_MAE: 0.3849 - lr: 0.0010\n",
            "\n",
            "Epoch 935: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 935/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2958 - MAE: 0.7122\n",
            "Epoch 935: loss improved from 2.29588 to 2.29583, saving model to ./model_PID__0935_loss_2.296_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 2.2958 - MAE: 0.7122 - val_loss: 0.3438 - val_MAE: 0.3849 - lr: 0.0010\n",
            "\n",
            "Epoch 936: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 936/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2958 - MAE: 0.7122\n",
            "Epoch 936: loss improved from 2.29583 to 2.29579, saving model to ./model_PID__0936_loss_2.296_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 2.2958 - MAE: 0.7122 - val_loss: 0.3438 - val_MAE: 0.3849 - lr: 0.0010\n",
            "\n",
            "Epoch 937: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 937/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2957 - MAE: 0.7122\n",
            "Epoch 937: loss improved from 2.29579 to 2.29574, saving model to ./model_PID__0937_loss_2.296_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 2.2957 - MAE: 0.7122 - val_loss: 0.3438 - val_MAE: 0.3849 - lr: 0.0010\n",
            "\n",
            "Epoch 938: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 938/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2957 - MAE: 0.7121\n",
            "Epoch 938: loss improved from 2.29574 to 2.29569, saving model to ./model_PID__0938_loss_2.296_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 2.2957 - MAE: 0.7121 - val_loss: 0.3439 - val_MAE: 0.3849 - lr: 0.0010\n",
            "\n",
            "Epoch 939: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 939/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2956 - MAE: 0.7121\n",
            "Epoch 939: loss improved from 2.29569 to 2.29564, saving model to ./model_PID__0939_loss_2.296_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 2.2956 - MAE: 0.7121 - val_loss: 0.3439 - val_MAE: 0.3849 - lr: 0.0010\n",
            "\n",
            "Epoch 940: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 940/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2956 - MAE: 0.7121\n",
            "Epoch 940: loss improved from 2.29564 to 2.29559, saving model to ./model_PID__0940_loss_2.296_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 2.2956 - MAE: 0.7121 - val_loss: 0.3439 - val_MAE: 0.3850 - lr: 0.0010\n",
            "\n",
            "Epoch 941: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 941/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2955 - MAE: 0.7121\n",
            "Epoch 941: loss improved from 2.29559 to 2.29554, saving model to ./model_PID__0941_loss_2.296_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 2.2955 - MAE: 0.7121 - val_loss: 0.3439 - val_MAE: 0.3850 - lr: 0.0010\n",
            "\n",
            "Epoch 942: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 942/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2955 - MAE: 0.7120\n",
            "Epoch 942: loss improved from 2.29554 to 2.29549, saving model to ./model_PID__0942_loss_2.295_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 2.2955 - MAE: 0.7120 - val_loss: 0.3439 - val_MAE: 0.3850 - lr: 0.0010\n",
            "\n",
            "Epoch 943: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 943/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2954 - MAE: 0.7120\n",
            "Epoch 943: loss improved from 2.29549 to 2.29544, saving model to ./model_PID__0943_loss_2.295_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 2.2954 - MAE: 0.7120 - val_loss: 0.3439 - val_MAE: 0.3850 - lr: 0.0010\n",
            "\n",
            "Epoch 944: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 944/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2954 - MAE: 0.7120\n",
            "Epoch 944: loss improved from 2.29544 to 2.29539, saving model to ./model_PID__0944_loss_2.295_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 2.2954 - MAE: 0.7120 - val_loss: 0.3440 - val_MAE: 0.3850 - lr: 0.0010\n",
            "\n",
            "Epoch 945: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 945/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2953 - MAE: 0.7120\n",
            "Epoch 945: loss improved from 2.29539 to 2.29534, saving model to ./model_PID__0945_loss_2.295_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 2.2953 - MAE: 0.7120 - val_loss: 0.3440 - val_MAE: 0.3850 - lr: 0.0010\n",
            "\n",
            "Epoch 946: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 946/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2953 - MAE: 0.7119\n",
            "Epoch 946: loss improved from 2.29534 to 2.29529, saving model to ./model_PID__0946_loss_2.295_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 2.2953 - MAE: 0.7119 - val_loss: 0.3440 - val_MAE: 0.3850 - lr: 0.0010\n",
            "\n",
            "Epoch 947: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 947/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2952 - MAE: 0.7119\n",
            "Epoch 947: loss improved from 2.29529 to 2.29524, saving model to ./model_PID__0947_loss_2.295_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 2.2952 - MAE: 0.7119 - val_loss: 0.3440 - val_MAE: 0.3850 - lr: 0.0010\n",
            "\n",
            "Epoch 948: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 948/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2952 - MAE: 0.7119\n",
            "Epoch 948: loss improved from 2.29524 to 2.29519, saving model to ./model_PID__0948_loss_2.295_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 2.2952 - MAE: 0.7119 - val_loss: 0.3440 - val_MAE: 0.3850 - lr: 0.0010\n",
            "\n",
            "Epoch 949: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 949/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2951 - MAE: 0.7119\n",
            "Epoch 949: loss improved from 2.29519 to 2.29514, saving model to ./model_PID__0949_loss_2.295_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 2.2951 - MAE: 0.7119 - val_loss: 0.3441 - val_MAE: 0.3850 - lr: 0.0010\n",
            "\n",
            "Epoch 950: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 950/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2951 - MAE: 0.7119\n",
            "Epoch 950: loss improved from 2.29514 to 2.29509, saving model to ./model_PID__0950_loss_2.295_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 2.2951 - MAE: 0.7119 - val_loss: 0.3441 - val_MAE: 0.3850 - lr: 0.0010\n",
            "\n",
            "Epoch 951: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 951/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2950 - MAE: 0.7118\n",
            "Epoch 951: loss improved from 2.29509 to 2.29503, saving model to ./model_PID__0951_loss_2.295_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 2.2950 - MAE: 0.7118 - val_loss: 0.3441 - val_MAE: 0.3850 - lr: 0.0010\n",
            "\n",
            "Epoch 952: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 952/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2950 - MAE: 0.7118\n",
            "Epoch 952: loss improved from 2.29503 to 2.29498, saving model to ./model_PID__0952_loss_2.295_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 2.2950 - MAE: 0.7118 - val_loss: 0.3441 - val_MAE: 0.3850 - lr: 0.0010\n",
            "\n",
            "Epoch 953: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 953/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2949 - MAE: 0.7118\n",
            "Epoch 953: loss improved from 2.29498 to 2.29493, saving model to ./model_PID__0953_loss_2.295_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 2.2949 - MAE: 0.7118 - val_loss: 0.3441 - val_MAE: 0.3850 - lr: 0.0010\n",
            "\n",
            "Epoch 954: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 954/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2949 - MAE: 0.7118\n",
            "Epoch 954: loss improved from 2.29493 to 2.29488, saving model to ./model_PID__0954_loss_2.295_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 2.2949 - MAE: 0.7118 - val_loss: 0.3441 - val_MAE: 0.3851 - lr: 0.0010\n",
            "\n",
            "Epoch 955: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 955/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2948 - MAE: 0.7117\n",
            "Epoch 955: loss improved from 2.29488 to 2.29483, saving model to ./model_PID__0955_loss_2.295_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 2.2948 - MAE: 0.7117 - val_loss: 0.3442 - val_MAE: 0.3851 - lr: 0.0010\n",
            "\n",
            "Epoch 956: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 956/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2948 - MAE: 0.7117\n",
            "Epoch 956: loss improved from 2.29483 to 2.29477, saving model to ./model_PID__0956_loss_2.295_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 2.2948 - MAE: 0.7117 - val_loss: 0.3442 - val_MAE: 0.3851 - lr: 0.0010\n",
            "\n",
            "Epoch 957: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 957/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2947 - MAE: 0.7117\n",
            "Epoch 957: loss improved from 2.29477 to 2.29472, saving model to ./model_PID__0957_loss_2.295_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 2.2947 - MAE: 0.7117 - val_loss: 0.3442 - val_MAE: 0.3851 - lr: 0.0010\n",
            "\n",
            "Epoch 958: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 958/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2947 - MAE: 0.7117\n",
            "Epoch 958: loss improved from 2.29472 to 2.29467, saving model to ./model_PID__0958_loss_2.295_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 2.2947 - MAE: 0.7117 - val_loss: 0.3442 - val_MAE: 0.3851 - lr: 0.0010\n",
            "\n",
            "Epoch 959: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 959/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2946 - MAE: 0.7116\n",
            "Epoch 959: loss improved from 2.29467 to 2.29461, saving model to ./model_PID__0959_loss_2.295_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 2.2946 - MAE: 0.7116 - val_loss: 0.3442 - val_MAE: 0.3851 - lr: 0.0010\n",
            "\n",
            "Epoch 960: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 960/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2946 - MAE: 0.7116\n",
            "Epoch 960: loss improved from 2.29461 to 2.29456, saving model to ./model_PID__0960_loss_2.295_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 2.2946 - MAE: 0.7116 - val_loss: 0.3443 - val_MAE: 0.3851 - lr: 0.0010\n",
            "\n",
            "Epoch 961: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 961/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2945 - MAE: 0.7116\n",
            "Epoch 961: loss improved from 2.29456 to 2.29451, saving model to ./model_PID__0961_loss_2.295_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 2.2945 - MAE: 0.7116 - val_loss: 0.3443 - val_MAE: 0.3851 - lr: 0.0010\n",
            "\n",
            "Epoch 962: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 962/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2945 - MAE: 0.7116\n",
            "Epoch 962: loss improved from 2.29451 to 2.29446, saving model to ./model_PID__0962_loss_2.294_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 2.2945 - MAE: 0.7116 - val_loss: 0.3443 - val_MAE: 0.3851 - lr: 0.0010\n",
            "\n",
            "Epoch 963: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 963/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2944 - MAE: 0.7115\n",
            "Epoch 963: loss improved from 2.29446 to 2.29440, saving model to ./model_PID__0963_loss_2.294_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 2.2944 - MAE: 0.7115 - val_loss: 0.3443 - val_MAE: 0.3851 - lr: 0.0010\n",
            "\n",
            "Epoch 964: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 964/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2944 - MAE: 0.7115\n",
            "Epoch 964: loss improved from 2.29440 to 2.29435, saving model to ./model_PID__0964_loss_2.294_vloss_0.344_acc_0.712_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 2.2944 - MAE: 0.7115 - val_loss: 0.3443 - val_MAE: 0.3851 - lr: 0.0010\n",
            "\n",
            "Epoch 965: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 965/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2943 - MAE: 0.7115\n",
            "Epoch 965: loss improved from 2.29435 to 2.29430, saving model to ./model_PID__0965_loss_2.294_vloss_0.344_acc_0.711_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 2.2943 - MAE: 0.7115 - val_loss: 0.3444 - val_MAE: 0.3852 - lr: 0.0010\n",
            "\n",
            "Epoch 966: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 966/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2942 - MAE: 0.7115\n",
            "Epoch 966: loss improved from 2.29430 to 2.29425, saving model to ./model_PID__0966_loss_2.294_vloss_0.344_acc_0.711_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.2942 - MAE: 0.7115 - val_loss: 0.3444 - val_MAE: 0.3852 - lr: 0.0010\n",
            "\n",
            "Epoch 967: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 967/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2942 - MAE: 0.7114\n",
            "Epoch 967: loss improved from 2.29425 to 2.29419, saving model to ./model_PID__0967_loss_2.294_vloss_0.344_acc_0.711_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 2.2942 - MAE: 0.7114 - val_loss: 0.3444 - val_MAE: 0.3852 - lr: 0.0010\n",
            "\n",
            "Epoch 968: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 968/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2941 - MAE: 0.7114\n",
            "Epoch 968: loss improved from 2.29419 to 2.29414, saving model to ./model_PID__0968_loss_2.294_vloss_0.344_acc_0.711_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 2.2941 - MAE: 0.7114 - val_loss: 0.3444 - val_MAE: 0.3852 - lr: 0.0010\n",
            "\n",
            "Epoch 969: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 969/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2941 - MAE: 0.7114\n",
            "Epoch 969: loss improved from 2.29414 to 2.29409, saving model to ./model_PID__0969_loss_2.294_vloss_0.344_acc_0.711_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 2.2941 - MAE: 0.7114 - val_loss: 0.3444 - val_MAE: 0.3852 - lr: 0.0010\n",
            "\n",
            "Epoch 970: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 970/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2940 - MAE: 0.7114\n",
            "Epoch 970: loss improved from 2.29409 to 2.29404, saving model to ./model_PID__0970_loss_2.294_vloss_0.344_acc_0.711_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 2.2940 - MAE: 0.7114 - val_loss: 0.3445 - val_MAE: 0.3852 - lr: 0.0010\n",
            "\n",
            "Epoch 971: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 971/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2940 - MAE: 0.7113\n",
            "Epoch 971: loss improved from 2.29404 to 2.29398, saving model to ./model_PID__0971_loss_2.294_vloss_0.344_acc_0.711_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 2.2940 - MAE: 0.7113 - val_loss: 0.3445 - val_MAE: 0.3852 - lr: 0.0010\n",
            "\n",
            "Epoch 972: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 972/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2939 - MAE: 0.7113\n",
            "Epoch 972: loss improved from 2.29398 to 2.29393, saving model to ./model_PID__0972_loss_2.294_vloss_0.345_acc_0.711_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 2.2939 - MAE: 0.7113 - val_loss: 0.3445 - val_MAE: 0.3852 - lr: 0.0010\n",
            "\n",
            "Epoch 973: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 973/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2939 - MAE: 0.7113\n",
            "Epoch 973: loss improved from 2.29393 to 2.29388, saving model to ./model_PID__0973_loss_2.294_vloss_0.345_acc_0.711_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.2939 - MAE: 0.7113 - val_loss: 0.3445 - val_MAE: 0.3852 - lr: 0.0010\n",
            "\n",
            "Epoch 974: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 974/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2938 - MAE: 0.7113\n",
            "Epoch 974: loss improved from 2.29388 to 2.29383, saving model to ./model_PID__0974_loss_2.294_vloss_0.345_acc_0.711_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 2.2938 - MAE: 0.7113 - val_loss: 0.3445 - val_MAE: 0.3852 - lr: 0.0010\n",
            "\n",
            "Epoch 975: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 975/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2938 - MAE: 0.7112\n",
            "Epoch 975: loss improved from 2.29383 to 2.29378, saving model to ./model_PID__0975_loss_2.294_vloss_0.345_acc_0.711_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 2.2938 - MAE: 0.7112 - val_loss: 0.3446 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 976: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 976/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2937 - MAE: 0.7112\n",
            "Epoch 976: loss improved from 2.29378 to 2.29372, saving model to ./model_PID__0976_loss_2.294_vloss_0.345_acc_0.711_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2.2937 - MAE: 0.7112 - val_loss: 0.3446 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 977: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 977/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2937 - MAE: 0.7112\n",
            "Epoch 977: loss improved from 2.29372 to 2.29367, saving model to ./model_PID__0977_loss_2.294_vloss_0.345_acc_0.711_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.2937 - MAE: 0.7112 - val_loss: 0.3446 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 978: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 978/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2936 - MAE: 0.7112\n",
            "Epoch 978: loss improved from 2.29367 to 2.29362, saving model to ./model_PID__0978_loss_2.294_vloss_0.345_acc_0.711_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 2.2936 - MAE: 0.7112 - val_loss: 0.3446 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 979: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 979/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2936 - MAE: 0.7112\n",
            "Epoch 979: loss improved from 2.29362 to 2.29357, saving model to ./model_PID__0979_loss_2.294_vloss_0.345_acc_0.711_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.2936 - MAE: 0.7112 - val_loss: 0.3447 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 980: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 980/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2935 - MAE: 0.7111\n",
            "Epoch 980: loss improved from 2.29357 to 2.29352, saving model to ./model_PID__0980_loss_2.294_vloss_0.345_acc_0.711_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 2.2935 - MAE: 0.7111 - val_loss: 0.3447 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 981: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 981/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2935 - MAE: 0.7111\n",
            "Epoch 981: loss improved from 2.29352 to 2.29347, saving model to ./model_PID__0981_loss_2.293_vloss_0.345_acc_0.711_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 2.2935 - MAE: 0.7111 - val_loss: 0.3447 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 982: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 982/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2934 - MAE: 0.7111\n",
            "Epoch 982: loss improved from 2.29347 to 2.29341, saving model to ./model_PID__0982_loss_2.293_vloss_0.345_acc_0.711_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 2.2934 - MAE: 0.7111 - val_loss: 0.3447 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 983: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 983/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2934 - MAE: 0.7111\n",
            "Epoch 983: loss improved from 2.29341 to 2.29336, saving model to ./model_PID__0983_loss_2.293_vloss_0.345_acc_0.711_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 2.2934 - MAE: 0.7111 - val_loss: 0.3447 - val_MAE: 0.3853 - lr: 0.0010\n",
            "\n",
            "Epoch 984: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 984/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2933 - MAE: 0.7110\n",
            "Epoch 984: loss improved from 2.29336 to 2.29331, saving model to ./model_PID__0984_loss_2.293_vloss_0.345_acc_0.711_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 2.2933 - MAE: 0.7110 - val_loss: 0.3448 - val_MAE: 0.3854 - lr: 0.0010\n",
            "\n",
            "Epoch 985: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 985/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2933 - MAE: 0.7110\n",
            "Epoch 985: loss improved from 2.29331 to 2.29326, saving model to ./model_PID__0985_loss_2.293_vloss_0.345_acc_0.711_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 2.2933 - MAE: 0.7110 - val_loss: 0.3448 - val_MAE: 0.3854 - lr: 0.0010\n",
            "\n",
            "Epoch 986: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 986/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2932 - MAE: 0.7110\n",
            "Epoch 986: loss improved from 2.29326 to 2.29320, saving model to ./model_PID__0986_loss_2.293_vloss_0.345_acc_0.711_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 2.2932 - MAE: 0.7110 - val_loss: 0.3448 - val_MAE: 0.3854 - lr: 0.0010\n",
            "\n",
            "Epoch 987: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 987/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2932 - MAE: 0.7110\n",
            "Epoch 987: loss improved from 2.29320 to 2.29315, saving model to ./model_PID__0987_loss_2.293_vloss_0.345_acc_0.711_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 2.2932 - MAE: 0.7110 - val_loss: 0.3448 - val_MAE: 0.3854 - lr: 0.0010\n",
            "\n",
            "Epoch 988: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 988/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2931 - MAE: 0.7110\n",
            "Epoch 988: loss improved from 2.29315 to 2.29310, saving model to ./model_PID__0988_loss_2.293_vloss_0.345_acc_0.711_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.2931 - MAE: 0.7110 - val_loss: 0.3448 - val_MAE: 0.3854 - lr: 0.0010\n",
            "\n",
            "Epoch 989: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 989/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2930 - MAE: 0.7109\n",
            "Epoch 989: loss improved from 2.29310 to 2.29304, saving model to ./model_PID__0989_loss_2.293_vloss_0.345_acc_0.711_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 2.2930 - MAE: 0.7109 - val_loss: 0.3449 - val_MAE: 0.3854 - lr: 0.0010\n",
            "\n",
            "Epoch 990: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 990/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2930 - MAE: 0.7109\n",
            "Epoch 990: loss improved from 2.29304 to 2.29299, saving model to ./model_PID__0990_loss_2.293_vloss_0.345_acc_0.711_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.2930 - MAE: 0.7109 - val_loss: 0.3449 - val_MAE: 0.3854 - lr: 0.0010\n",
            "\n",
            "Epoch 991: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 991/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2929 - MAE: 0.7109\n",
            "Epoch 991: loss improved from 2.29299 to 2.29294, saving model to ./model_PID__0991_loss_2.293_vloss_0.345_acc_0.711_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.2929 - MAE: 0.7109 - val_loss: 0.3449 - val_MAE: 0.3854 - lr: 0.0010\n",
            "\n",
            "Epoch 992: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 992/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2929 - MAE: 0.7109\n",
            "Epoch 992: loss improved from 2.29294 to 2.29288, saving model to ./model_PID__0992_loss_2.293_vloss_0.345_acc_0.711_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 2.2929 - MAE: 0.7109 - val_loss: 0.3449 - val_MAE: 0.3854 - lr: 0.0010\n",
            "\n",
            "Epoch 993: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 993/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2928 - MAE: 0.7109\n",
            "Epoch 993: loss improved from 2.29288 to 2.29283, saving model to ./model_PID__0993_loss_2.293_vloss_0.345_acc_0.711_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 2.2928 - MAE: 0.7109 - val_loss: 0.3449 - val_MAE: 0.3855 - lr: 0.0010\n",
            "\n",
            "Epoch 994: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 994/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2928 - MAE: 0.7108\n",
            "Epoch 994: loss improved from 2.29283 to 2.29277, saving model to ./model_PID__0994_loss_2.293_vloss_0.345_acc_0.711_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.2928 - MAE: 0.7108 - val_loss: 0.3449 - val_MAE: 0.3855 - lr: 0.0010\n",
            "\n",
            "Epoch 995: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 995/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2927 - MAE: 0.7108\n",
            "Epoch 995: loss improved from 2.29277 to 2.29272, saving model to ./model_PID__0995_loss_2.293_vloss_0.345_acc_0.711_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 2.2927 - MAE: 0.7108 - val_loss: 0.3450 - val_MAE: 0.3855 - lr: 0.0010\n",
            "\n",
            "Epoch 996: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 996/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2927 - MAE: 0.7108\n",
            "Epoch 996: loss improved from 2.29272 to 2.29266, saving model to ./model_PID__0996_loss_2.293_vloss_0.345_acc_0.711_vacc_0.385.hdf5\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 2.2927 - MAE: 0.7108 - val_loss: 0.3450 - val_MAE: 0.3855 - lr: 0.0010\n",
            "\n",
            "Epoch 997: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 997/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2926 - MAE: 0.7108\n",
            "Epoch 997: loss improved from 2.29266 to 2.29260, saving model to ./model_PID__0997_loss_2.293_vloss_0.345_acc_0.711_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 2.2926 - MAE: 0.7108 - val_loss: 0.3450 - val_MAE: 0.3855 - lr: 0.0010\n",
            "\n",
            "Epoch 998: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 998/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2925 - MAE: 0.7107\n",
            "Epoch 998: loss improved from 2.29260 to 2.29254, saving model to ./model_PID__0998_loss_2.293_vloss_0.345_acc_0.711_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 2.2925 - MAE: 0.7107 - val_loss: 0.3450 - val_MAE: 0.3855 - lr: 0.0010\n",
            "\n",
            "Epoch 999: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 999/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2925 - MAE: 0.7107\n",
            "Epoch 999: loss improved from 2.29254 to 2.29249, saving model to ./model_PID__0999_loss_2.292_vloss_0.345_acc_0.711_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.2925 - MAE: 0.7107 - val_loss: 0.3450 - val_MAE: 0.3855 - lr: 0.0010\n",
            "\n",
            "Epoch 1000: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1000/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2924 - MAE: 0.7107\n",
            "Epoch 1000: loss improved from 2.29249 to 2.29243, saving model to ./model_PID__1000_loss_2.292_vloss_0.345_acc_0.711_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 2.2924 - MAE: 0.7107 - val_loss: 0.3450 - val_MAE: 0.3855 - lr: 0.0010\n",
            "\n",
            "Epoch 1001: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1001/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2924 - MAE: 0.7107\n",
            "Epoch 1001: loss improved from 2.29243 to 2.29237, saving model to ./model_PID__1001_loss_2.292_vloss_0.345_acc_0.711_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 2.2924 - MAE: 0.7107 - val_loss: 0.3450 - val_MAE: 0.3855 - lr: 0.0010\n",
            "\n",
            "Epoch 1002: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1002/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2923 - MAE: 0.7106\n",
            "Epoch 1002: loss improved from 2.29237 to 2.29231, saving model to ./model_PID__1002_loss_2.292_vloss_0.345_acc_0.711_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 2.2923 - MAE: 0.7106 - val_loss: 0.3451 - val_MAE: 0.3856 - lr: 0.0010\n",
            "\n",
            "Epoch 1003: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1003/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2922 - MAE: 0.7106\n",
            "Epoch 1003: loss improved from 2.29231 to 2.29225, saving model to ./model_PID__1003_loss_2.292_vloss_0.345_acc_0.711_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.2922 - MAE: 0.7106 - val_loss: 0.3451 - val_MAE: 0.3856 - lr: 0.0010\n",
            "\n",
            "Epoch 1004: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1004/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2922 - MAE: 0.7106\n",
            "Epoch 1004: loss improved from 2.29225 to 2.29218, saving model to ./model_PID__1004_loss_2.292_vloss_0.345_acc_0.711_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 2.2922 - MAE: 0.7106 - val_loss: 0.3451 - val_MAE: 0.3856 - lr: 0.0010\n",
            "\n",
            "Epoch 1005: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1005/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2921 - MAE: 0.7106\n",
            "Epoch 1005: loss improved from 2.29218 to 2.29212, saving model to ./model_PID__1005_loss_2.292_vloss_0.345_acc_0.711_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2.2921 - MAE: 0.7106 - val_loss: 0.3451 - val_MAE: 0.3856 - lr: 0.0010\n",
            "\n",
            "Epoch 1006: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1006/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2921 - MAE: 0.7105\n",
            "Epoch 1006: loss improved from 2.29212 to 2.29206, saving model to ./model_PID__1006_loss_2.292_vloss_0.345_acc_0.711_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 2.2921 - MAE: 0.7105 - val_loss: 0.3451 - val_MAE: 0.3856 - lr: 0.0010\n",
            "\n",
            "Epoch 1007: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1007/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2920 - MAE: 0.7105\n",
            "Epoch 1007: loss improved from 2.29206 to 2.29200, saving model to ./model_PID__1007_loss_2.292_vloss_0.345_acc_0.711_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 2.2920 - MAE: 0.7105 - val_loss: 0.3451 - val_MAE: 0.3856 - lr: 0.0010\n",
            "\n",
            "Epoch 1008: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1008/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2919 - MAE: 0.7105\n",
            "Epoch 1008: loss improved from 2.29200 to 2.29193, saving model to ./model_PID__1008_loss_2.292_vloss_0.345_acc_0.710_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 2.2919 - MAE: 0.7105 - val_loss: 0.3451 - val_MAE: 0.3856 - lr: 0.0010\n",
            "\n",
            "Epoch 1009: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1009/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2919 - MAE: 0.7105\n",
            "Epoch 1009: loss improved from 2.29193 to 2.29187, saving model to ./model_PID__1009_loss_2.292_vloss_0.345_acc_0.710_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 2.2919 - MAE: 0.7105 - val_loss: 0.3452 - val_MAE: 0.3856 - lr: 0.0010\n",
            "\n",
            "Epoch 1010: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1010/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2918 - MAE: 0.7104\n",
            "Epoch 1010: loss improved from 2.29187 to 2.29181, saving model to ./model_PID__1010_loss_2.292_vloss_0.345_acc_0.710_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 2.2918 - MAE: 0.7104 - val_loss: 0.3452 - val_MAE: 0.3857 - lr: 0.0010\n",
            "\n",
            "Epoch 1011: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1011/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2917 - MAE: 0.7104\n",
            "Epoch 1011: loss improved from 2.29181 to 2.29175, saving model to ./model_PID__1011_loss_2.292_vloss_0.345_acc_0.710_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 2.2917 - MAE: 0.7104 - val_loss: 0.3452 - val_MAE: 0.3857 - lr: 0.0010\n",
            "\n",
            "Epoch 1012: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1012/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2917 - MAE: 0.7104\n",
            "Epoch 1012: loss improved from 2.29175 to 2.29169, saving model to ./model_PID__1012_loss_2.292_vloss_0.345_acc_0.710_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 2.2917 - MAE: 0.7104 - val_loss: 0.3452 - val_MAE: 0.3857 - lr: 0.0010\n",
            "\n",
            "Epoch 1013: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1013/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2916 - MAE: 0.7103\n",
            "Epoch 1013: loss improved from 2.29169 to 2.29162, saving model to ./model_PID__1013_loss_2.292_vloss_0.345_acc_0.710_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 2.2916 - MAE: 0.7103 - val_loss: 0.3452 - val_MAE: 0.3857 - lr: 0.0010\n",
            "\n",
            "Epoch 1014: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1014/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2916 - MAE: 0.7103\n",
            "Epoch 1014: loss improved from 2.29162 to 2.29156, saving model to ./model_PID__1014_loss_2.292_vloss_0.345_acc_0.710_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 2.2916 - MAE: 0.7103 - val_loss: 0.3453 - val_MAE: 0.3857 - lr: 0.0010\n",
            "\n",
            "Epoch 1015: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1015/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2915 - MAE: 0.7103\n",
            "Epoch 1015: loss improved from 2.29156 to 2.29150, saving model to ./model_PID__1015_loss_2.292_vloss_0.345_acc_0.710_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 2.2915 - MAE: 0.7103 - val_loss: 0.3453 - val_MAE: 0.3857 - lr: 0.0010\n",
            "\n",
            "Epoch 1016: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1016/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2914 - MAE: 0.7102\n",
            "Epoch 1016: loss improved from 2.29150 to 2.29144, saving model to ./model_PID__1016_loss_2.291_vloss_0.345_acc_0.710_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 2.2914 - MAE: 0.7102 - val_loss: 0.3453 - val_MAE: 0.3858 - lr: 0.0010\n",
            "\n",
            "Epoch 1017: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1017/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2914 - MAE: 0.7102\n",
            "Epoch 1017: loss improved from 2.29144 to 2.29138, saving model to ./model_PID__1017_loss_2.291_vloss_0.345_acc_0.710_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 2.2914 - MAE: 0.7102 - val_loss: 0.3453 - val_MAE: 0.3858 - lr: 0.0010\n",
            "\n",
            "Epoch 1018: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1018/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2913 - MAE: 0.7102\n",
            "Epoch 1018: loss improved from 2.29138 to 2.29132, saving model to ./model_PID__1018_loss_2.291_vloss_0.345_acc_0.710_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 2.2913 - MAE: 0.7102 - val_loss: 0.3454 - val_MAE: 0.3858 - lr: 0.0010\n",
            "\n",
            "Epoch 1019: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1019/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2913 - MAE: 0.7101\n",
            "Epoch 1019: loss improved from 2.29132 to 2.29125, saving model to ./model_PID__1019_loss_2.291_vloss_0.345_acc_0.710_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 2.2913 - MAE: 0.7101 - val_loss: 0.3454 - val_MAE: 0.3858 - lr: 0.0010\n",
            "\n",
            "Epoch 1020: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1020/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2912 - MAE: 0.7101\n",
            "Epoch 1020: loss improved from 2.29125 to 2.29119, saving model to ./model_PID__1020_loss_2.291_vloss_0.345_acc_0.710_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 2.2912 - MAE: 0.7101 - val_loss: 0.3454 - val_MAE: 0.3859 - lr: 0.0010\n",
            "\n",
            "Epoch 1021: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1021/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2911 - MAE: 0.7101\n",
            "Epoch 1021: loss improved from 2.29119 to 2.29113, saving model to ./model_PID__1021_loss_2.291_vloss_0.345_acc_0.710_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.2911 - MAE: 0.7101 - val_loss: 0.3455 - val_MAE: 0.3859 - lr: 0.0010\n",
            "\n",
            "Epoch 1022: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1022/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2911 - MAE: 0.7100\n",
            "Epoch 1022: loss improved from 2.29113 to 2.29107, saving model to ./model_PID__1022_loss_2.291_vloss_0.346_acc_0.710_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 2.2911 - MAE: 0.7100 - val_loss: 0.3455 - val_MAE: 0.3859 - lr: 0.0010\n",
            "\n",
            "Epoch 1023: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1023/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2910 - MAE: 0.7100\n",
            "Epoch 1023: loss improved from 2.29107 to 2.29100, saving model to ./model_PID__1023_loss_2.291_vloss_0.346_acc_0.710_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.2910 - MAE: 0.7100 - val_loss: 0.3456 - val_MAE: 0.3859 - lr: 0.0010\n",
            "\n",
            "Epoch 1024: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1024/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2909 - MAE: 0.7100\n",
            "Epoch 1024: loss improved from 2.29100 to 2.29094, saving model to ./model_PID__1024_loss_2.291_vloss_0.346_acc_0.710_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 2.2909 - MAE: 0.7100 - val_loss: 0.3456 - val_MAE: 0.3860 - lr: 0.0010\n",
            "\n",
            "Epoch 1025: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1025/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2909 - MAE: 0.7099\n",
            "Epoch 1025: loss improved from 2.29094 to 2.29087, saving model to ./model_PID__1025_loss_2.291_vloss_0.346_acc_0.710_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 2.2909 - MAE: 0.7099 - val_loss: 0.3456 - val_MAE: 0.3860 - lr: 0.0010\n",
            "\n",
            "Epoch 1026: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1026/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2908 - MAE: 0.7099\n",
            "Epoch 1026: loss improved from 2.29087 to 2.29081, saving model to ./model_PID__1026_loss_2.291_vloss_0.346_acc_0.710_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 2.2908 - MAE: 0.7099 - val_loss: 0.3457 - val_MAE: 0.3860 - lr: 0.0010\n",
            "\n",
            "Epoch 1027: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1027/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2907 - MAE: 0.7099\n",
            "Epoch 1027: loss improved from 2.29081 to 2.29074, saving model to ./model_PID__1027_loss_2.291_vloss_0.346_acc_0.710_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.2907 - MAE: 0.7099 - val_loss: 0.3457 - val_MAE: 0.3861 - lr: 0.0010\n",
            "\n",
            "Epoch 1028: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1028/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2907 - MAE: 0.7099\n",
            "Epoch 1028: loss improved from 2.29074 to 2.29067, saving model to ./model_PID__1028_loss_2.291_vloss_0.346_acc_0.710_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.2907 - MAE: 0.7099 - val_loss: 0.3457 - val_MAE: 0.3861 - lr: 0.0010\n",
            "\n",
            "Epoch 1029: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1029/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2906 - MAE: 0.7098\n",
            "Epoch 1029: loss improved from 2.29067 to 2.29061, saving model to ./model_PID__1029_loss_2.291_vloss_0.346_acc_0.710_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 2.2906 - MAE: 0.7098 - val_loss: 0.3458 - val_MAE: 0.3861 - lr: 0.0010\n",
            "\n",
            "Epoch 1030: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1030/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2905 - MAE: 0.7098\n",
            "Epoch 1030: loss improved from 2.29061 to 2.29054, saving model to ./model_PID__1030_loss_2.291_vloss_0.346_acc_0.710_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 2.2905 - MAE: 0.7098 - val_loss: 0.3458 - val_MAE: 0.3862 - lr: 0.0010\n",
            "\n",
            "Epoch 1031: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1031/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2905 - MAE: 0.7098\n",
            "Epoch 1031: loss improved from 2.29054 to 2.29047, saving model to ./model_PID__1031_loss_2.290_vloss_0.346_acc_0.710_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 2.2905 - MAE: 0.7098 - val_loss: 0.3459 - val_MAE: 0.3862 - lr: 0.0010\n",
            "\n",
            "Epoch 1032: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1032/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2904 - MAE: 0.7097\n",
            "Epoch 1032: loss improved from 2.29047 to 2.29040, saving model to ./model_PID__1032_loss_2.290_vloss_0.346_acc_0.710_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 2.2904 - MAE: 0.7097 - val_loss: 0.3459 - val_MAE: 0.3862 - lr: 0.0010\n",
            "\n",
            "Epoch 1033: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1033/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2903 - MAE: 0.7097\n",
            "Epoch 1033: loss improved from 2.29040 to 2.29033, saving model to ./model_PID__1033_loss_2.290_vloss_0.346_acc_0.710_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 2.2903 - MAE: 0.7097 - val_loss: 0.3459 - val_MAE: 0.3863 - lr: 0.0010\n",
            "\n",
            "Epoch 1034: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1034/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2903 - MAE: 0.7096\n",
            "Epoch 1034: loss improved from 2.29033 to 2.29026, saving model to ./model_PID__1034_loss_2.290_vloss_0.346_acc_0.710_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 2.2903 - MAE: 0.7096 - val_loss: 0.3460 - val_MAE: 0.3863 - lr: 0.0010\n",
            "\n",
            "Epoch 1035: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1035/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2902 - MAE: 0.7096\n",
            "Epoch 1035: loss improved from 2.29026 to 2.29019, saving model to ./model_PID__1035_loss_2.290_vloss_0.346_acc_0.710_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 2.2902 - MAE: 0.7096 - val_loss: 0.3460 - val_MAE: 0.3863 - lr: 0.0010\n",
            "\n",
            "Epoch 1036: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1036/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2901 - MAE: 0.7096\n",
            "Epoch 1036: loss improved from 2.29019 to 2.29012, saving model to ./model_PID__1036_loss_2.290_vloss_0.346_acc_0.710_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 2.2901 - MAE: 0.7096 - val_loss: 0.3461 - val_MAE: 0.3863 - lr: 0.0010\n",
            "\n",
            "Epoch 1037: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1037/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2900 - MAE: 0.7096\n",
            "Epoch 1037: loss improved from 2.29012 to 2.29004, saving model to ./model_PID__1037_loss_2.290_vloss_0.346_acc_0.710_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 2.2900 - MAE: 0.7096 - val_loss: 0.3461 - val_MAE: 0.3864 - lr: 0.0010\n",
            "\n",
            "Epoch 1038: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1038/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2900 - MAE: 0.7095\n",
            "Epoch 1038: loss improved from 2.29004 to 2.28997, saving model to ./model_PID__1038_loss_2.290_vloss_0.346_acc_0.710_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 2.2900 - MAE: 0.7095 - val_loss: 0.3461 - val_MAE: 0.3864 - lr: 0.0010\n",
            "\n",
            "Epoch 1039: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1039/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2899 - MAE: 0.7095\n",
            "Epoch 1039: loss improved from 2.28997 to 2.28990, saving model to ./model_PID__1039_loss_2.290_vloss_0.346_acc_0.709_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.2899 - MAE: 0.7095 - val_loss: 0.3462 - val_MAE: 0.3864 - lr: 0.0010\n",
            "\n",
            "Epoch 1040: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1040/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2898 - MAE: 0.7095\n",
            "Epoch 1040: loss improved from 2.28990 to 2.28982, saving model to ./model_PID__1040_loss_2.290_vloss_0.346_acc_0.709_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.2898 - MAE: 0.7095 - val_loss: 0.3462 - val_MAE: 0.3864 - lr: 0.0010\n",
            "\n",
            "Epoch 1041: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1041/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2897 - MAE: 0.7094\n",
            "Epoch 1041: loss improved from 2.28982 to 2.28975, saving model to ./model_PID__1041_loss_2.290_vloss_0.346_acc_0.709_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 2.2897 - MAE: 0.7094 - val_loss: 0.3462 - val_MAE: 0.3865 - lr: 0.0010\n",
            "\n",
            "Epoch 1042: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1042/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2897 - MAE: 0.7094\n",
            "Epoch 1042: loss improved from 2.28975 to 2.28968, saving model to ./model_PID__1042_loss_2.290_vloss_0.346_acc_0.709_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 2.2897 - MAE: 0.7094 - val_loss: 0.3463 - val_MAE: 0.3865 - lr: 0.0010\n",
            "\n",
            "Epoch 1043: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1043/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2896 - MAE: 0.7094\n",
            "Epoch 1043: loss improved from 2.28968 to 2.28960, saving model to ./model_PID__1043_loss_2.290_vloss_0.346_acc_0.709_vacc_0.386.hdf5\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 2.2896 - MAE: 0.7094 - val_loss: 0.3463 - val_MAE: 0.3865 - lr: 0.0010\n",
            "\n",
            "Epoch 1044: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1044/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2895 - MAE: 0.7093\n",
            "Epoch 1044: loss improved from 2.28960 to 2.28953, saving model to ./model_PID__1044_loss_2.290_vloss_0.346_acc_0.709_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 2.2895 - MAE: 0.7093 - val_loss: 0.3463 - val_MAE: 0.3865 - lr: 0.0010\n",
            "\n",
            "Epoch 1045: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1045/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2895 - MAE: 0.7093\n",
            "Epoch 1045: loss improved from 2.28953 to 2.28945, saving model to ./model_PID__1045_loss_2.289_vloss_0.346_acc_0.709_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 2.2895 - MAE: 0.7093 - val_loss: 0.3464 - val_MAE: 0.3865 - lr: 0.0010\n",
            "\n",
            "Epoch 1046: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1046/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2894 - MAE: 0.7093\n",
            "Epoch 1046: loss improved from 2.28945 to 2.28938, saving model to ./model_PID__1046_loss_2.289_vloss_0.346_acc_0.709_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 2.2894 - MAE: 0.7093 - val_loss: 0.3464 - val_MAE: 0.3865 - lr: 0.0010\n",
            "\n",
            "Epoch 1047: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1047/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2893 - MAE: 0.7092\n",
            "Epoch 1047: loss improved from 2.28938 to 2.28931, saving model to ./model_PID__1047_loss_2.289_vloss_0.346_acc_0.709_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 2.2893 - MAE: 0.7092 - val_loss: 0.3464 - val_MAE: 0.3865 - lr: 0.0010\n",
            "\n",
            "Epoch 1048: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1048/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2892 - MAE: 0.7092\n",
            "Epoch 1048: loss improved from 2.28931 to 2.28923, saving model to ./model_PID__1048_loss_2.289_vloss_0.346_acc_0.709_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.2892 - MAE: 0.7092 - val_loss: 0.3464 - val_MAE: 0.3865 - lr: 0.0010\n",
            "\n",
            "Epoch 1049: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1049/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2892 - MAE: 0.7092\n",
            "Epoch 1049: loss improved from 2.28923 to 2.28916, saving model to ./model_PID__1049_loss_2.289_vloss_0.346_acc_0.709_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.2892 - MAE: 0.7092 - val_loss: 0.3465 - val_MAE: 0.3866 - lr: 0.0010\n",
            "\n",
            "Epoch 1050: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1050/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2891 - MAE: 0.7091\n",
            "Epoch 1050: loss improved from 2.28916 to 2.28909, saving model to ./model_PID__1050_loss_2.289_vloss_0.347_acc_0.709_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 2.2891 - MAE: 0.7091 - val_loss: 0.3465 - val_MAE: 0.3866 - lr: 0.0010\n",
            "\n",
            "Epoch 1051: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1051/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2890 - MAE: 0.7091\n",
            "Epoch 1051: loss improved from 2.28909 to 2.28901, saving model to ./model_PID__1051_loss_2.289_vloss_0.347_acc_0.709_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 2.2890 - MAE: 0.7091 - val_loss: 0.3465 - val_MAE: 0.3866 - lr: 0.0010\n",
            "\n",
            "Epoch 1052: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1052/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2889 - MAE: 0.7091\n",
            "Epoch 1052: loss improved from 2.28901 to 2.28894, saving model to ./model_PID__1052_loss_2.289_vloss_0.347_acc_0.709_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 2.2889 - MAE: 0.7091 - val_loss: 0.3466 - val_MAE: 0.3866 - lr: 0.0010\n",
            "\n",
            "Epoch 1053: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1053/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2889 - MAE: 0.7090\n",
            "Epoch 1053: loss improved from 2.28894 to 2.28887, saving model to ./model_PID__1053_loss_2.289_vloss_0.347_acc_0.709_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 2.2889 - MAE: 0.7090 - val_loss: 0.3466 - val_MAE: 0.3866 - lr: 0.0010\n",
            "\n",
            "Epoch 1054: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1054/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2888 - MAE: 0.7090\n",
            "Epoch 1054: loss improved from 2.28887 to 2.28879, saving model to ./model_PID__1054_loss_2.289_vloss_0.347_acc_0.709_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 2.2888 - MAE: 0.7090 - val_loss: 0.3466 - val_MAE: 0.3866 - lr: 0.0010\n",
            "\n",
            "Epoch 1055: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1055/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2887 - MAE: 0.7090\n",
            "Epoch 1055: loss improved from 2.28879 to 2.28872, saving model to ./model_PID__1055_loss_2.289_vloss_0.347_acc_0.709_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 2.2887 - MAE: 0.7090 - val_loss: 0.3466 - val_MAE: 0.3866 - lr: 0.0010\n",
            "\n",
            "Epoch 1056: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1056/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2886 - MAE: 0.7089\n",
            "Epoch 1056: loss improved from 2.28872 to 2.28865, saving model to ./model_PID__1056_loss_2.289_vloss_0.347_acc_0.709_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.2886 - MAE: 0.7089 - val_loss: 0.3467 - val_MAE: 0.3866 - lr: 0.0010\n",
            "\n",
            "Epoch 1057: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1057/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2886 - MAE: 0.7089\n",
            "Epoch 1057: loss improved from 2.28865 to 2.28857, saving model to ./model_PID__1057_loss_2.289_vloss_0.347_acc_0.709_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.2886 - MAE: 0.7089 - val_loss: 0.3467 - val_MAE: 0.3866 - lr: 0.0010\n",
            "\n",
            "Epoch 1058: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1058/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2885 - MAE: 0.7088\n",
            "Epoch 1058: loss improved from 2.28857 to 2.28850, saving model to ./model_PID__1058_loss_2.288_vloss_0.347_acc_0.709_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 2.2885 - MAE: 0.7088 - val_loss: 0.3467 - val_MAE: 0.3866 - lr: 0.0010\n",
            "\n",
            "Epoch 1059: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1059/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2884 - MAE: 0.7088\n",
            "Epoch 1059: loss improved from 2.28850 to 2.28842, saving model to ./model_PID__1059_loss_2.288_vloss_0.347_acc_0.709_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2.2884 - MAE: 0.7088 - val_loss: 0.3468 - val_MAE: 0.3866 - lr: 0.0010\n",
            "\n",
            "Epoch 1060: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1060/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2883 - MAE: 0.7088\n",
            "Epoch 1060: loss improved from 2.28842 to 2.28835, saving model to ./model_PID__1060_loss_2.288_vloss_0.347_acc_0.709_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 2.2883 - MAE: 0.7088 - val_loss: 0.3468 - val_MAE: 0.3867 - lr: 0.0010\n",
            "\n",
            "Epoch 1061: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1061/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2883 - MAE: 0.7087\n",
            "Epoch 1061: loss improved from 2.28835 to 2.28827, saving model to ./model_PID__1061_loss_2.288_vloss_0.347_acc_0.709_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 2.2883 - MAE: 0.7087 - val_loss: 0.3469 - val_MAE: 0.3867 - lr: 0.0010\n",
            "\n",
            "Epoch 1062: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1062/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2882 - MAE: 0.7087\n",
            "Epoch 1062: loss improved from 2.28827 to 2.28820, saving model to ./model_PID__1062_loss_2.288_vloss_0.347_acc_0.709_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 2.2882 - MAE: 0.7087 - val_loss: 0.3469 - val_MAE: 0.3867 - lr: 0.0010\n",
            "\n",
            "Epoch 1063: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1063/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2881 - MAE: 0.7087\n",
            "Epoch 1063: loss improved from 2.28820 to 2.28812, saving model to ./model_PID__1063_loss_2.288_vloss_0.347_acc_0.709_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 2.2881 - MAE: 0.7087 - val_loss: 0.3469 - val_MAE: 0.3867 - lr: 0.0010\n",
            "\n",
            "Epoch 1064: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1064/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2880 - MAE: 0.7086\n",
            "Epoch 1064: loss improved from 2.28812 to 2.28804, saving model to ./model_PID__1064_loss_2.288_vloss_0.347_acc_0.709_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.2880 - MAE: 0.7086 - val_loss: 0.3470 - val_MAE: 0.3867 - lr: 0.0010\n",
            "\n",
            "Epoch 1065: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1065/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2880 - MAE: 0.7086\n",
            "Epoch 1065: loss improved from 2.28804 to 2.28796, saving model to ./model_PID__1065_loss_2.288_vloss_0.347_acc_0.709_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 2.2880 - MAE: 0.7086 - val_loss: 0.3470 - val_MAE: 0.3868 - lr: 0.0010\n",
            "\n",
            "Epoch 1066: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1066/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2879 - MAE: 0.7085\n",
            "Epoch 1066: loss improved from 2.28796 to 2.28788, saving model to ./model_PID__1066_loss_2.288_vloss_0.347_acc_0.709_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 2.2879 - MAE: 0.7085 - val_loss: 0.3470 - val_MAE: 0.3868 - lr: 0.0010\n",
            "\n",
            "Epoch 1067: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1067/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2878 - MAE: 0.7085\n",
            "Epoch 1067: loss improved from 2.28788 to 2.28780, saving model to ./model_PID__1067_loss_2.288_vloss_0.347_acc_0.708_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 2.2878 - MAE: 0.7085 - val_loss: 0.3471 - val_MAE: 0.3868 - lr: 0.0010\n",
            "\n",
            "Epoch 1068: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1068/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2877 - MAE: 0.7085\n",
            "Epoch 1068: loss improved from 2.28780 to 2.28772, saving model to ./model_PID__1068_loss_2.288_vloss_0.347_acc_0.708_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 2.2877 - MAE: 0.7085 - val_loss: 0.3471 - val_MAE: 0.3869 - lr: 0.0010\n",
            "\n",
            "Epoch 1069: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1069/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2876 - MAE: 0.7084\n",
            "Epoch 1069: loss improved from 2.28772 to 2.28764, saving model to ./model_PID__1069_loss_2.288_vloss_0.347_acc_0.708_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 2.2876 - MAE: 0.7084 - val_loss: 0.3472 - val_MAE: 0.3869 - lr: 0.0010\n",
            "\n",
            "Epoch 1070: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1070/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2876 - MAE: 0.7084\n",
            "Epoch 1070: loss improved from 2.28764 to 2.28755, saving model to ./model_PID__1070_loss_2.288_vloss_0.347_acc_0.708_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 2.2876 - MAE: 0.7084 - val_loss: 0.3472 - val_MAE: 0.3869 - lr: 0.0010\n",
            "\n",
            "Epoch 1071: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1071/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2875 - MAE: 0.7083\n",
            "Epoch 1071: loss improved from 2.28755 to 2.28747, saving model to ./model_PID__1071_loss_2.287_vloss_0.347_acc_0.708_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 2.2875 - MAE: 0.7083 - val_loss: 0.3473 - val_MAE: 0.3870 - lr: 0.0010\n",
            "\n",
            "Epoch 1072: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1072/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2874 - MAE: 0.7083\n",
            "Epoch 1072: loss improved from 2.28747 to 2.28738, saving model to ./model_PID__1072_loss_2.287_vloss_0.347_acc_0.708_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.2874 - MAE: 0.7083 - val_loss: 0.3474 - val_MAE: 0.3870 - lr: 0.0010\n",
            "\n",
            "Epoch 1073: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1073/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2873 - MAE: 0.7082\n",
            "Epoch 1073: loss improved from 2.28738 to 2.28729, saving model to ./model_PID__1073_loss_2.287_vloss_0.347_acc_0.708_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 2.2873 - MAE: 0.7082 - val_loss: 0.3474 - val_MAE: 0.3871 - lr: 0.0010\n",
            "\n",
            "Epoch 1074: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1074/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2872 - MAE: 0.7082\n",
            "Epoch 1074: loss improved from 2.28729 to 2.28719, saving model to ./model_PID__1074_loss_2.287_vloss_0.347_acc_0.708_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 2.2872 - MAE: 0.7082 - val_loss: 0.3475 - val_MAE: 0.3871 - lr: 0.0010\n",
            "\n",
            "Epoch 1075: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1075/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2871 - MAE: 0.7081\n",
            "Epoch 1075: loss improved from 2.28719 to 2.28710, saving model to ./model_PID__1075_loss_2.287_vloss_0.348_acc_0.708_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 2.2871 - MAE: 0.7081 - val_loss: 0.3476 - val_MAE: 0.3872 - lr: 0.0010\n",
            "\n",
            "Epoch 1076: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1076/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2870 - MAE: 0.7081\n",
            "Epoch 1076: loss improved from 2.28710 to 2.28700, saving model to ./model_PID__1076_loss_2.287_vloss_0.348_acc_0.708_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 2.2870 - MAE: 0.7081 - val_loss: 0.3476 - val_MAE: 0.3872 - lr: 0.0010\n",
            "\n",
            "Epoch 1077: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1077/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2869 - MAE: 0.7080\n",
            "Epoch 1077: loss improved from 2.28700 to 2.28690, saving model to ./model_PID__1077_loss_2.287_vloss_0.348_acc_0.708_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 2.2869 - MAE: 0.7080 - val_loss: 0.3477 - val_MAE: 0.3873 - lr: 0.0010\n",
            "\n",
            "Epoch 1078: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1078/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2868 - MAE: 0.7080\n",
            "Epoch 1078: loss improved from 2.28690 to 2.28680, saving model to ./model_PID__1078_loss_2.287_vloss_0.348_acc_0.708_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 2.2868 - MAE: 0.7080 - val_loss: 0.3478 - val_MAE: 0.3874 - lr: 0.0010\n",
            "\n",
            "Epoch 1079: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1079/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2867 - MAE: 0.7079\n",
            "Epoch 1079: loss improved from 2.28680 to 2.28670, saving model to ./model_PID__1079_loss_2.287_vloss_0.348_acc_0.708_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.2867 - MAE: 0.7079 - val_loss: 0.3478 - val_MAE: 0.3874 - lr: 0.0010\n",
            "\n",
            "Epoch 1080: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1080/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2866 - MAE: 0.7079\n",
            "Epoch 1080: loss improved from 2.28670 to 2.28660, saving model to ./model_PID__1080_loss_2.287_vloss_0.348_acc_0.708_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 2.2866 - MAE: 0.7079 - val_loss: 0.3479 - val_MAE: 0.3875 - lr: 0.0010\n",
            "\n",
            "Epoch 1081: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1081/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2865 - MAE: 0.7078\n",
            "Epoch 1081: loss improved from 2.28660 to 2.28650, saving model to ./model_PID__1081_loss_2.286_vloss_0.348_acc_0.708_vacc_0.387.hdf5\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 2.2865 - MAE: 0.7078 - val_loss: 0.3479 - val_MAE: 0.3875 - lr: 0.0010\n",
            "\n",
            "Epoch 1082: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1082/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2864 - MAE: 0.7077\n",
            "Epoch 1082: loss improved from 2.28650 to 2.28640, saving model to ./model_PID__1082_loss_2.286_vloss_0.348_acc_0.708_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 2.2864 - MAE: 0.7077 - val_loss: 0.3480 - val_MAE: 0.3875 - lr: 0.0010\n",
            "\n",
            "Epoch 1083: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1083/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2863 - MAE: 0.7077\n",
            "Epoch 1083: loss improved from 2.28640 to 2.28630, saving model to ./model_PID__1083_loss_2.286_vloss_0.348_acc_0.708_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 2.2863 - MAE: 0.7077 - val_loss: 0.3481 - val_MAE: 0.3876 - lr: 0.0010\n",
            "\n",
            "Epoch 1084: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1084/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2862 - MAE: 0.7077\n",
            "Epoch 1084: loss improved from 2.28630 to 2.28621, saving model to ./model_PID__1084_loss_2.286_vloss_0.348_acc_0.708_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 2.2862 - MAE: 0.7077 - val_loss: 0.3481 - val_MAE: 0.3876 - lr: 0.0010\n",
            "\n",
            "Epoch 1085: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1085/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2861 - MAE: 0.7076\n",
            "Epoch 1085: loss improved from 2.28621 to 2.28612, saving model to ./model_PID__1085_loss_2.286_vloss_0.348_acc_0.708_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 2.2861 - MAE: 0.7076 - val_loss: 0.3481 - val_MAE: 0.3876 - lr: 0.0010\n",
            "\n",
            "Epoch 1086: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1086/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2860 - MAE: 0.7076\n",
            "Epoch 1086: loss improved from 2.28612 to 2.28604, saving model to ./model_PID__1086_loss_2.286_vloss_0.348_acc_0.708_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.2860 - MAE: 0.7076 - val_loss: 0.3482 - val_MAE: 0.3876 - lr: 0.0010\n",
            "\n",
            "Epoch 1087: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1087/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2860 - MAE: 0.7075\n",
            "Epoch 1087: loss improved from 2.28604 to 2.28595, saving model to ./model_PID__1087_loss_2.286_vloss_0.348_acc_0.708_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 2.2860 - MAE: 0.7075 - val_loss: 0.3482 - val_MAE: 0.3876 - lr: 0.0010\n",
            "\n",
            "Epoch 1088: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1088/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2859 - MAE: 0.7075\n",
            "Epoch 1088: loss improved from 2.28595 to 2.28587, saving model to ./model_PID__1088_loss_2.286_vloss_0.348_acc_0.708_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 2.2859 - MAE: 0.7075 - val_loss: 0.3483 - val_MAE: 0.3876 - lr: 0.0010\n",
            "\n",
            "Epoch 1089: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1089/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2858 - MAE: 0.7075\n",
            "Epoch 1089: loss improved from 2.28587 to 2.28579, saving model to ./model_PID__1089_loss_2.286_vloss_0.348_acc_0.707_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 2.2858 - MAE: 0.7075 - val_loss: 0.3483 - val_MAE: 0.3876 - lr: 0.0010\n",
            "\n",
            "Epoch 1090: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1090/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2857 - MAE: 0.7074\n",
            "Epoch 1090: loss improved from 2.28579 to 2.28570, saving model to ./model_PID__1090_loss_2.286_vloss_0.348_acc_0.707_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 2.2857 - MAE: 0.7074 - val_loss: 0.3483 - val_MAE: 0.3876 - lr: 0.0010\n",
            "\n",
            "Epoch 1091: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1091/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2856 - MAE: 0.7074\n",
            "Epoch 1091: loss improved from 2.28570 to 2.28562, saving model to ./model_PID__1091_loss_2.286_vloss_0.348_acc_0.707_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 2.2856 - MAE: 0.7074 - val_loss: 0.3483 - val_MAE: 0.3876 - lr: 0.0010\n",
            "\n",
            "Epoch 1092: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1092/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2855 - MAE: 0.7074\n",
            "Epoch 1092: loss improved from 2.28562 to 2.28554, saving model to ./model_PID__1092_loss_2.286_vloss_0.348_acc_0.707_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 2.2855 - MAE: 0.7074 - val_loss: 0.3484 - val_MAE: 0.3876 - lr: 0.0010\n",
            "\n",
            "Epoch 1093: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1093/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2855 - MAE: 0.7073\n",
            "Epoch 1093: loss improved from 2.28554 to 2.28546, saving model to ./model_PID__1093_loss_2.285_vloss_0.348_acc_0.707_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 2.2855 - MAE: 0.7073 - val_loss: 0.3484 - val_MAE: 0.3876 - lr: 0.0010\n",
            "\n",
            "Epoch 1094: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1094/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2854 - MAE: 0.7073\n",
            "Epoch 1094: loss improved from 2.28546 to 2.28538, saving model to ./model_PID__1094_loss_2.285_vloss_0.348_acc_0.707_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 2.2854 - MAE: 0.7073 - val_loss: 0.3484 - val_MAE: 0.3876 - lr: 0.0010\n",
            "\n",
            "Epoch 1095: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1095/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2853 - MAE: 0.7073\n",
            "Epoch 1095: loss improved from 2.28538 to 2.28530, saving model to ./model_PID__1095_loss_2.285_vloss_0.348_acc_0.707_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 2.2853 - MAE: 0.7073 - val_loss: 0.3484 - val_MAE: 0.3875 - lr: 0.0010\n",
            "\n",
            "Epoch 1096: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1096/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2852 - MAE: 0.7072\n",
            "Epoch 1096: loss improved from 2.28530 to 2.28522, saving model to ./model_PID__1096_loss_2.285_vloss_0.348_acc_0.707_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 2.2852 - MAE: 0.7072 - val_loss: 0.3484 - val_MAE: 0.3875 - lr: 0.0010\n",
            "\n",
            "Epoch 1097: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1097/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2851 - MAE: 0.7072\n",
            "Epoch 1097: loss improved from 2.28522 to 2.28515, saving model to ./model_PID__1097_loss_2.285_vloss_0.348_acc_0.707_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 2.2851 - MAE: 0.7072 - val_loss: 0.3485 - val_MAE: 0.3875 - lr: 0.0010\n",
            "\n",
            "Epoch 1098: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1098/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2851 - MAE: 0.7072\n",
            "Epoch 1098: loss improved from 2.28515 to 2.28507, saving model to ./model_PID__1098_loss_2.285_vloss_0.348_acc_0.707_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 2.2851 - MAE: 0.7072 - val_loss: 0.3485 - val_MAE: 0.3875 - lr: 0.0010\n",
            "\n",
            "Epoch 1099: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1099/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2850 - MAE: 0.7071\n",
            "Epoch 1099: loss improved from 2.28507 to 2.28499, saving model to ./model_PID__1099_loss_2.285_vloss_0.349_acc_0.707_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 2.2850 - MAE: 0.7071 - val_loss: 0.3485 - val_MAE: 0.3876 - lr: 0.0010\n",
            "\n",
            "Epoch 1100: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1100/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2849 - MAE: 0.7071\n",
            "Epoch 1100: loss improved from 2.28499 to 2.28491, saving model to ./model_PID__1100_loss_2.285_vloss_0.349_acc_0.707_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 2.2849 - MAE: 0.7071 - val_loss: 0.3486 - val_MAE: 0.3876 - lr: 0.0010\n",
            "\n",
            "Epoch 1101: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1101/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2848 - MAE: 0.7071\n",
            "Epoch 1101: loss improved from 2.28491 to 2.28483, saving model to ./model_PID__1101_loss_2.285_vloss_0.349_acc_0.707_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 2.2848 - MAE: 0.7071 - val_loss: 0.3486 - val_MAE: 0.3876 - lr: 0.0010\n",
            "\n",
            "Epoch 1102: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1102/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2847 - MAE: 0.7070\n",
            "Epoch 1102: loss improved from 2.28483 to 2.28475, saving model to ./model_PID__1102_loss_2.285_vloss_0.349_acc_0.707_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 2.2847 - MAE: 0.7070 - val_loss: 0.3486 - val_MAE: 0.3876 - lr: 0.0010\n",
            "\n",
            "Epoch 1103: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1103/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2847 - MAE: 0.7070\n",
            "Epoch 1103: loss improved from 2.28475 to 2.28467, saving model to ./model_PID__1103_loss_2.285_vloss_0.349_acc_0.707_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 2.2847 - MAE: 0.7070 - val_loss: 0.3487 - val_MAE: 0.3876 - lr: 0.0010\n",
            "\n",
            "Epoch 1104: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1104/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2846 - MAE: 0.7070\n",
            "Epoch 1104: loss improved from 2.28467 to 2.28459, saving model to ./model_PID__1104_loss_2.285_vloss_0.349_acc_0.707_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 2.2846 - MAE: 0.7070 - val_loss: 0.3487 - val_MAE: 0.3876 - lr: 0.0010\n",
            "\n",
            "Epoch 1105: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1105/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2845 - MAE: 0.7069\n",
            "Epoch 1105: loss improved from 2.28459 to 2.28451, saving model to ./model_PID__1105_loss_2.285_vloss_0.349_acc_0.707_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 2.2845 - MAE: 0.7069 - val_loss: 0.3488 - val_MAE: 0.3877 - lr: 0.0010\n",
            "\n",
            "Epoch 1106: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1106/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2844 - MAE: 0.7069\n",
            "Epoch 1106: loss improved from 2.28451 to 2.28443, saving model to ./model_PID__1106_loss_2.284_vloss_0.349_acc_0.707_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 2.2844 - MAE: 0.7069 - val_loss: 0.3488 - val_MAE: 0.3877 - lr: 0.0010\n",
            "\n",
            "Epoch 1107: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1107/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2844 - MAE: 0.7068\n",
            "Epoch 1107: loss improved from 2.28443 to 2.28436, saving model to ./model_PID__1107_loss_2.284_vloss_0.349_acc_0.707_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 2.2844 - MAE: 0.7068 - val_loss: 0.3489 - val_MAE: 0.3877 - lr: 0.0010\n",
            "\n",
            "Epoch 1108: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1108/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2843 - MAE: 0.7068\n",
            "Epoch 1108: loss improved from 2.28436 to 2.28428, saving model to ./model_PID__1108_loss_2.284_vloss_0.349_acc_0.707_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 2.2843 - MAE: 0.7068 - val_loss: 0.3489 - val_MAE: 0.3878 - lr: 0.0010\n",
            "\n",
            "Epoch 1109: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1109/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2842 - MAE: 0.7068\n",
            "Epoch 1109: loss improved from 2.28428 to 2.28420, saving model to ./model_PID__1109_loss_2.284_vloss_0.349_acc_0.707_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.2842 - MAE: 0.7068 - val_loss: 0.3490 - val_MAE: 0.3878 - lr: 0.0010\n",
            "\n",
            "Epoch 1110: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1110/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2841 - MAE: 0.7067\n",
            "Epoch 1110: loss improved from 2.28420 to 2.28412, saving model to ./model_PID__1110_loss_2.284_vloss_0.349_acc_0.707_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 2.2841 - MAE: 0.7067 - val_loss: 0.3490 - val_MAE: 0.3878 - lr: 0.0010\n",
            "\n",
            "Epoch 1111: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1111/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2840 - MAE: 0.7067\n",
            "Epoch 1111: loss improved from 2.28412 to 2.28404, saving model to ./model_PID__1111_loss_2.284_vloss_0.349_acc_0.707_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 2.2840 - MAE: 0.7067 - val_loss: 0.3490 - val_MAE: 0.3878 - lr: 0.0010\n",
            "\n",
            "Epoch 1112: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1112/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2840 - MAE: 0.7066\n",
            "Epoch 1112: loss improved from 2.28404 to 2.28396, saving model to ./model_PID__1112_loss_2.284_vloss_0.349_acc_0.707_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 2.2840 - MAE: 0.7066 - val_loss: 0.3491 - val_MAE: 0.3878 - lr: 0.0010\n",
            "\n",
            "Epoch 1113: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1113/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2839 - MAE: 0.7066\n",
            "Epoch 1113: loss improved from 2.28396 to 2.28388, saving model to ./model_PID__1113_loss_2.284_vloss_0.349_acc_0.707_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 2.2839 - MAE: 0.7066 - val_loss: 0.3491 - val_MAE: 0.3878 - lr: 0.0010\n",
            "\n",
            "Epoch 1114: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1114/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2838 - MAE: 0.7066\n",
            "Epoch 1114: loss improved from 2.28388 to 2.28381, saving model to ./model_PID__1114_loss_2.284_vloss_0.349_acc_0.707_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 2.2838 - MAE: 0.7066 - val_loss: 0.3491 - val_MAE: 0.3879 - lr: 0.0010\n",
            "\n",
            "Epoch 1115: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1115/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2837 - MAE: 0.7065\n",
            "Epoch 1115: loss improved from 2.28381 to 2.28373, saving model to ./model_PID__1115_loss_2.284_vloss_0.349_acc_0.707_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 2.2837 - MAE: 0.7065 - val_loss: 0.3492 - val_MAE: 0.3879 - lr: 0.0010\n",
            "\n",
            "Epoch 1116: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1116/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2836 - MAE: 0.7065\n",
            "Epoch 1116: loss improved from 2.28373 to 2.28365, saving model to ./model_PID__1116_loss_2.284_vloss_0.349_acc_0.706_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 2.2836 - MAE: 0.7065 - val_loss: 0.3492 - val_MAE: 0.3879 - lr: 0.0010\n",
            "\n",
            "Epoch 1117: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1117/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2836 - MAE: 0.7065\n",
            "Epoch 1117: loss improved from 2.28365 to 2.28357, saving model to ./model_PID__1117_loss_2.284_vloss_0.349_acc_0.706_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 2.2836 - MAE: 0.7065 - val_loss: 0.3492 - val_MAE: 0.3879 - lr: 0.0010\n",
            "\n",
            "Epoch 1118: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1118/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2835 - MAE: 0.7064\n",
            "Epoch 1118: loss improved from 2.28357 to 2.28349, saving model to ./model_PID__1118_loss_2.283_vloss_0.349_acc_0.706_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 2.2835 - MAE: 0.7064 - val_loss: 0.3493 - val_MAE: 0.3879 - lr: 0.0010\n",
            "\n",
            "Epoch 1119: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1119/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2834 - MAE: 0.7064\n",
            "Epoch 1119: loss improved from 2.28349 to 2.28341, saving model to ./model_PID__1119_loss_2.283_vloss_0.349_acc_0.706_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 2.2834 - MAE: 0.7064 - val_loss: 0.3493 - val_MAE: 0.3879 - lr: 0.0010\n",
            "\n",
            "Epoch 1120: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1120/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2833 - MAE: 0.7063\n",
            "Epoch 1120: loss improved from 2.28341 to 2.28333, saving model to ./model_PID__1120_loss_2.283_vloss_0.349_acc_0.706_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 2.2833 - MAE: 0.7063 - val_loss: 0.3493 - val_MAE: 0.3879 - lr: 0.0010\n",
            "\n",
            "Epoch 1121: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1121/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2833 - MAE: 0.7063\n",
            "Epoch 1121: loss improved from 2.28333 to 2.28325, saving model to ./model_PID__1121_loss_2.283_vloss_0.349_acc_0.706_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 2.2833 - MAE: 0.7063 - val_loss: 0.3493 - val_MAE: 0.3879 - lr: 0.0010\n",
            "\n",
            "Epoch 1122: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1122/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2832 - MAE: 0.7063\n",
            "Epoch 1122: loss improved from 2.28325 to 2.28317, saving model to ./model_PID__1122_loss_2.283_vloss_0.349_acc_0.706_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 2.2832 - MAE: 0.7063 - val_loss: 0.3494 - val_MAE: 0.3879 - lr: 0.0010\n",
            "\n",
            "Epoch 1123: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1123/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2831 - MAE: 0.7062\n",
            "Epoch 1123: loss improved from 2.28317 to 2.28309, saving model to ./model_PID__1123_loss_2.283_vloss_0.349_acc_0.706_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.2831 - MAE: 0.7062 - val_loss: 0.3494 - val_MAE: 0.3879 - lr: 0.0010\n",
            "\n",
            "Epoch 1124: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1124/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2830 - MAE: 0.7062\n",
            "Epoch 1124: loss improved from 2.28309 to 2.28301, saving model to ./model_PID__1124_loss_2.283_vloss_0.349_acc_0.706_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 2.2830 - MAE: 0.7062 - val_loss: 0.3494 - val_MAE: 0.3879 - lr: 0.0010\n",
            "\n",
            "Epoch 1125: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1125/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2829 - MAE: 0.7062\n",
            "Epoch 1125: loss improved from 2.28301 to 2.28293, saving model to ./model_PID__1125_loss_2.283_vloss_0.349_acc_0.706_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 2.2829 - MAE: 0.7062 - val_loss: 0.3494 - val_MAE: 0.3879 - lr: 0.0010\n",
            "\n",
            "Epoch 1126: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1126/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2829 - MAE: 0.7061\n",
            "Epoch 1126: loss improved from 2.28293 to 2.28285, saving model to ./model_PID__1126_loss_2.283_vloss_0.349_acc_0.706_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.2829 - MAE: 0.7061 - val_loss: 0.3495 - val_MAE: 0.3879 - lr: 0.0010\n",
            "\n",
            "Epoch 1127: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1127/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2828 - MAE: 0.7061\n",
            "Epoch 1127: loss improved from 2.28285 to 2.28277, saving model to ./model_PID__1127_loss_2.283_vloss_0.349_acc_0.706_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 2.2828 - MAE: 0.7061 - val_loss: 0.3495 - val_MAE: 0.3879 - lr: 0.0010\n",
            "\n",
            "Epoch 1128: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1128/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2827 - MAE: 0.7060\n",
            "Epoch 1128: loss improved from 2.28277 to 2.28269, saving model to ./model_PID__1128_loss_2.283_vloss_0.350_acc_0.706_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.2827 - MAE: 0.7060 - val_loss: 0.3495 - val_MAE: 0.3880 - lr: 0.0010\n",
            "\n",
            "Epoch 1129: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1129/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2826 - MAE: 0.7060\n",
            "Epoch 1129: loss improved from 2.28269 to 2.28261, saving model to ./model_PID__1129_loss_2.283_vloss_0.350_acc_0.706_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 2.2826 - MAE: 0.7060 - val_loss: 0.3495 - val_MAE: 0.3880 - lr: 0.0010\n",
            "\n",
            "Epoch 1130: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1130/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2825 - MAE: 0.7059\n",
            "Epoch 1130: loss improved from 2.28261 to 2.28253, saving model to ./model_PID__1130_loss_2.283_vloss_0.350_acc_0.706_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 2.2825 - MAE: 0.7059 - val_loss: 0.3496 - val_MAE: 0.3880 - lr: 0.0010\n",
            "\n",
            "Epoch 1131: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1131/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2824 - MAE: 0.7059\n",
            "Epoch 1131: loss improved from 2.28253 to 2.28244, saving model to ./model_PID__1131_loss_2.282_vloss_0.350_acc_0.706_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 2.2824 - MAE: 0.7059 - val_loss: 0.3496 - val_MAE: 0.3880 - lr: 0.0010\n",
            "\n",
            "Epoch 1132: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1132/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2824 - MAE: 0.7059\n",
            "Epoch 1132: loss improved from 2.28244 to 2.28236, saving model to ./model_PID__1132_loss_2.282_vloss_0.350_acc_0.706_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2.2824 - MAE: 0.7059 - val_loss: 0.3496 - val_MAE: 0.3880 - lr: 0.0010\n",
            "\n",
            "Epoch 1133: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1133/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2823 - MAE: 0.7058\n",
            "Epoch 1133: loss improved from 2.28236 to 2.28228, saving model to ./model_PID__1133_loss_2.282_vloss_0.350_acc_0.706_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 2.2823 - MAE: 0.7058 - val_loss: 0.3497 - val_MAE: 0.3880 - lr: 0.0010\n",
            "\n",
            "Epoch 1134: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1134/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2822 - MAE: 0.7058\n",
            "Epoch 1134: loss improved from 2.28228 to 2.28219, saving model to ./model_PID__1134_loss_2.282_vloss_0.350_acc_0.706_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.2822 - MAE: 0.7058 - val_loss: 0.3497 - val_MAE: 0.3881 - lr: 0.0010\n",
            "\n",
            "Epoch 1135: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1135/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2821 - MAE: 0.7057\n",
            "Epoch 1135: loss improved from 2.28219 to 2.28211, saving model to ./model_PID__1135_loss_2.282_vloss_0.350_acc_0.706_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.2821 - MAE: 0.7057 - val_loss: 0.3497 - val_MAE: 0.3881 - lr: 0.0010\n",
            "\n",
            "Epoch 1136: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1136/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2820 - MAE: 0.7057\n",
            "Epoch 1136: loss improved from 2.28211 to 2.28202, saving model to ./model_PID__1136_loss_2.282_vloss_0.350_acc_0.706_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 2.2820 - MAE: 0.7057 - val_loss: 0.3498 - val_MAE: 0.3881 - lr: 0.0010\n",
            "\n",
            "Epoch 1137: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1137/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2819 - MAE: 0.7056\n",
            "Epoch 1137: loss improved from 2.28202 to 2.28194, saving model to ./model_PID__1137_loss_2.282_vloss_0.350_acc_0.706_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 2.2819 - MAE: 0.7056 - val_loss: 0.3498 - val_MAE: 0.3881 - lr: 0.0010\n",
            "\n",
            "Epoch 1138: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1138/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2819 - MAE: 0.7056\n",
            "Epoch 1138: loss improved from 2.28194 to 2.28185, saving model to ./model_PID__1138_loss_2.282_vloss_0.350_acc_0.706_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 2.2819 - MAE: 0.7056 - val_loss: 0.3498 - val_MAE: 0.3881 - lr: 0.0010\n",
            "\n",
            "Epoch 1139: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1139/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2818 - MAE: 0.7055\n",
            "Epoch 1139: loss improved from 2.28185 to 2.28177, saving model to ./model_PID__1139_loss_2.282_vloss_0.350_acc_0.706_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 2.2818 - MAE: 0.7055 - val_loss: 0.3498 - val_MAE: 0.3881 - lr: 0.0010\n",
            "\n",
            "Epoch 1140: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1140/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2817 - MAE: 0.7055\n",
            "Epoch 1140: loss improved from 2.28177 to 2.28168, saving model to ./model_PID__1140_loss_2.282_vloss_0.350_acc_0.705_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 2.2817 - MAE: 0.7055 - val_loss: 0.3499 - val_MAE: 0.3882 - lr: 0.0010\n",
            "\n",
            "Epoch 1141: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1141/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2816 - MAE: 0.7054\n",
            "Epoch 1141: loss improved from 2.28168 to 2.28159, saving model to ./model_PID__1141_loss_2.282_vloss_0.350_acc_0.705_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 2.2816 - MAE: 0.7054 - val_loss: 0.3499 - val_MAE: 0.3882 - lr: 0.0010\n",
            "\n",
            "Epoch 1142: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1142/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2815 - MAE: 0.7054\n",
            "Epoch 1142: loss improved from 2.28159 to 2.28151, saving model to ./model_PID__1142_loss_2.282_vloss_0.350_acc_0.705_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 2.2815 - MAE: 0.7054 - val_loss: 0.3500 - val_MAE: 0.3882 - lr: 0.0010\n",
            "\n",
            "Epoch 1143: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1143/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2814 - MAE: 0.7054\n",
            "Epoch 1143: loss improved from 2.28151 to 2.28142, saving model to ./model_PID__1143_loss_2.281_vloss_0.350_acc_0.705_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 2.2814 - MAE: 0.7054 - val_loss: 0.3500 - val_MAE: 0.3882 - lr: 0.0010\n",
            "\n",
            "Epoch 1144: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1144/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2813 - MAE: 0.7053\n",
            "Epoch 1144: loss improved from 2.28142 to 2.28133, saving model to ./model_PID__1144_loss_2.281_vloss_0.350_acc_0.705_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 2.2813 - MAE: 0.7053 - val_loss: 0.3500 - val_MAE: 0.3883 - lr: 0.0010\n",
            "\n",
            "Epoch 1145: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1145/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2812 - MAE: 0.7053\n",
            "Epoch 1145: loss improved from 2.28133 to 2.28124, saving model to ./model_PID__1145_loss_2.281_vloss_0.350_acc_0.705_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2.2812 - MAE: 0.7053 - val_loss: 0.3501 - val_MAE: 0.3883 - lr: 0.0010\n",
            "\n",
            "Epoch 1146: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1146/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2811 - MAE: 0.7052\n",
            "Epoch 1146: loss improved from 2.28124 to 2.28115, saving model to ./model_PID__1146_loss_2.281_vloss_0.350_acc_0.705_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 2.2811 - MAE: 0.7052 - val_loss: 0.3501 - val_MAE: 0.3883 - lr: 0.0010\n",
            "\n",
            "Epoch 1147: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1147/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2811 - MAE: 0.7052\n",
            "Epoch 1147: loss improved from 2.28115 to 2.28106, saving model to ./model_PID__1147_loss_2.281_vloss_0.350_acc_0.705_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 2.2811 - MAE: 0.7052 - val_loss: 0.3502 - val_MAE: 0.3884 - lr: 0.0010\n",
            "\n",
            "Epoch 1148: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1148/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2810 - MAE: 0.7051\n",
            "Epoch 1148: loss improved from 2.28106 to 2.28097, saving model to ./model_PID__1148_loss_2.281_vloss_0.350_acc_0.705_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2.2810 - MAE: 0.7051 - val_loss: 0.3502 - val_MAE: 0.3884 - lr: 0.0010\n",
            "\n",
            "Epoch 1149: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1149/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2809 - MAE: 0.7051\n",
            "Epoch 1149: loss improved from 2.28097 to 2.28087, saving model to ./model_PID__1149_loss_2.281_vloss_0.350_acc_0.705_vacc_0.388.hdf5\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 2.2809 - MAE: 0.7051 - val_loss: 0.3502 - val_MAE: 0.3885 - lr: 0.0010\n",
            "\n",
            "Epoch 1150: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1150/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2808 - MAE: 0.7050\n",
            "Epoch 1150: loss improved from 2.28087 to 2.28078, saving model to ./model_PID__1150_loss_2.281_vloss_0.350_acc_0.705_vacc_0.389.hdf5\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 2.2808 - MAE: 0.7050 - val_loss: 0.3503 - val_MAE: 0.3885 - lr: 0.0010\n",
            "\n",
            "Epoch 1151: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1151/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2807 - MAE: 0.7050\n",
            "Epoch 1151: loss improved from 2.28078 to 2.28069, saving model to ./model_PID__1151_loss_2.281_vloss_0.350_acc_0.705_vacc_0.389.hdf5\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 2.2807 - MAE: 0.7050 - val_loss: 0.3504 - val_MAE: 0.3886 - lr: 0.0010\n",
            "\n",
            "Epoch 1152: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1152/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2806 - MAE: 0.7049\n",
            "Epoch 1152: loss improved from 2.28069 to 2.28059, saving model to ./model_PID__1152_loss_2.281_vloss_0.350_acc_0.705_vacc_0.389.hdf5\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 2.2806 - MAE: 0.7049 - val_loss: 0.3504 - val_MAE: 0.3886 - lr: 0.0010\n",
            "\n",
            "Epoch 1153: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1153/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2805 - MAE: 0.7049\n",
            "Epoch 1153: loss improved from 2.28059 to 2.28049, saving model to ./model_PID__1153_loss_2.280_vloss_0.350_acc_0.705_vacc_0.389.hdf5\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 2.2805 - MAE: 0.7049 - val_loss: 0.3505 - val_MAE: 0.3887 - lr: 0.0010\n",
            "\n",
            "Epoch 1154: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1154/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2804 - MAE: 0.7048\n",
            "Epoch 1154: loss improved from 2.28049 to 2.28039, saving model to ./model_PID__1154_loss_2.280_vloss_0.351_acc_0.705_vacc_0.389.hdf5\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 2.2804 - MAE: 0.7048 - val_loss: 0.3505 - val_MAE: 0.3887 - lr: 0.0010\n",
            "\n",
            "Epoch 1155: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1155/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2803 - MAE: 0.7048\n",
            "Epoch 1155: loss improved from 2.28039 to 2.28029, saving model to ./model_PID__1155_loss_2.280_vloss_0.351_acc_0.705_vacc_0.389.hdf5\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 2.2803 - MAE: 0.7048 - val_loss: 0.3506 - val_MAE: 0.3888 - lr: 0.0010\n",
            "\n",
            "Epoch 1156: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1156/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2802 - MAE: 0.7047\n",
            "Epoch 1156: loss improved from 2.28029 to 2.28019, saving model to ./model_PID__1156_loss_2.280_vloss_0.351_acc_0.705_vacc_0.389.hdf5\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.2802 - MAE: 0.7047 - val_loss: 0.3506 - val_MAE: 0.3888 - lr: 0.0010\n",
            "\n",
            "Epoch 1157: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1157/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2801 - MAE: 0.7047\n",
            "Epoch 1157: loss improved from 2.28019 to 2.28009, saving model to ./model_PID__1157_loss_2.280_vloss_0.351_acc_0.705_vacc_0.389.hdf5\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 2.2801 - MAE: 0.7047 - val_loss: 0.3507 - val_MAE: 0.3889 - lr: 0.0010\n",
            "\n",
            "Epoch 1158: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1158/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2800 - MAE: 0.7046\n",
            "Epoch 1158: loss improved from 2.28009 to 2.27999, saving model to ./model_PID__1158_loss_2.280_vloss_0.351_acc_0.705_vacc_0.389.hdf5\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 2.2800 - MAE: 0.7046 - val_loss: 0.3508 - val_MAE: 0.3889 - lr: 0.0010\n",
            "\n",
            "Epoch 1159: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1159/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2799 - MAE: 0.7045\n",
            "Epoch 1159: loss improved from 2.27999 to 2.27988, saving model to ./model_PID__1159_loss_2.280_vloss_0.351_acc_0.705_vacc_0.389.hdf5\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 2.2799 - MAE: 0.7045 - val_loss: 0.3508 - val_MAE: 0.3890 - lr: 0.0010\n",
            "\n",
            "Epoch 1160: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1160/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2798 - MAE: 0.7045\n",
            "Epoch 1160: loss improved from 2.27988 to 2.27978, saving model to ./model_PID__1160_loss_2.280_vloss_0.351_acc_0.704_vacc_0.389.hdf5\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 2.2798 - MAE: 0.7045 - val_loss: 0.3509 - val_MAE: 0.3891 - lr: 0.0010\n",
            "\n",
            "Epoch 1161: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1161/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2797 - MAE: 0.7044\n",
            "Epoch 1161: loss improved from 2.27978 to 2.27967, saving model to ./model_PID__1161_loss_2.280_vloss_0.351_acc_0.704_vacc_0.389.hdf5\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 2.2797 - MAE: 0.7044 - val_loss: 0.3510 - val_MAE: 0.3891 - lr: 0.0010\n",
            "\n",
            "Epoch 1162: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1162/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2796 - MAE: 0.7044\n",
            "Epoch 1162: loss improved from 2.27967 to 2.27956, saving model to ./model_PID__1162_loss_2.280_vloss_0.351_acc_0.704_vacc_0.389.hdf5\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 2.2796 - MAE: 0.7044 - val_loss: 0.3510 - val_MAE: 0.3892 - lr: 0.0010\n",
            "\n",
            "Epoch 1163: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1163/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2795 - MAE: 0.7043\n",
            "Epoch 1163: loss improved from 2.27956 to 2.27946, saving model to ./model_PID__1163_loss_2.279_vloss_0.351_acc_0.704_vacc_0.389.hdf5\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.2795 - MAE: 0.7043 - val_loss: 0.3511 - val_MAE: 0.3892 - lr: 0.0010\n",
            "\n",
            "Epoch 1164: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1164/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2793 - MAE: 0.7043\n",
            "Epoch 1164: loss improved from 2.27946 to 2.27935, saving model to ./model_PID__1164_loss_2.279_vloss_0.351_acc_0.704_vacc_0.389.hdf5\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 2.2793 - MAE: 0.7043 - val_loss: 0.3512 - val_MAE: 0.3893 - lr: 0.0010\n",
            "\n",
            "Epoch 1165: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1165/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2792 - MAE: 0.7042\n",
            "Epoch 1165: loss improved from 2.27935 to 2.27924, saving model to ./model_PID__1165_loss_2.279_vloss_0.351_acc_0.704_vacc_0.389.hdf5\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 2.2792 - MAE: 0.7042 - val_loss: 0.3512 - val_MAE: 0.3893 - lr: 0.0010\n",
            "\n",
            "Epoch 1166: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1166/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2791 - MAE: 0.7042\n",
            "Epoch 1166: loss improved from 2.27924 to 2.27914, saving model to ./model_PID__1166_loss_2.279_vloss_0.351_acc_0.704_vacc_0.389.hdf5\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.2791 - MAE: 0.7042 - val_loss: 0.3513 - val_MAE: 0.3894 - lr: 0.0010\n",
            "\n",
            "Epoch 1167: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1167/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2790 - MAE: 0.7041\n",
            "Epoch 1167: loss improved from 2.27914 to 2.27904, saving model to ./model_PID__1167_loss_2.279_vloss_0.351_acc_0.704_vacc_0.389.hdf5\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 2.2790 - MAE: 0.7041 - val_loss: 0.3514 - val_MAE: 0.3894 - lr: 0.0010\n",
            "\n",
            "Epoch 1168: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1168/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2789 - MAE: 0.7040\n",
            "Epoch 1168: loss improved from 2.27904 to 2.27894, saving model to ./model_PID__1168_loss_2.279_vloss_0.351_acc_0.704_vacc_0.389.hdf5\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 2.2789 - MAE: 0.7040 - val_loss: 0.3514 - val_MAE: 0.3895 - lr: 0.0010\n",
            "\n",
            "Epoch 1169: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1169/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2788 - MAE: 0.7040\n",
            "Epoch 1169: loss improved from 2.27894 to 2.27884, saving model to ./model_PID__1169_loss_2.279_vloss_0.351_acc_0.704_vacc_0.389.hdf5\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 2.2788 - MAE: 0.7040 - val_loss: 0.3515 - val_MAE: 0.3895 - lr: 0.0010\n",
            "\n",
            "Epoch 1170: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1170/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2787 - MAE: 0.7039\n",
            "Epoch 1170: loss improved from 2.27884 to 2.27874, saving model to ./model_PID__1170_loss_2.279_vloss_0.351_acc_0.704_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 2.2787 - MAE: 0.7039 - val_loss: 0.3515 - val_MAE: 0.3895 - lr: 0.0010\n",
            "\n",
            "Epoch 1171: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1171/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2787 - MAE: 0.7039\n",
            "Epoch 1171: loss improved from 2.27874 to 2.27865, saving model to ./model_PID__1171_loss_2.279_vloss_0.352_acc_0.704_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 2.2787 - MAE: 0.7039 - val_loss: 0.3515 - val_MAE: 0.3895 - lr: 0.0010\n",
            "\n",
            "Epoch 1172: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1172/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2786 - MAE: 0.7039\n",
            "Epoch 1172: loss improved from 2.27865 to 2.27856, saving model to ./model_PID__1172_loss_2.279_vloss_0.352_acc_0.704_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.2786 - MAE: 0.7039 - val_loss: 0.3516 - val_MAE: 0.3895 - lr: 0.0010\n",
            "\n",
            "Epoch 1173: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1173/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2785 - MAE: 0.7038\n",
            "Epoch 1173: loss improved from 2.27856 to 2.27847, saving model to ./model_PID__1173_loss_2.278_vloss_0.352_acc_0.704_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 2.2785 - MAE: 0.7038 - val_loss: 0.3516 - val_MAE: 0.3895 - lr: 0.0010\n",
            "\n",
            "Epoch 1174: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1174/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2784 - MAE: 0.7038\n",
            "Epoch 1174: loss improved from 2.27847 to 2.27838, saving model to ./model_PID__1174_loss_2.278_vloss_0.352_acc_0.704_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 2.2784 - MAE: 0.7038 - val_loss: 0.3516 - val_MAE: 0.3895 - lr: 0.0010\n",
            "\n",
            "Epoch 1175: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1175/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2783 - MAE: 0.7038\n",
            "Epoch 1175: loss improved from 2.27838 to 2.27829, saving model to ./model_PID__1175_loss_2.278_vloss_0.352_acc_0.704_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 2.2783 - MAE: 0.7038 - val_loss: 0.3517 - val_MAE: 0.3895 - lr: 0.0010\n",
            "\n",
            "Epoch 1176: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1176/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2782 - MAE: 0.7037\n",
            "Epoch 1176: loss improved from 2.27829 to 2.27820, saving model to ./model_PID__1176_loss_2.278_vloss_0.352_acc_0.704_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 2.2782 - MAE: 0.7037 - val_loss: 0.3517 - val_MAE: 0.3895 - lr: 0.0010\n",
            "\n",
            "Epoch 1177: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1177/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2781 - MAE: 0.7037\n",
            "Epoch 1177: loss improved from 2.27820 to 2.27812, saving model to ./model_PID__1177_loss_2.278_vloss_0.352_acc_0.704_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 2.2781 - MAE: 0.7037 - val_loss: 0.3517 - val_MAE: 0.3895 - lr: 0.0010\n",
            "\n",
            "Epoch 1178: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1178/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2780 - MAE: 0.7037\n",
            "Epoch 1178: loss improved from 2.27812 to 2.27803, saving model to ./model_PID__1178_loss_2.278_vloss_0.352_acc_0.704_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 2.2780 - MAE: 0.7037 - val_loss: 0.3517 - val_MAE: 0.3895 - lr: 0.0010\n",
            "\n",
            "Epoch 1179: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1179/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2779 - MAE: 0.7036\n",
            "Epoch 1179: loss improved from 2.27803 to 2.27794, saving model to ./model_PID__1179_loss_2.278_vloss_0.352_acc_0.704_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 2.2779 - MAE: 0.7036 - val_loss: 0.3517 - val_MAE: 0.3895 - lr: 0.0010\n",
            "\n",
            "Epoch 1180: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1180/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2779 - MAE: 0.7036\n",
            "Epoch 1180: loss improved from 2.27794 to 2.27786, saving model to ./model_PID__1180_loss_2.278_vloss_0.352_acc_0.704_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 2.2779 - MAE: 0.7036 - val_loss: 0.3518 - val_MAE: 0.3895 - lr: 0.0010\n",
            "\n",
            "Epoch 1181: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1181/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2778 - MAE: 0.7035\n",
            "Epoch 1181: loss improved from 2.27786 to 2.27777, saving model to ./model_PID__1181_loss_2.278_vloss_0.352_acc_0.704_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 2.2778 - MAE: 0.7035 - val_loss: 0.3518 - val_MAE: 0.3895 - lr: 0.0010\n",
            "\n",
            "Epoch 1182: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1182/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2777 - MAE: 0.7035\n",
            "Epoch 1182: loss improved from 2.27777 to 2.27768, saving model to ./model_PID__1182_loss_2.278_vloss_0.352_acc_0.704_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 2.2777 - MAE: 0.7035 - val_loss: 0.3518 - val_MAE: 0.3895 - lr: 0.0010\n",
            "\n",
            "Epoch 1183: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1183/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2776 - MAE: 0.7035\n",
            "Epoch 1183: loss improved from 2.27768 to 2.27760, saving model to ./model_PID__1183_loss_2.278_vloss_0.352_acc_0.703_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 2.2776 - MAE: 0.7035 - val_loss: 0.3518 - val_MAE: 0.3895 - lr: 0.0010\n",
            "\n",
            "Epoch 1184: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1184/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2775 - MAE: 0.7034\n",
            "Epoch 1184: loss improved from 2.27760 to 2.27751, saving model to ./model_PID__1184_loss_2.278_vloss_0.352_acc_0.703_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.2775 - MAE: 0.7034 - val_loss: 0.3519 - val_MAE: 0.3895 - lr: 0.0010\n",
            "\n",
            "Epoch 1185: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1185/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2774 - MAE: 0.7034\n",
            "Epoch 1185: loss improved from 2.27751 to 2.27743, saving model to ./model_PID__1185_loss_2.277_vloss_0.352_acc_0.703_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 2.2774 - MAE: 0.7034 - val_loss: 0.3519 - val_MAE: 0.3895 - lr: 0.0010\n",
            "\n",
            "Epoch 1186: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1186/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2773 - MAE: 0.7034\n",
            "Epoch 1186: loss improved from 2.27743 to 2.27734, saving model to ./model_PID__1186_loss_2.277_vloss_0.352_acc_0.703_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 2.2773 - MAE: 0.7034 - val_loss: 0.3519 - val_MAE: 0.3895 - lr: 0.0010\n",
            "\n",
            "Epoch 1187: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1187/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2773 - MAE: 0.7033\n",
            "Epoch 1187: loss improved from 2.27734 to 2.27725, saving model to ./model_PID__1187_loss_2.277_vloss_0.352_acc_0.703_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 2.2773 - MAE: 0.7033 - val_loss: 0.3519 - val_MAE: 0.3895 - lr: 0.0010\n",
            "\n",
            "Epoch 1188: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1188/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2772 - MAE: 0.7033\n",
            "Epoch 1188: loss improved from 2.27725 to 2.27717, saving model to ./model_PID__1188_loss_2.277_vloss_0.352_acc_0.703_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 2.2772 - MAE: 0.7033 - val_loss: 0.3520 - val_MAE: 0.3895 - lr: 0.0010\n",
            "\n",
            "Epoch 1189: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1189/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2771 - MAE: 0.7032\n",
            "Epoch 1189: loss improved from 2.27717 to 2.27708, saving model to ./model_PID__1189_loss_2.277_vloss_0.352_acc_0.703_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 2.2771 - MAE: 0.7032 - val_loss: 0.3520 - val_MAE: 0.3895 - lr: 0.0010\n",
            "\n",
            "Epoch 1190: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1190/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2770 - MAE: 0.7032\n",
            "Epoch 1190: loss improved from 2.27708 to 2.27699, saving model to ./model_PID__1190_loss_2.277_vloss_0.352_acc_0.703_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 2.2770 - MAE: 0.7032 - val_loss: 0.3520 - val_MAE: 0.3896 - lr: 0.0010\n",
            "\n",
            "Epoch 1191: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1191/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2769 - MAE: 0.7031\n",
            "Epoch 1191: loss improved from 2.27699 to 2.27691, saving model to ./model_PID__1191_loss_2.277_vloss_0.352_acc_0.703_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 2.2769 - MAE: 0.7031 - val_loss: 0.3521 - val_MAE: 0.3896 - lr: 0.0010\n",
            "\n",
            "Epoch 1192: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1192/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2768 - MAE: 0.7031\n",
            "Epoch 1192: loss improved from 2.27691 to 2.27682, saving model to ./model_PID__1192_loss_2.277_vloss_0.352_acc_0.703_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 2.2768 - MAE: 0.7031 - val_loss: 0.3521 - val_MAE: 0.3896 - lr: 0.0010\n",
            "\n",
            "Epoch 1193: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1193/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2767 - MAE: 0.7030\n",
            "Epoch 1193: loss improved from 2.27682 to 2.27673, saving model to ./model_PID__1193_loss_2.277_vloss_0.352_acc_0.703_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.2767 - MAE: 0.7030 - val_loss: 0.3521 - val_MAE: 0.3896 - lr: 0.0010\n",
            "\n",
            "Epoch 1194: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1194/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2766 - MAE: 0.7030\n",
            "Epoch 1194: loss improved from 2.27673 to 2.27665, saving model to ./model_PID__1194_loss_2.277_vloss_0.352_acc_0.703_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 2.2766 - MAE: 0.7030 - val_loss: 0.3522 - val_MAE: 0.3896 - lr: 0.0010\n",
            "\n",
            "Epoch 1195: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1195/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2766 - MAE: 0.7029\n",
            "Epoch 1195: loss improved from 2.27665 to 2.27656, saving model to ./model_PID__1195_loss_2.277_vloss_0.352_acc_0.703_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 2.2766 - MAE: 0.7029 - val_loss: 0.3522 - val_MAE: 0.3896 - lr: 0.0010\n",
            "\n",
            "Epoch 1196: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1196/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2765 - MAE: 0.7029\n",
            "Epoch 1196: loss improved from 2.27656 to 2.27647, saving model to ./model_PID__1196_loss_2.276_vloss_0.352_acc_0.703_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.2765 - MAE: 0.7029 - val_loss: 0.3523 - val_MAE: 0.3897 - lr: 0.0010\n",
            "\n",
            "Epoch 1197: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1197/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2764 - MAE: 0.7028\n",
            "Epoch 1197: loss improved from 2.27647 to 2.27639, saving model to ./model_PID__1197_loss_2.276_vloss_0.352_acc_0.703_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 2.2764 - MAE: 0.7028 - val_loss: 0.3523 - val_MAE: 0.3897 - lr: 0.0010\n",
            "\n",
            "Epoch 1198: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1198/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2763 - MAE: 0.7028\n",
            "Epoch 1198: loss improved from 2.27639 to 2.27630, saving model to ./model_PID__1198_loss_2.276_vloss_0.352_acc_0.703_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.2763 - MAE: 0.7028 - val_loss: 0.3523 - val_MAE: 0.3897 - lr: 0.0010\n",
            "\n",
            "Epoch 1199: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1199/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2762 - MAE: 0.7027\n",
            "Epoch 1199: loss improved from 2.27630 to 2.27621, saving model to ./model_PID__1199_loss_2.276_vloss_0.352_acc_0.703_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 2.2762 - MAE: 0.7027 - val_loss: 0.3524 - val_MAE: 0.3897 - lr: 0.0010\n",
            "\n",
            "Epoch 1200: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1200/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2761 - MAE: 0.7027\n",
            "Epoch 1200: loss improved from 2.27621 to 2.27612, saving model to ./model_PID__1200_loss_2.276_vloss_0.352_acc_0.703_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 2.2761 - MAE: 0.7027 - val_loss: 0.3524 - val_MAE: 0.3897 - lr: 0.0010\n",
            "\n",
            "Epoch 1201: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1201/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2760 - MAE: 0.7027\n",
            "Epoch 1201: loss improved from 2.27612 to 2.27604, saving model to ./model_PID__1201_loss_2.276_vloss_0.352_acc_0.703_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 2.2760 - MAE: 0.7027 - val_loss: 0.3525 - val_MAE: 0.3897 - lr: 0.0010\n",
            "\n",
            "Epoch 1202: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1202/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2759 - MAE: 0.7026\n",
            "Epoch 1202: loss improved from 2.27604 to 2.27595, saving model to ./model_PID__1202_loss_2.276_vloss_0.352_acc_0.703_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2.2759 - MAE: 0.7026 - val_loss: 0.3525 - val_MAE: 0.3898 - lr: 0.0010\n",
            "\n",
            "Epoch 1203: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1203/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2759 - MAE: 0.7026\n",
            "Epoch 1203: loss improved from 2.27595 to 2.27586, saving model to ./model_PID__1203_loss_2.276_vloss_0.353_acc_0.703_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 2.2759 - MAE: 0.7026 - val_loss: 0.3525 - val_MAE: 0.3898 - lr: 0.0010\n",
            "\n",
            "Epoch 1204: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1204/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2758 - MAE: 0.7025\n",
            "Epoch 1204: loss improved from 2.27586 to 2.27577, saving model to ./model_PID__1204_loss_2.276_vloss_0.353_acc_0.703_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 2.2758 - MAE: 0.7025 - val_loss: 0.3526 - val_MAE: 0.3898 - lr: 0.0010\n",
            "\n",
            "Epoch 1205: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1205/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2757 - MAE: 0.7025\n",
            "Epoch 1205: loss improved from 2.27577 to 2.27568, saving model to ./model_PID__1205_loss_2.276_vloss_0.353_acc_0.702_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 2.2757 - MAE: 0.7025 - val_loss: 0.3526 - val_MAE: 0.3898 - lr: 0.0010\n",
            "\n",
            "Epoch 1206: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1206/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2756 - MAE: 0.7024\n",
            "Epoch 1206: loss improved from 2.27568 to 2.27560, saving model to ./model_PID__1206_loss_2.276_vloss_0.353_acc_0.702_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 2.2756 - MAE: 0.7024 - val_loss: 0.3527 - val_MAE: 0.3898 - lr: 0.0010\n",
            "\n",
            "Epoch 1207: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1207/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2755 - MAE: 0.7024\n",
            "Epoch 1207: loss improved from 2.27560 to 2.27551, saving model to ./model_PID__1207_loss_2.276_vloss_0.353_acc_0.702_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 2.2755 - MAE: 0.7024 - val_loss: 0.3527 - val_MAE: 0.3899 - lr: 0.0010\n",
            "\n",
            "Epoch 1208: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1208/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2754 - MAE: 0.7023\n",
            "Epoch 1208: loss improved from 2.27551 to 2.27542, saving model to ./model_PID__1208_loss_2.275_vloss_0.353_acc_0.702_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 2.2754 - MAE: 0.7023 - val_loss: 0.3527 - val_MAE: 0.3899 - lr: 0.0010\n",
            "\n",
            "Epoch 1209: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1209/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2753 - MAE: 0.7023\n",
            "Epoch 1209: loss improved from 2.27542 to 2.27533, saving model to ./model_PID__1209_loss_2.275_vloss_0.353_acc_0.702_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 2.2753 - MAE: 0.7023 - val_loss: 0.3528 - val_MAE: 0.3899 - lr: 0.0010\n",
            "\n",
            "Epoch 1210: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1210/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2752 - MAE: 0.7022\n",
            "Epoch 1210: loss improved from 2.27533 to 2.27524, saving model to ./model_PID__1210_loss_2.275_vloss_0.353_acc_0.702_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 2.2752 - MAE: 0.7022 - val_loss: 0.3528 - val_MAE: 0.3899 - lr: 0.0010\n",
            "\n",
            "Epoch 1211: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1211/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2752 - MAE: 0.7022\n",
            "Epoch 1211: loss improved from 2.27524 to 2.27515, saving model to ./model_PID__1211_loss_2.275_vloss_0.353_acc_0.702_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 2.2752 - MAE: 0.7022 - val_loss: 0.3529 - val_MAE: 0.3900 - lr: 0.0010\n",
            "\n",
            "Epoch 1212: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1212/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2751 - MAE: 0.7021\n",
            "Epoch 1212: loss improved from 2.27515 to 2.27507, saving model to ./model_PID__1212_loss_2.275_vloss_0.353_acc_0.702_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 2.2751 - MAE: 0.7021 - val_loss: 0.3529 - val_MAE: 0.3900 - lr: 0.0010\n",
            "\n",
            "Epoch 1213: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1213/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2750 - MAE: 0.7021\n",
            "Epoch 1213: loss improved from 2.27507 to 2.27498, saving model to ./model_PID__1213_loss_2.275_vloss_0.353_acc_0.702_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 2.2750 - MAE: 0.7021 - val_loss: 0.3530 - val_MAE: 0.3900 - lr: 0.0010\n",
            "\n",
            "Epoch 1214: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1214/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2749 - MAE: 0.7020\n",
            "Epoch 1214: loss improved from 2.27498 to 2.27489, saving model to ./model_PID__1214_loss_2.275_vloss_0.353_acc_0.702_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 2.2749 - MAE: 0.7020 - val_loss: 0.3530 - val_MAE: 0.3901 - lr: 0.0010\n",
            "\n",
            "Epoch 1215: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1215/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2748 - MAE: 0.7020\n",
            "Epoch 1215: loss improved from 2.27489 to 2.27480, saving model to ./model_PID__1215_loss_2.275_vloss_0.353_acc_0.702_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 2.2748 - MAE: 0.7020 - val_loss: 0.3531 - val_MAE: 0.3901 - lr: 0.0010\n",
            "\n",
            "Epoch 1216: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1216/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2747 - MAE: 0.7019\n",
            "Epoch 1216: loss improved from 2.27480 to 2.27471, saving model to ./model_PID__1216_loss_2.275_vloss_0.353_acc_0.702_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.2747 - MAE: 0.7019 - val_loss: 0.3532 - val_MAE: 0.3902 - lr: 0.0010\n",
            "\n",
            "Epoch 1217: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1217/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2746 - MAE: 0.7019\n",
            "Epoch 1217: loss improved from 2.27471 to 2.27462, saving model to ./model_PID__1217_loss_2.275_vloss_0.353_acc_0.702_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 2.2746 - MAE: 0.7019 - val_loss: 0.3532 - val_MAE: 0.3902 - lr: 0.0010\n",
            "\n",
            "Epoch 1218: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1218/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2745 - MAE: 0.7018\n",
            "Epoch 1218: loss improved from 2.27462 to 2.27453, saving model to ./model_PID__1218_loss_2.275_vloss_0.353_acc_0.702_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 2.2745 - MAE: 0.7018 - val_loss: 0.3533 - val_MAE: 0.3902 - lr: 0.0010\n",
            "\n",
            "Epoch 1219: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1219/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2744 - MAE: 0.7018\n",
            "Epoch 1219: loss improved from 2.27453 to 2.27444, saving model to ./model_PID__1219_loss_2.274_vloss_0.353_acc_0.702_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 2.2744 - MAE: 0.7018 - val_loss: 0.3534 - val_MAE: 0.3903 - lr: 0.0010\n",
            "\n",
            "Epoch 1220: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1220/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2743 - MAE: 0.7017\n",
            "Epoch 1220: loss improved from 2.27444 to 2.27434, saving model to ./model_PID__1220_loss_2.274_vloss_0.353_acc_0.702_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 2.2743 - MAE: 0.7017 - val_loss: 0.3534 - val_MAE: 0.3903 - lr: 0.0010\n",
            "\n",
            "Epoch 1221: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1221/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2742 - MAE: 0.7017\n",
            "Epoch 1221: loss improved from 2.27434 to 2.27425, saving model to ./model_PID__1221_loss_2.274_vloss_0.353_acc_0.702_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 2.2742 - MAE: 0.7017 - val_loss: 0.3535 - val_MAE: 0.3904 - lr: 0.0010\n",
            "\n",
            "Epoch 1222: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1222/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2742 - MAE: 0.7016\n",
            "Epoch 1222: loss improved from 2.27425 to 2.27415, saving model to ./model_PID__1222_loss_2.274_vloss_0.354_acc_0.702_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2.2742 - MAE: 0.7016 - val_loss: 0.3536 - val_MAE: 0.3904 - lr: 0.0010\n",
            "\n",
            "Epoch 1223: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1223/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2741 - MAE: 0.7016\n",
            "Epoch 1223: loss improved from 2.27415 to 2.27406, saving model to ./model_PID__1223_loss_2.274_vloss_0.354_acc_0.702_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 2.2741 - MAE: 0.7016 - val_loss: 0.3536 - val_MAE: 0.3905 - lr: 0.0010\n",
            "\n",
            "Epoch 1224: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1224/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2740 - MAE: 0.7015\n",
            "Epoch 1224: loss improved from 2.27406 to 2.27396, saving model to ./model_PID__1224_loss_2.274_vloss_0.354_acc_0.702_vacc_0.390.hdf5\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 2.2740 - MAE: 0.7015 - val_loss: 0.3537 - val_MAE: 0.3905 - lr: 0.0010\n",
            "\n",
            "Epoch 1225: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1225/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2739 - MAE: 0.7015\n",
            "Epoch 1225: loss improved from 2.27396 to 2.27387, saving model to ./model_PID__1225_loss_2.274_vloss_0.354_acc_0.701_vacc_0.391.hdf5\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 2.2739 - MAE: 0.7015 - val_loss: 0.3538 - val_MAE: 0.3905 - lr: 0.0010\n",
            "\n",
            "Epoch 1226: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1226/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2738 - MAE: 0.7014\n",
            "Epoch 1226: loss improved from 2.27387 to 2.27377, saving model to ./model_PID__1226_loss_2.274_vloss_0.354_acc_0.701_vacc_0.391.hdf5\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 2.2738 - MAE: 0.7014 - val_loss: 0.3538 - val_MAE: 0.3906 - lr: 0.0010\n",
            "\n",
            "Epoch 1227: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1227/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2737 - MAE: 0.7014\n",
            "Epoch 1227: loss improved from 2.27377 to 2.27368, saving model to ./model_PID__1227_loss_2.274_vloss_0.354_acc_0.701_vacc_0.391.hdf5\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 2.2737 - MAE: 0.7014 - val_loss: 0.3539 - val_MAE: 0.3906 - lr: 0.0010\n",
            "\n",
            "Epoch 1228: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1228/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2736 - MAE: 0.7013\n",
            "Epoch 1228: loss improved from 2.27368 to 2.27358, saving model to ./model_PID__1228_loss_2.274_vloss_0.354_acc_0.701_vacc_0.391.hdf5\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 2.2736 - MAE: 0.7013 - val_loss: 0.3539 - val_MAE: 0.3906 - lr: 0.0010\n",
            "\n",
            "Epoch 1229: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1229/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2735 - MAE: 0.7012\n",
            "Epoch 1229: loss improved from 2.27358 to 2.27348, saving model to ./model_PID__1229_loss_2.273_vloss_0.354_acc_0.701_vacc_0.391.hdf5\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 2.2735 - MAE: 0.7012 - val_loss: 0.3540 - val_MAE: 0.3907 - lr: 0.0010\n",
            "\n",
            "Epoch 1230: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1230/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2734 - MAE: 0.7012\n",
            "Epoch 1230: loss improved from 2.27348 to 2.27339, saving model to ./model_PID__1230_loss_2.273_vloss_0.354_acc_0.701_vacc_0.391.hdf5\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 2.2734 - MAE: 0.7012 - val_loss: 0.3541 - val_MAE: 0.3907 - lr: 0.0010\n",
            "\n",
            "Epoch 1231: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1231/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2733 - MAE: 0.7011\n",
            "Epoch 1231: loss improved from 2.27339 to 2.27329, saving model to ./model_PID__1231_loss_2.273_vloss_0.354_acc_0.701_vacc_0.391.hdf5\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 2.2733 - MAE: 0.7011 - val_loss: 0.3541 - val_MAE: 0.3908 - lr: 0.0010\n",
            "\n",
            "Epoch 1232: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1232/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2732 - MAE: 0.7011\n",
            "Epoch 1232: loss improved from 2.27329 to 2.27319, saving model to ./model_PID__1232_loss_2.273_vloss_0.354_acc_0.701_vacc_0.391.hdf5\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 2.2732 - MAE: 0.7011 - val_loss: 0.3542 - val_MAE: 0.3908 - lr: 0.0010\n",
            "\n",
            "Epoch 1233: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1233/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2731 - MAE: 0.7010\n",
            "Epoch 1233: loss improved from 2.27319 to 2.27309, saving model to ./model_PID__1233_loss_2.273_vloss_0.354_acc_0.701_vacc_0.391.hdf5\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 2.2731 - MAE: 0.7010 - val_loss: 0.3543 - val_MAE: 0.3909 - lr: 0.0010\n",
            "\n",
            "Epoch 1234: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1234/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2730 - MAE: 0.7009\n",
            "Epoch 1234: loss improved from 2.27309 to 2.27299, saving model to ./model_PID__1234_loss_2.273_vloss_0.354_acc_0.701_vacc_0.391.hdf5\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.2730 - MAE: 0.7009 - val_loss: 0.3543 - val_MAE: 0.3909 - lr: 0.0010\n",
            "\n",
            "Epoch 1235: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1235/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2729 - MAE: 0.7009\n",
            "Epoch 1235: loss improved from 2.27299 to 2.27289, saving model to ./model_PID__1235_loss_2.273_vloss_0.354_acc_0.701_vacc_0.391.hdf5\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 2.2729 - MAE: 0.7009 - val_loss: 0.3544 - val_MAE: 0.3909 - lr: 0.0010\n",
            "\n",
            "Epoch 1236: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1236/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2728 - MAE: 0.7008\n",
            "Epoch 1236: loss improved from 2.27289 to 2.27279, saving model to ./model_PID__1236_loss_2.273_vloss_0.354_acc_0.701_vacc_0.391.hdf5\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 2.2728 - MAE: 0.7008 - val_loss: 0.3545 - val_MAE: 0.3910 - lr: 0.0010\n",
            "\n",
            "Epoch 1237: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1237/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2727 - MAE: 0.7008\n",
            "Epoch 1237: loss improved from 2.27279 to 2.27269, saving model to ./model_PID__1237_loss_2.273_vloss_0.355_acc_0.701_vacc_0.391.hdf5\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 2.2727 - MAE: 0.7008 - val_loss: 0.3546 - val_MAE: 0.3910 - lr: 0.0010\n",
            "\n",
            "Epoch 1238: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1238/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2726 - MAE: 0.7007\n",
            "Epoch 1238: loss improved from 2.27269 to 2.27259, saving model to ./model_PID__1238_loss_2.273_vloss_0.355_acc_0.701_vacc_0.391.hdf5\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 2.2726 - MAE: 0.7007 - val_loss: 0.3546 - val_MAE: 0.3911 - lr: 0.0010\n",
            "\n",
            "Epoch 1239: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1239/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2725 - MAE: 0.7006\n",
            "Epoch 1239: loss improved from 2.27259 to 2.27248, saving model to ./model_PID__1239_loss_2.272_vloss_0.355_acc_0.701_vacc_0.391.hdf5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 2.2725 - MAE: 0.7006 - val_loss: 0.3547 - val_MAE: 0.3911 - lr: 0.0010\n",
            "\n",
            "Epoch 1240: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1240/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2724 - MAE: 0.7006\n",
            "Epoch 1240: loss improved from 2.27248 to 2.27237, saving model to ./model_PID__1240_loss_2.272_vloss_0.355_acc_0.701_vacc_0.391.hdf5\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 2.2724 - MAE: 0.7006 - val_loss: 0.3548 - val_MAE: 0.3912 - lr: 0.0010\n",
            "\n",
            "Epoch 1241: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1241/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2723 - MAE: 0.7005\n",
            "Epoch 1241: loss improved from 2.27237 to 2.27227, saving model to ./model_PID__1241_loss_2.272_vloss_0.355_acc_0.701_vacc_0.391.hdf5\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 2.2723 - MAE: 0.7005 - val_loss: 0.3549 - val_MAE: 0.3912 - lr: 0.0010\n",
            "\n",
            "Epoch 1242: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1242/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2722 - MAE: 0.7004\n",
            "Epoch 1242: loss improved from 2.27227 to 2.27216, saving model to ./model_PID__1242_loss_2.272_vloss_0.355_acc_0.700_vacc_0.391.hdf5\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.2722 - MAE: 0.7004 - val_loss: 0.3549 - val_MAE: 0.3913 - lr: 0.0010\n",
            "\n",
            "Epoch 1243: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1243/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2721 - MAE: 0.7004\n",
            "Epoch 1243: loss improved from 2.27216 to 2.27205, saving model to ./model_PID__1243_loss_2.272_vloss_0.355_acc_0.700_vacc_0.391.hdf5\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 2.2721 - MAE: 0.7004 - val_loss: 0.3550 - val_MAE: 0.3913 - lr: 0.0010\n",
            "\n",
            "Epoch 1244: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1244/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2719 - MAE: 0.7003\n",
            "Epoch 1244: loss improved from 2.27205 to 2.27194, saving model to ./model_PID__1244_loss_2.272_vloss_0.355_acc_0.700_vacc_0.391.hdf5\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 2.2719 - MAE: 0.7003 - val_loss: 0.3551 - val_MAE: 0.3913 - lr: 0.0010\n",
            "\n",
            "Epoch 1245: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1245/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2718 - MAE: 0.7003\n",
            "Epoch 1245: loss improved from 2.27194 to 2.27183, saving model to ./model_PID__1245_loss_2.272_vloss_0.355_acc_0.700_vacc_0.391.hdf5\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 2.2718 - MAE: 0.7003 - val_loss: 0.3551 - val_MAE: 0.3914 - lr: 0.0010\n",
            "\n",
            "Epoch 1246: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1246/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2717 - MAE: 0.7002\n",
            "Epoch 1246: loss improved from 2.27183 to 2.27172, saving model to ./model_PID__1246_loss_2.272_vloss_0.355_acc_0.700_vacc_0.391.hdf5\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 2.2717 - MAE: 0.7002 - val_loss: 0.3552 - val_MAE: 0.3914 - lr: 0.0010\n",
            "\n",
            "Epoch 1247: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1247/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2716 - MAE: 0.7001\n",
            "Epoch 1247: loss improved from 2.27172 to 2.27162, saving model to ./model_PID__1247_loss_2.272_vloss_0.355_acc_0.700_vacc_0.391.hdf5\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 2.2716 - MAE: 0.7001 - val_loss: 0.3552 - val_MAE: 0.3914 - lr: 0.0010\n",
            "\n",
            "Epoch 1248: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1248/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2715 - MAE: 0.7001\n",
            "Epoch 1248: loss improved from 2.27162 to 2.27151, saving model to ./model_PID__1248_loss_2.272_vloss_0.355_acc_0.700_vacc_0.391.hdf5\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 2.2715 - MAE: 0.7001 - val_loss: 0.3552 - val_MAE: 0.3914 - lr: 0.0010\n",
            "\n",
            "Epoch 1249: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1249/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2714 - MAE: 0.7000\n",
            "Epoch 1249: loss improved from 2.27151 to 2.27141, saving model to ./model_PID__1249_loss_2.271_vloss_0.355_acc_0.700_vacc_0.391.hdf5\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.2714 - MAE: 0.7000 - val_loss: 0.3553 - val_MAE: 0.3914 - lr: 0.0010\n",
            "\n",
            "Epoch 1250: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1250/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2713 - MAE: 0.7000\n",
            "Epoch 1250: loss improved from 2.27141 to 2.27130, saving model to ./model_PID__1250_loss_2.271_vloss_0.355_acc_0.700_vacc_0.391.hdf5\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.2713 - MAE: 0.7000 - val_loss: 0.3553 - val_MAE: 0.3915 - lr: 0.0010\n",
            "\n",
            "Epoch 1251: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1251/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2712 - MAE: 0.6999\n",
            "Epoch 1251: loss improved from 2.27130 to 2.27120, saving model to ./model_PID__1251_loss_2.271_vloss_0.355_acc_0.700_vacc_0.391.hdf5\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 2.2712 - MAE: 0.6999 - val_loss: 0.3554 - val_MAE: 0.3915 - lr: 0.0010\n",
            "\n",
            "Epoch 1252: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1252/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2711 - MAE: 0.6999\n",
            "Epoch 1252: loss improved from 2.27120 to 2.27110, saving model to ./model_PID__1252_loss_2.271_vloss_0.355_acc_0.700_vacc_0.391.hdf5\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 2.2711 - MAE: 0.6999 - val_loss: 0.3554 - val_MAE: 0.3915 - lr: 0.0010\n",
            "\n",
            "Epoch 1253: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1253/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2710 - MAE: 0.6998\n",
            "Epoch 1253: loss improved from 2.27110 to 2.27100, saving model to ./model_PID__1253_loss_2.271_vloss_0.355_acc_0.700_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 2.2710 - MAE: 0.6998 - val_loss: 0.3555 - val_MAE: 0.3915 - lr: 0.0010\n",
            "\n",
            "Epoch 1254: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1254/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2709 - MAE: 0.6998\n",
            "Epoch 1254: loss improved from 2.27100 to 2.27090, saving model to ./model_PID__1254_loss_2.271_vloss_0.356_acc_0.700_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 2.2709 - MAE: 0.6998 - val_loss: 0.3555 - val_MAE: 0.3916 - lr: 0.0010\n",
            "\n",
            "Epoch 1255: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1255/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2708 - MAE: 0.6997\n",
            "Epoch 1255: loss improved from 2.27090 to 2.27080, saving model to ./model_PID__1255_loss_2.271_vloss_0.356_acc_0.700_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 2.2708 - MAE: 0.6997 - val_loss: 0.3556 - val_MAE: 0.3916 - lr: 0.0010\n",
            "\n",
            "Epoch 1256: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1256/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2707 - MAE: 0.6997\n",
            "Epoch 1256: loss improved from 2.27080 to 2.27070, saving model to ./model_PID__1256_loss_2.271_vloss_0.356_acc_0.700_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 2.2707 - MAE: 0.6997 - val_loss: 0.3556 - val_MAE: 0.3916 - lr: 0.0010\n",
            "\n",
            "Epoch 1257: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1257/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2706 - MAE: 0.6996\n",
            "Epoch 1257: loss improved from 2.27070 to 2.27060, saving model to ./model_PID__1257_loss_2.271_vloss_0.356_acc_0.700_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 2.2706 - MAE: 0.6996 - val_loss: 0.3557 - val_MAE: 0.3916 - lr: 0.0010\n",
            "\n",
            "Epoch 1258: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1258/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2705 - MAE: 0.6996\n",
            "Epoch 1258: loss improved from 2.27060 to 2.27050, saving model to ./model_PID__1258_loss_2.271_vloss_0.356_acc_0.700_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 2.2705 - MAE: 0.6996 - val_loss: 0.3557 - val_MAE: 0.3917 - lr: 0.0010\n",
            "\n",
            "Epoch 1259: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1259/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2704 - MAE: 0.6996\n",
            "Epoch 1259: loss improved from 2.27050 to 2.27040, saving model to ./model_PID__1259_loss_2.270_vloss_0.356_acc_0.700_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 2.2704 - MAE: 0.6996 - val_loss: 0.3558 - val_MAE: 0.3917 - lr: 0.0010\n",
            "\n",
            "Epoch 1260: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1260/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2703 - MAE: 0.6995\n",
            "Epoch 1260: loss improved from 2.27040 to 2.27030, saving model to ./model_PID__1260_loss_2.270_vloss_0.356_acc_0.700_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 2.2703 - MAE: 0.6995 - val_loss: 0.3558 - val_MAE: 0.3917 - lr: 0.0010\n",
            "\n",
            "Epoch 1261: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1261/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2702 - MAE: 0.6995\n",
            "Epoch 1261: loss improved from 2.27030 to 2.27020, saving model to ./model_PID__1261_loss_2.270_vloss_0.356_acc_0.699_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 2.2702 - MAE: 0.6995 - val_loss: 0.3559 - val_MAE: 0.3917 - lr: 0.0010\n",
            "\n",
            "Epoch 1262: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1262/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2701 - MAE: 0.6994\n",
            "Epoch 1262: loss improved from 2.27020 to 2.27010, saving model to ./model_PID__1262_loss_2.270_vloss_0.356_acc_0.699_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 2.2701 - MAE: 0.6994 - val_loss: 0.3559 - val_MAE: 0.3917 - lr: 0.0010\n",
            "\n",
            "Epoch 1263: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1263/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2700 - MAE: 0.6994\n",
            "Epoch 1263: loss improved from 2.27010 to 2.27000, saving model to ./model_PID__1263_loss_2.270_vloss_0.356_acc_0.699_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 2.2700 - MAE: 0.6994 - val_loss: 0.3559 - val_MAE: 0.3918 - lr: 0.0010\n",
            "\n",
            "Epoch 1264: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1264/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2699 - MAE: 0.6993\n",
            "Epoch 1264: loss improved from 2.27000 to 2.26990, saving model to ./model_PID__1264_loss_2.270_vloss_0.356_acc_0.699_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 2.2699 - MAE: 0.6993 - val_loss: 0.3560 - val_MAE: 0.3918 - lr: 0.0010\n",
            "\n",
            "Epoch 1265: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1265/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2698 - MAE: 0.6993\n",
            "Epoch 1265: loss improved from 2.26990 to 2.26980, saving model to ./model_PID__1265_loss_2.270_vloss_0.356_acc_0.699_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 2.2698 - MAE: 0.6993 - val_loss: 0.3560 - val_MAE: 0.3918 - lr: 0.0010\n",
            "\n",
            "Epoch 1266: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1266/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2697 - MAE: 0.6992\n",
            "Epoch 1266: loss improved from 2.26980 to 2.26970, saving model to ./model_PID__1266_loss_2.270_vloss_0.356_acc_0.699_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 2.2697 - MAE: 0.6992 - val_loss: 0.3560 - val_MAE: 0.3918 - lr: 0.0010\n",
            "\n",
            "Epoch 1267: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1267/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2696 - MAE: 0.6992\n",
            "Epoch 1267: loss improved from 2.26970 to 2.26959, saving model to ./model_PID__1267_loss_2.270_vloss_0.356_acc_0.699_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 2.2696 - MAE: 0.6992 - val_loss: 0.3561 - val_MAE: 0.3918 - lr: 0.0010\n",
            "\n",
            "Epoch 1268: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1268/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2695 - MAE: 0.6991\n",
            "Epoch 1268: loss improved from 2.26959 to 2.26949, saving model to ./model_PID__1268_loss_2.269_vloss_0.356_acc_0.699_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 2.2695 - MAE: 0.6991 - val_loss: 0.3561 - val_MAE: 0.3918 - lr: 0.0010\n",
            "\n",
            "Epoch 1269: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1269/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2694 - MAE: 0.6991\n",
            "Epoch 1269: loss improved from 2.26949 to 2.26939, saving model to ./model_PID__1269_loss_2.269_vloss_0.356_acc_0.699_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 2.2694 - MAE: 0.6991 - val_loss: 0.3561 - val_MAE: 0.3918 - lr: 0.0010\n",
            "\n",
            "Epoch 1270: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1270/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2693 - MAE: 0.6991\n",
            "Epoch 1270: loss improved from 2.26939 to 2.26929, saving model to ./model_PID__1270_loss_2.269_vloss_0.356_acc_0.699_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.2693 - MAE: 0.6991 - val_loss: 0.3562 - val_MAE: 0.3919 - lr: 0.0010\n",
            "\n",
            "Epoch 1271: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1271/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2692 - MAE: 0.6990\n",
            "Epoch 1271: loss improved from 2.26929 to 2.26919, saving model to ./model_PID__1271_loss_2.269_vloss_0.356_acc_0.699_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 2.2692 - MAE: 0.6990 - val_loss: 0.3562 - val_MAE: 0.3919 - lr: 0.0010\n",
            "\n",
            "Epoch 1272: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1272/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2691 - MAE: 0.6990\n",
            "Epoch 1272: loss improved from 2.26919 to 2.26909, saving model to ./model_PID__1272_loss_2.269_vloss_0.356_acc_0.699_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 2.2691 - MAE: 0.6990 - val_loss: 0.3562 - val_MAE: 0.3919 - lr: 0.0010\n",
            "\n",
            "Epoch 1273: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1273/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2690 - MAE: 0.6989\n",
            "Epoch 1273: loss improved from 2.26909 to 2.26899, saving model to ./model_PID__1273_loss_2.269_vloss_0.356_acc_0.699_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 2.2690 - MAE: 0.6989 - val_loss: 0.3563 - val_MAE: 0.3919 - lr: 0.0010\n",
            "\n",
            "Epoch 1274: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1274/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2689 - MAE: 0.6989\n",
            "Epoch 1274: loss improved from 2.26899 to 2.26889, saving model to ./model_PID__1274_loss_2.269_vloss_0.356_acc_0.699_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.2689 - MAE: 0.6989 - val_loss: 0.3563 - val_MAE: 0.3919 - lr: 0.0010\n",
            "\n",
            "Epoch 1275: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1275/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2688 - MAE: 0.6988\n",
            "Epoch 1275: loss improved from 2.26889 to 2.26879, saving model to ./model_PID__1275_loss_2.269_vloss_0.356_acc_0.699_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 2.2688 - MAE: 0.6988 - val_loss: 0.3563 - val_MAE: 0.3919 - lr: 0.0010\n",
            "\n",
            "Epoch 1276: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1276/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2687 - MAE: 0.6988\n",
            "Epoch 1276: loss improved from 2.26879 to 2.26869, saving model to ./model_PID__1276_loss_2.269_vloss_0.356_acc_0.699_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 2.2687 - MAE: 0.6988 - val_loss: 0.3564 - val_MAE: 0.3919 - lr: 0.0010\n",
            "\n",
            "Epoch 1277: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1277/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2686 - MAE: 0.6987\n",
            "Epoch 1277: loss improved from 2.26869 to 2.26860, saving model to ./model_PID__1277_loss_2.269_vloss_0.356_acc_0.699_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 2.2686 - MAE: 0.6987 - val_loss: 0.3564 - val_MAE: 0.3919 - lr: 0.0010\n",
            "\n",
            "Epoch 1278: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1278/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2685 - MAE: 0.6987\n",
            "Epoch 1278: loss improved from 2.26860 to 2.26850, saving model to ./model_PID__1278_loss_2.268_vloss_0.356_acc_0.699_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 2.2685 - MAE: 0.6987 - val_loss: 0.3564 - val_MAE: 0.3919 - lr: 0.0010\n",
            "\n",
            "Epoch 1279: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1279/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2684 - MAE: 0.6987\n",
            "Epoch 1279: loss improved from 2.26850 to 2.26840, saving model to ./model_PID__1279_loss_2.268_vloss_0.356_acc_0.699_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 2.2684 - MAE: 0.6987 - val_loss: 0.3565 - val_MAE: 0.3919 - lr: 0.0010\n",
            "\n",
            "Epoch 1280: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1280/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2683 - MAE: 0.6986\n",
            "Epoch 1280: loss improved from 2.26840 to 2.26831, saving model to ./model_PID__1280_loss_2.268_vloss_0.356_acc_0.699_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 2.2683 - MAE: 0.6986 - val_loss: 0.3565 - val_MAE: 0.3919 - lr: 0.0010\n",
            "\n",
            "Epoch 1281: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1281/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2682 - MAE: 0.6986\n",
            "Epoch 1281: loss improved from 2.26831 to 2.26822, saving model to ./model_PID__1281_loss_2.268_vloss_0.357_acc_0.699_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 2.2682 - MAE: 0.6986 - val_loss: 0.3565 - val_MAE: 0.3919 - lr: 0.0010\n",
            "\n",
            "Epoch 1282: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1282/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2681 - MAE: 0.6985\n",
            "Epoch 1282: loss improved from 2.26822 to 2.26812, saving model to ./model_PID__1282_loss_2.268_vloss_0.357_acc_0.699_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2.2681 - MAE: 0.6985 - val_loss: 0.3565 - val_MAE: 0.3919 - lr: 0.0010\n",
            "\n",
            "Epoch 1283: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1283/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2680 - MAE: 0.6985\n",
            "Epoch 1283: loss improved from 2.26812 to 2.26803, saving model to ./model_PID__1283_loss_2.268_vloss_0.357_acc_0.698_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.2680 - MAE: 0.6985 - val_loss: 0.3566 - val_MAE: 0.3919 - lr: 0.0010\n",
            "\n",
            "Epoch 1284: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1284/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2679 - MAE: 0.6985\n",
            "Epoch 1284: loss improved from 2.26803 to 2.26794, saving model to ./model_PID__1284_loss_2.268_vloss_0.357_acc_0.698_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 2.2679 - MAE: 0.6985 - val_loss: 0.3566 - val_MAE: 0.3919 - lr: 0.0010\n",
            "\n",
            "Epoch 1285: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1285/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2679 - MAE: 0.6984\n",
            "Epoch 1285: loss improved from 2.26794 to 2.26785, saving model to ./model_PID__1285_loss_2.268_vloss_0.357_acc_0.698_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 2.2679 - MAE: 0.6984 - val_loss: 0.3566 - val_MAE: 0.3919 - lr: 0.0010\n",
            "\n",
            "Epoch 1286: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1286/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2678 - MAE: 0.6984\n",
            "Epoch 1286: loss improved from 2.26785 to 2.26776, saving model to ./model_PID__1286_loss_2.268_vloss_0.357_acc_0.698_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 2.2678 - MAE: 0.6984 - val_loss: 0.3566 - val_MAE: 0.3919 - lr: 0.0010\n",
            "\n",
            "Epoch 1287: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1287/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2677 - MAE: 0.6983\n",
            "Epoch 1287: loss improved from 2.26776 to 2.26767, saving model to ./model_PID__1287_loss_2.268_vloss_0.357_acc_0.698_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 2.2677 - MAE: 0.6983 - val_loss: 0.3567 - val_MAE: 0.3919 - lr: 0.0010\n",
            "\n",
            "Epoch 1288: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1288/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2676 - MAE: 0.6983\n",
            "Epoch 1288: loss improved from 2.26767 to 2.26759, saving model to ./model_PID__1288_loss_2.268_vloss_0.357_acc_0.698_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 2.2676 - MAE: 0.6983 - val_loss: 0.3567 - val_MAE: 0.3919 - lr: 0.0010\n",
            "\n",
            "Epoch 1289: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1289/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2675 - MAE: 0.6983\n",
            "Epoch 1289: loss improved from 2.26759 to 2.26750, saving model to ./model_PID__1289_loss_2.267_vloss_0.357_acc_0.698_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 2.2675 - MAE: 0.6983 - val_loss: 0.3567 - val_MAE: 0.3919 - lr: 0.0010\n",
            "\n",
            "Epoch 1290: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1290/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2674 - MAE: 0.6982\n",
            "Epoch 1290: loss improved from 2.26750 to 2.26741, saving model to ./model_PID__1290_loss_2.267_vloss_0.357_acc_0.698_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 2.2674 - MAE: 0.6982 - val_loss: 0.3567 - val_MAE: 0.3919 - lr: 0.0010\n",
            "\n",
            "Epoch 1291: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1291/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2673 - MAE: 0.6982\n",
            "Epoch 1291: loss improved from 2.26741 to 2.26733, saving model to ./model_PID__1291_loss_2.267_vloss_0.357_acc_0.698_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 2.2673 - MAE: 0.6982 - val_loss: 0.3567 - val_MAE: 0.3919 - lr: 0.0010\n",
            "\n",
            "Epoch 1292: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1292/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2672 - MAE: 0.6981\n",
            "Epoch 1292: loss improved from 2.26733 to 2.26725, saving model to ./model_PID__1292_loss_2.267_vloss_0.357_acc_0.698_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 2.2672 - MAE: 0.6981 - val_loss: 0.3568 - val_MAE: 0.3919 - lr: 0.0010\n",
            "\n",
            "Epoch 1293: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1293/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2672 - MAE: 0.6981\n",
            "Epoch 1293: loss improved from 2.26725 to 2.26716, saving model to ./model_PID__1293_loss_2.267_vloss_0.357_acc_0.698_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 2.2672 - MAE: 0.6981 - val_loss: 0.3568 - val_MAE: 0.3919 - lr: 0.0010\n",
            "\n",
            "Epoch 1294: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1294/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2671 - MAE: 0.6981\n",
            "Epoch 1294: loss improved from 2.26716 to 2.26708, saving model to ./model_PID__1294_loss_2.267_vloss_0.357_acc_0.698_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 2.2671 - MAE: 0.6981 - val_loss: 0.3568 - val_MAE: 0.3919 - lr: 0.0010\n",
            "\n",
            "Epoch 1295: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1295/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2670 - MAE: 0.6980\n",
            "Epoch 1295: loss improved from 2.26708 to 2.26700, saving model to ./model_PID__1295_loss_2.267_vloss_0.357_acc_0.698_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 2.2670 - MAE: 0.6980 - val_loss: 0.3569 - val_MAE: 0.3919 - lr: 0.0010\n",
            "\n",
            "Epoch 1296: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1296/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2669 - MAE: 0.6980\n",
            "Epoch 1296: loss improved from 2.26700 to 2.26692, saving model to ./model_PID__1296_loss_2.267_vloss_0.357_acc_0.698_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 2.2669 - MAE: 0.6980 - val_loss: 0.3569 - val_MAE: 0.3919 - lr: 0.0010\n",
            "\n",
            "Epoch 1297: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1297/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2668 - MAE: 0.6979\n",
            "Epoch 1297: loss improved from 2.26692 to 2.26683, saving model to ./model_PID__1297_loss_2.267_vloss_0.357_acc_0.698_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 2.2668 - MAE: 0.6979 - val_loss: 0.3569 - val_MAE: 0.3919 - lr: 0.0010\n",
            "\n",
            "Epoch 1298: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1298/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2668 - MAE: 0.6979\n",
            "Epoch 1298: loss improved from 2.26683 to 2.26675, saving model to ./model_PID__1298_loss_2.267_vloss_0.357_acc_0.698_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 2.2668 - MAE: 0.6979 - val_loss: 0.3570 - val_MAE: 0.3919 - lr: 0.0010\n",
            "\n",
            "Epoch 1299: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1299/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2667 - MAE: 0.6978\n",
            "Epoch 1299: loss improved from 2.26675 to 2.26667, saving model to ./model_PID__1299_loss_2.267_vloss_0.357_acc_0.698_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.2667 - MAE: 0.6978 - val_loss: 0.3570 - val_MAE: 0.3919 - lr: 0.0010\n",
            "\n",
            "Epoch 1300: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1300/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2666 - MAE: 0.6978\n",
            "Epoch 1300: loss improved from 2.26667 to 2.26660, saving model to ./model_PID__1300_loss_2.267_vloss_0.357_acc_0.698_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 2.2666 - MAE: 0.6978 - val_loss: 0.3570 - val_MAE: 0.3920 - lr: 0.0010\n",
            "\n",
            "Epoch 1301: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1301/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2665 - MAE: 0.6978\n",
            "Epoch 1301: loss improved from 2.26660 to 2.26652, saving model to ./model_PID__1301_loss_2.267_vloss_0.357_acc_0.698_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 2.2665 - MAE: 0.6978 - val_loss: 0.3571 - val_MAE: 0.3920 - lr: 0.0010\n",
            "\n",
            "Epoch 1302: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1302/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2664 - MAE: 0.6977\n",
            "Epoch 1302: loss improved from 2.26652 to 2.26644, saving model to ./model_PID__1302_loss_2.266_vloss_0.357_acc_0.698_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 2.2664 - MAE: 0.6977 - val_loss: 0.3571 - val_MAE: 0.3920 - lr: 0.0010\n",
            "\n",
            "Epoch 1303: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1303/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2664 - MAE: 0.6977\n",
            "Epoch 1303: loss improved from 2.26644 to 2.26636, saving model to ./model_PID__1303_loss_2.266_vloss_0.357_acc_0.698_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 2.2664 - MAE: 0.6977 - val_loss: 0.3572 - val_MAE: 0.3920 - lr: 0.0010\n",
            "\n",
            "Epoch 1304: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1304/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2663 - MAE: 0.6976\n",
            "Epoch 1304: loss improved from 2.26636 to 2.26628, saving model to ./model_PID__1304_loss_2.266_vloss_0.357_acc_0.698_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2.2663 - MAE: 0.6976 - val_loss: 0.3572 - val_MAE: 0.3920 - lr: 0.0010\n",
            "\n",
            "Epoch 1305: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1305/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2662 - MAE: 0.6976\n",
            "Epoch 1305: loss improved from 2.26628 to 2.26620, saving model to ./model_PID__1305_loss_2.266_vloss_0.357_acc_0.698_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 2.2662 - MAE: 0.6976 - val_loss: 0.3572 - val_MAE: 0.3920 - lr: 0.0010\n",
            "\n",
            "Epoch 1306: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1306/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2661 - MAE: 0.6975\n",
            "Epoch 1306: loss improved from 2.26620 to 2.26612, saving model to ./model_PID__1306_loss_2.266_vloss_0.357_acc_0.698_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 2.2661 - MAE: 0.6975 - val_loss: 0.3573 - val_MAE: 0.3920 - lr: 0.0010\n",
            "\n",
            "Epoch 1307: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1307/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2660 - MAE: 0.6975\n",
            "Epoch 1307: loss improved from 2.26612 to 2.26604, saving model to ./model_PID__1307_loss_2.266_vloss_0.357_acc_0.698_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 2.2660 - MAE: 0.6975 - val_loss: 0.3573 - val_MAE: 0.3920 - lr: 0.0010\n",
            "\n",
            "Epoch 1308: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1308/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2660 - MAE: 0.6975\n",
            "Epoch 1308: loss improved from 2.26604 to 2.26596, saving model to ./model_PID__1308_loss_2.266_vloss_0.357_acc_0.697_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 2.2660 - MAE: 0.6975 - val_loss: 0.3574 - val_MAE: 0.3921 - lr: 0.0010\n",
            "\n",
            "Epoch 1309: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1309/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2659 - MAE: 0.6974\n",
            "Epoch 1309: loss improved from 2.26596 to 2.26588, saving model to ./model_PID__1309_loss_2.266_vloss_0.357_acc_0.697_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.2659 - MAE: 0.6974 - val_loss: 0.3574 - val_MAE: 0.3921 - lr: 0.0010\n",
            "\n",
            "Epoch 1310: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1310/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2658 - MAE: 0.6974\n",
            "Epoch 1310: loss improved from 2.26588 to 2.26580, saving model to ./model_PID__1310_loss_2.266_vloss_0.357_acc_0.697_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 2.2658 - MAE: 0.6974 - val_loss: 0.3575 - val_MAE: 0.3921 - lr: 0.0010\n",
            "\n",
            "Epoch 1311: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1311/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2657 - MAE: 0.6973\n",
            "Epoch 1311: loss improved from 2.26580 to 2.26572, saving model to ./model_PID__1311_loss_2.266_vloss_0.358_acc_0.697_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 2.2657 - MAE: 0.6973 - val_loss: 0.3575 - val_MAE: 0.3921 - lr: 0.0010\n",
            "\n",
            "Epoch 1312: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1312/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2656 - MAE: 0.6973\n",
            "Epoch 1312: loss improved from 2.26572 to 2.26564, saving model to ./model_PID__1312_loss_2.266_vloss_0.358_acc_0.697_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 2.2656 - MAE: 0.6973 - val_loss: 0.3576 - val_MAE: 0.3921 - lr: 0.0010\n",
            "\n",
            "Epoch 1313: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1313/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2656 - MAE: 0.6972\n",
            "Epoch 1313: loss improved from 2.26564 to 2.26557, saving model to ./model_PID__1313_loss_2.266_vloss_0.358_acc_0.697_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 2.2656 - MAE: 0.6972 - val_loss: 0.3576 - val_MAE: 0.3921 - lr: 0.0010\n",
            "\n",
            "Epoch 1314: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1314/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2655 - MAE: 0.6972\n",
            "Epoch 1314: loss improved from 2.26557 to 2.26549, saving model to ./model_PID__1314_loss_2.265_vloss_0.358_acc_0.697_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 2.2655 - MAE: 0.6972 - val_loss: 0.3577 - val_MAE: 0.3921 - lr: 0.0010\n",
            "\n",
            "Epoch 1315: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1315/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2654 - MAE: 0.6972\n",
            "Epoch 1315: loss improved from 2.26549 to 2.26541, saving model to ./model_PID__1315_loss_2.265_vloss_0.358_acc_0.697_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 2.2654 - MAE: 0.6972 - val_loss: 0.3577 - val_MAE: 0.3922 - lr: 0.0010\n",
            "\n",
            "Epoch 1316: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1316/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2653 - MAE: 0.6971\n",
            "Epoch 1316: loss improved from 2.26541 to 2.26533, saving model to ./model_PID__1316_loss_2.265_vloss_0.358_acc_0.697_vacc_0.392.hdf5\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 2.2653 - MAE: 0.6971 - val_loss: 0.3577 - val_MAE: 0.3922 - lr: 0.0010\n",
            "\n",
            "Epoch 1317: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1317/5500\n",
            "1/1 [==============================] - ETA: 0s - loss: 2.2652 - MAE: 0.6971"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-104-3d100e390548>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__learning__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_epochs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_epochs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/wandb/integration/keras/keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/wandb/integration/keras/keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/wandb/integration/keras/keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1443\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[0;32m-> 1445\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1446\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "if __learning__: \n",
        "    history = model.fit(X_train, X_train, epochs=_epochs_, batch_size=_epochs_, validation_data=(X_test, y_test),verbose=1,callbacks=callbacks)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "__load_file__=True\n",
        "model_file=\"model_PID__0634_loss_0.086_vloss_1.253_acc_0.961_vacc_0.886.hdf5\"\n",
        "model_url=\"https://github.com/sipocz/pid_time_series/raw/main/model3/\"+model_file"
      ],
      "metadata": {
        "id": "EGg1PjCJDTKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __load_file__:\n",
        "    ! rm *.hdf5 \n",
        "    ! wget $model_url\n",
        "    model.load_weights(model_file)"
      ],
      "metadata": {
        "id": "JgzklVywoNmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwcWQ94IpDFu"
      },
      "outputs": [],
      "source": [
        "y_pred=model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_display_object_visualization.html#sphx-glr-auto-examples-miscellaneous-plot-display-object-visualization-py"
      ],
      "metadata": {
        "id": "H0c0Fkd2cWRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import Binarizer\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "zctwrl1AcTZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bina_transformer=Binarizer(threshold=0.5)\n",
        "y_pred_transform=bina_transformer.fit_transform(y_pred)"
      ],
      "metadata": {
        "id": "hxZwDiKYhA5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCqcqNJl79G5"
      },
      "outputs": [],
      "source": [
        "cm=confusion_matrix(y_test,y_pred_transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm_display = ConfusionMatrixDisplay(cm).plot()"
      ],
      "metadata": {
        "id": "Z69kCq3T-pMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZ0rmkNsBGnl"
      },
      "outputs": [],
      "source": [
        "fpr, tpr, _ = roc_curve( y_pred_transform,y_test,pos_label=1)\n",
        "roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()\n",
        "auc = roc_auc_score(y_test, y_pred_transform)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_all_normalized"
      ],
      "metadata": {
        "id": "sNIc1l6vF6Y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def color_changer(arr):\n",
        "    o=[\"r\" if i>0.5 else \"g\" for i in arr]\n",
        "    return o"
      ],
      "metadata": {
        "id": "YFJoZO8TG1ED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotgraf(df_in, predicted):\n",
        "    xkoordinata=[i for i in range(len(df_in[\"0\"]))]\n",
        "    plot.figure(figsize=(12,6))\n",
        "    col_ch=color_changer(predicted)\n",
        "    plot.scatter(xkoordinata,df_in[\"0\"],c=col_ch,marker=\".\",alpha=0.3)\n",
        "    plot.ylabel('értékek')\n",
        "    plot.xlabel('index')\n",
        "    plot\n",
        "    plot.show()"
      ],
      "metadata": {
        "id": "YMHy-wbZGeqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_y_all_predict"
      ],
      "metadata": {
        "id": "HuL1OutGHHEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_y_all_predict=model.predict(df_all_normalized[prediktorok])"
      ],
      "metadata": {
        "id": "4aXpzheKE7bM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_y_predict=df_y_all_predict.round()"
      ],
      "metadata": {
        "id": "70M96KLSdCHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_y_predict"
      ],
      "metadata": {
        "id": "e72-bHKzdZve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plotgraf(df_all_normalized[400:600],df_y_predict[400:600])"
      ],
      "metadata": {
        "id": "BO3xdrHVGXhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auc"
      ],
      "metadata": {
        "id": "WMRd5eGU9ASA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grafikon3(fx,desc1,txt1,desc2=\"\",txt2=\"\",desc3=\"\",txt3=\"\",ngraf=2,c1='rgba(35,128,132,0.8)', c2='rgba(193,99,99,0.8)',c3='rgba(193,99,99,0.8)',title=None):\n",
        "    '''\n",
        "    fx: dataFrame\n",
        "    desc1:column1\n",
        "    txt1: label1\n",
        "    desc2:column2\n",
        "    txt2: label2\n",
        "    ngraf: number of graph\n",
        "    c1: color1\n",
        "    c2: color2\n",
        "    title: graph title\n",
        "    '''\n",
        "    \n",
        "    #x_=[i for i in range(len(y_pred))]\n",
        "    if title==None:\n",
        "      title=txt1+\" \"+txt2\n",
        "    import plotly.express as px\n",
        "    import plotly.graph_objects as go\n",
        "    from plotly.subplots import make_subplots\n",
        "    fig0 = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
        "\n",
        "\n",
        "    if ngraf>=3:\n",
        "        fig0.add_trace(\n",
        "            go.Bar(x=fx.index, y=fx[desc3], marker_color='rgba(225, 20, 20,0.2)',  name=txt3, showlegend=True, ),\n",
        "              secondary_y=False,\n",
        "            #row=1, col=1\n",
        "        )\n",
        "\n",
        "\n",
        "    if ngraf>=2:\n",
        "        fig0.add_trace(\n",
        "            go.Scatter(x=fx.index, y=fx[desc2], name=txt2, line=dict(color=c2) ,showlegend=True  ),\n",
        "            secondary_y=False,\n",
        "            #row=1, col=1\n",
        "\n",
        "        )\n",
        "\n",
        "    fig0.add_trace(\n",
        "        go.Scatter(x=fx.index, y=fx[desc1], name=txt1, line=dict(color=c1) ,showlegend=True  ),\n",
        "        secondary_y=False,\n",
        "        #row=1, col=1\n",
        "\n",
        "    )\n",
        "\n",
        "    fig0.update_layout(\n",
        "        title=title,\n",
        "        autosize=False,\n",
        "        width=1200,\n",
        "        height=600,\n",
        "        \n",
        "        )\n",
        "\n",
        "    print(title)\n",
        "    fig0.update_yaxes(title_text=\"<b>\"+title+\"</b>\", secondary_y=False)\n",
        "    #fig0.update_yaxes(title_text=\"<b>Alarm státusz</b>\", secondary_y=True)\n",
        "    fig0.update_layout(paper_bgcolor='rgb(200,200,200)')\n",
        "    fig0.show()"
      ],
      "metadata": {
        "id": "qa-AQAZV0EPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history_df=pd.DataFrame({\"epoch\":history.epoch, \"loss\":history.history[\"loss\"],\"val_loss\":history.history[\"val_loss\"]})"
      ],
      "metadata": {
        "id": "Uve0EfpV0Rkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grafikon3(history_df,\"loss\",\"Loss\",\"val_loss\",\"Val_Loss\",title=None)"
      ],
      "metadata": {
        "id": "4ENvDCA-0U1g"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyaAkB18bEX6uf012BJ5V9",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "67a7971beebc423382b8bd33854da0fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78a3dcd8cc5b432d87da8556d8d12b28",
              "IPY_MODEL_01327c6e47834b51b7ac073f531dab1d"
            ],
            "layout": "IPY_MODEL_f7d177a00baf4a79ad18daf903c1e426"
          }
        },
        "78a3dcd8cc5b432d87da8556d8d12b28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9ff02cee5e546818f289597c6fbf2ad",
            "placeholder": "​",
            "style": "IPY_MODEL_80fb96cba1b44366bcbd25427c52faa0",
            "value": "0.001 MB of 0.517 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "01327c6e47834b51b7ac073f531dab1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f02f4b46e2e46ea84bb539b813dbec3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7a0dcfacddb41e8bb58facaada21b6d",
            "value": 0.001083623622625766
          }
        },
        "f7d177a00baf4a79ad18daf903c1e426": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9ff02cee5e546818f289597c6fbf2ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80fb96cba1b44366bcbd25427c52faa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f02f4b46e2e46ea84bb539b813dbec3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7a0dcfacddb41e8bb58facaada21b6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}