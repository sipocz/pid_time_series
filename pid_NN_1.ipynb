{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPY15rmI79UbBKEXL3fREPH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sipocz/pid_time_series/blob/main/pid_NN_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OWFIUUUGKGdA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "ag6zIuPmKTux"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coqJiGk7KW_4",
        "outputId": "a972b63d-055f-4cc0-a8ee-52055bdcdf0a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#user = \"Anna\"\n",
        "user = \"SL\"\n",
        "uzem = \"Szint1\"\n",
        "data_source=\"5\"\n",
        "#fname=\"72C03_TC_error_toNN.csv\"\n",
        "fname_good = \"415_SC_error_part1.csv\"\n",
        "fname_bad = \"415_SC_error_part2.csv\""
      ],
      "metadata": {
        "id": "-_usNw7yKZDt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Elérési út a 415_SC_error-hoz\n",
        "if user==\"Anna\":\n",
        "    path_good = \"/content/drive/MyDrive/Egyetem_MSc/Diplomamunka/2022Anna/Datapipeline/\" + data_source + \"/\" + fname_good\n",
        "    path_bad = \"/content/drive/MyDrive/Egyetem_MSc/Diplomamunka/2022Anna/Datapipeline/\" + data_source + \"/\" + fname_bad\n",
        "    path_fig = \"/content/drive/MyDrive/Egyetem_MSc/Diplomamunka/2022Anna/Datapipeline/plots/\"\n",
        "else:\n",
        "    path_good = \"/content/drive/MyDrive/2022Anna/Datapipeline/\" + data_source + \"/\" + fname_good\n",
        "    path_bad = \"/content/drive/MyDrive/2022Anna/Datapipeline/\" + data_source + \"/\" + fname_bad\n",
        "    path_fig = \"/content/drive/MyDrive/2022Anna/Datapipeline/plots/\"\n"
      ],
      "metadata": {
        "id": "OkO7F6NaKbxi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(path_good)\n",
        "print(path_bad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5ZDDiY9KfAQ",
        "outputId": "b1a5ad2d-9a71-4848-ceec-241320c03455"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/2022Anna/Datapipeline/5/415_SC_error_part1.csv\n",
            "/content/drive/MyDrive/2022Anna/Datapipeline/5/415_SC_error_part2.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_good = pd.read_csv(path_good,usecols=None)\n",
        "df_bad = pd.read_csv(path_bad,usecols=None)"
      ],
      "metadata": {
        "id": "vUcMjZAGKvtt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_good.isnull().values.any())\n",
        "print(df_bad.isnull().values.any())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYuDXKraLOt4",
        "outputId": "cf049cd8-24a1-4738-b746-582084fe5dba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_good.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "vzl5zIO1LUoq",
        "outputId": "c2289b58-4f60-41df-f763-0f7787c3481f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0          1          2          3          4        5         6  \\\n",
              "0 -54.810024 -80.342186 -60.770203 -41.081482 -21.779583 -3.82353 -0.806820   \n",
              "1 -80.342186 -60.770203 -41.081482 -21.779583  -3.823530 -0.80682  0.220875   \n",
              "\n",
              "          7         8         9        10        11        12        13  \\\n",
              "0  0.220875  0.220875  0.220875  0.220875  0.220875  0.220875  0.220875   \n",
              "1  0.220875  0.220875  0.220875  0.220875  0.220875  0.220875  0.220875   \n",
              "\n",
              "         14        15        16        17        18        19  \n",
              "0  0.220875  0.220875  0.220875  0.220875  0.220875  0.220875  \n",
              "1  0.220875  0.220875  0.220875  0.220875  0.220875  0.220875  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-439ddd2f-91a0-4928-b692-357e3ca64c75\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-54.810024</td>\n",
              "      <td>-80.342186</td>\n",
              "      <td>-60.770203</td>\n",
              "      <td>-41.081482</td>\n",
              "      <td>-21.779583</td>\n",
              "      <td>-3.82353</td>\n",
              "      <td>-0.806820</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-80.342186</td>\n",
              "      <td>-60.770203</td>\n",
              "      <td>-41.081482</td>\n",
              "      <td>-21.779583</td>\n",
              "      <td>-3.823530</td>\n",
              "      <td>-0.80682</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-439ddd2f-91a0-4928-b692-357e3ca64c75')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-439ddd2f-91a0-4928-b692-357e3ca64c75 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-439ddd2f-91a0-4928-b692-357e3ca64c75');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f0xJfadFMOfA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plot\n",
        "\n",
        "df_ = df_good\n",
        "\n",
        "# You must normalize the data before applying the fit method\n",
        "df_good_normalized=(df_ - df_.mean()) / df_.std()\n",
        "\n",
        "# Normalize bad data with the good data parameters\n",
        "df_bad_normalized=(df_bad - df_.mean()) / df_.std()"
      ],
      "metadata": {
        "id": "hIMQw2sULmj9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_good_normalized[\"state\"]=0\n",
        "df_bad_normalized[\"state\"]=1"
      ],
      "metadata": {
        "id": "wknFhIRBNQ7k"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_good_normalized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "3W5mi70VM6hL",
        "outputId": "7b653229-bcc9-40c7-d663-3242893c7c9e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              0          1          2          3         4         5  \\\n",
              "0    -10.681306 -16.586266 -14.612051 -11.087981 -6.293341 -1.192618   \n",
              "1    -15.654548 -12.549683  -9.889987  -5.905180 -1.164099 -0.314249   \n",
              "2    -11.842250  -8.489023  -5.260696  -1.083756 -0.302359 -0.015017   \n",
              "3     -8.007214  -4.508142  -0.954188  -0.273732 -0.008793 -0.015017   \n",
              "4     -4.247524  -0.804833  -0.230672   0.002217 -0.008793 -0.015017   \n",
              "...         ...        ...        ...        ...       ...       ...   \n",
              "1053   0.037801   0.029297   0.015806   0.002217 -0.008793 -0.015017   \n",
              "1054   0.037801   0.029297   0.015806   0.002217 -0.008793 -0.015017   \n",
              "1055   0.037801   0.029297   0.015806   0.002217 -0.008793 -0.015017   \n",
              "1056   0.037801   0.029297   0.015806   0.002217 -0.008793 -0.015017   \n",
              "1057   0.037801   0.029297   0.015806   0.002217 -0.008793 -0.015017   \n",
              "\n",
              "             6         7         8         9  ...        11        12  \\\n",
              "0    -0.315574 -0.016425 -0.016425 -0.016425  ... -0.016425 -0.016425   \n",
              "1    -0.016141 -0.016425 -0.016425 -0.016425  ... -0.016425 -0.016425   \n",
              "2    -0.016141 -0.016425 -0.016425 -0.016425  ... -0.016425 -0.016425   \n",
              "3    -0.016141 -0.016425 -0.016425 -0.016425  ... -0.016425 -0.016425   \n",
              "4    -0.016141 -0.016425 -0.016425 -0.016425  ... -0.016425 -0.016425   \n",
              "...        ...       ...       ...       ...  ...       ...       ...   \n",
              "1053 -0.016141 -0.016425 -0.016425 -0.016425  ... -0.016425 -0.016425   \n",
              "1054 -0.016141 -0.016425 -0.016425 -0.016425  ... -0.016425 -0.016425   \n",
              "1055 -0.016141 -0.016425 -0.016425 -0.016425  ... -0.016425 -0.016425   \n",
              "1056 -0.016141 -0.016425 -0.016425 -0.016425  ... -0.016425 -0.016425   \n",
              "1057 -0.016141 -0.016425 -0.016425 -0.016425  ... -0.016425 -0.016425   \n",
              "\n",
              "            13        14        15        16        17        18        19  \\\n",
              "0    -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425   \n",
              "1    -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425   \n",
              "2    -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425   \n",
              "3    -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425   \n",
              "4    -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "1053 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425   \n",
              "1054 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425   \n",
              "1055 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425   \n",
              "1056 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425   \n",
              "1057 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425 -0.016425   \n",
              "\n",
              "      state  \n",
              "0         0  \n",
              "1         0  \n",
              "2         0  \n",
              "3         0  \n",
              "4         0  \n",
              "...     ...  \n",
              "1053      0  \n",
              "1054      0  \n",
              "1055      0  \n",
              "1056      0  \n",
              "1057      0  \n",
              "\n",
              "[1058 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-97813c23-fcdb-4a36-8048-1099605b9e5b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-10.681306</td>\n",
              "      <td>-16.586266</td>\n",
              "      <td>-14.612051</td>\n",
              "      <td>-11.087981</td>\n",
              "      <td>-6.293341</td>\n",
              "      <td>-1.192618</td>\n",
              "      <td>-0.315574</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-15.654548</td>\n",
              "      <td>-12.549683</td>\n",
              "      <td>-9.889987</td>\n",
              "      <td>-5.905180</td>\n",
              "      <td>-1.164099</td>\n",
              "      <td>-0.314249</td>\n",
              "      <td>-0.016141</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-11.842250</td>\n",
              "      <td>-8.489023</td>\n",
              "      <td>-5.260696</td>\n",
              "      <td>-1.083756</td>\n",
              "      <td>-0.302359</td>\n",
              "      <td>-0.015017</td>\n",
              "      <td>-0.016141</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-8.007214</td>\n",
              "      <td>-4.508142</td>\n",
              "      <td>-0.954188</td>\n",
              "      <td>-0.273732</td>\n",
              "      <td>-0.008793</td>\n",
              "      <td>-0.015017</td>\n",
              "      <td>-0.016141</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-4.247524</td>\n",
              "      <td>-0.804833</td>\n",
              "      <td>-0.230672</td>\n",
              "      <td>0.002217</td>\n",
              "      <td>-0.008793</td>\n",
              "      <td>-0.015017</td>\n",
              "      <td>-0.016141</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1053</th>\n",
              "      <td>0.037801</td>\n",
              "      <td>0.029297</td>\n",
              "      <td>0.015806</td>\n",
              "      <td>0.002217</td>\n",
              "      <td>-0.008793</td>\n",
              "      <td>-0.015017</td>\n",
              "      <td>-0.016141</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1054</th>\n",
              "      <td>0.037801</td>\n",
              "      <td>0.029297</td>\n",
              "      <td>0.015806</td>\n",
              "      <td>0.002217</td>\n",
              "      <td>-0.008793</td>\n",
              "      <td>-0.015017</td>\n",
              "      <td>-0.016141</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1055</th>\n",
              "      <td>0.037801</td>\n",
              "      <td>0.029297</td>\n",
              "      <td>0.015806</td>\n",
              "      <td>0.002217</td>\n",
              "      <td>-0.008793</td>\n",
              "      <td>-0.015017</td>\n",
              "      <td>-0.016141</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1056</th>\n",
              "      <td>0.037801</td>\n",
              "      <td>0.029297</td>\n",
              "      <td>0.015806</td>\n",
              "      <td>0.002217</td>\n",
              "      <td>-0.008793</td>\n",
              "      <td>-0.015017</td>\n",
              "      <td>-0.016141</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1057</th>\n",
              "      <td>0.037801</td>\n",
              "      <td>0.029297</td>\n",
              "      <td>0.015806</td>\n",
              "      <td>0.002217</td>\n",
              "      <td>-0.008793</td>\n",
              "      <td>-0.015017</td>\n",
              "      <td>-0.016141</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>-0.016425</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1058 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97813c23-fcdb-4a36-8048-1099605b9e5b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-97813c23-fcdb-4a36-8048-1099605b9e5b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-97813c23-fcdb-4a36-8048-1099605b9e5b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_all_normalized=pd.concat([df_good_normalized,df_bad_normalized],axis=0)"
      ],
      "metadata": {
        "id": "9nY0OMtYPT8J"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all_normalized.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "ClfUnwBRPwgK",
        "outputId": "e720d811-cb6c-4207-9c99-d80c17acfa53"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             0         1         2         3         4         5         6  \\\n",
              "1263  0.029553  0.020564  0.005651 -0.009153 -0.020888 -0.027346 -0.028478   \n",
              "1264  0.029553  0.020564  0.005651 -0.009153 -0.020888 -0.027346 -0.028478   \n",
              "1265  0.029553  0.020564  0.005651 -0.009153 -0.020888 -0.027346 -0.028478   \n",
              "1266  0.029553  0.020564  0.005651 -0.009153 -0.020888 -0.027346 -0.028478   \n",
              "1267  0.029553  0.020564  0.005651 -0.009153 -0.020888 -0.027346 -0.028478   \n",
              "\n",
              "             7         8         9  ...        11        12        13  \\\n",
              "1263 -0.028763 -0.028763 -0.028763  ... -0.028763 -0.028763 -0.028763   \n",
              "1264 -0.028763 -0.028763 -0.028763  ... -0.028763 -0.028763 -0.028763   \n",
              "1265 -0.028763 -0.028763 -0.028763  ... -0.028763 -0.028763 -0.028763   \n",
              "1266 -0.028763 -0.028763 -0.028763  ... -0.028763 -0.028763 -0.028763   \n",
              "1267 -0.028763 -0.028763 -0.028763  ... -0.028763 -0.028763 -0.028763   \n",
              "\n",
              "            14        15        16        17        18        19  state  \n",
              "1263 -0.028763 -0.028763 -0.028763 -0.028763 -0.028763 -0.028763      1  \n",
              "1264 -0.028763 -0.028763 -0.028763 -0.028763 -0.028763 -0.028763      1  \n",
              "1265 -0.028763 -0.028763 -0.028763 -0.028763 -0.028763 -0.028763      1  \n",
              "1266 -0.028763 -0.028763 -0.028763 -0.028763 -0.028763 -0.028763      1  \n",
              "1267 -0.028763 -0.028763 -0.028763 -0.028763 -0.028763 -0.028763      1  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-334af88e-3818-4ee1-a95e-3a1a71237106\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1263</th>\n",
              "      <td>0.029553</td>\n",
              "      <td>0.020564</td>\n",
              "      <td>0.005651</td>\n",
              "      <td>-0.009153</td>\n",
              "      <td>-0.020888</td>\n",
              "      <td>-0.027346</td>\n",
              "      <td>-0.028478</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1264</th>\n",
              "      <td>0.029553</td>\n",
              "      <td>0.020564</td>\n",
              "      <td>0.005651</td>\n",
              "      <td>-0.009153</td>\n",
              "      <td>-0.020888</td>\n",
              "      <td>-0.027346</td>\n",
              "      <td>-0.028478</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1265</th>\n",
              "      <td>0.029553</td>\n",
              "      <td>0.020564</td>\n",
              "      <td>0.005651</td>\n",
              "      <td>-0.009153</td>\n",
              "      <td>-0.020888</td>\n",
              "      <td>-0.027346</td>\n",
              "      <td>-0.028478</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1266</th>\n",
              "      <td>0.029553</td>\n",
              "      <td>0.020564</td>\n",
              "      <td>0.005651</td>\n",
              "      <td>-0.009153</td>\n",
              "      <td>-0.020888</td>\n",
              "      <td>-0.027346</td>\n",
              "      <td>-0.028478</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1267</th>\n",
              "      <td>0.029553</td>\n",
              "      <td>0.020564</td>\n",
              "      <td>0.005651</td>\n",
              "      <td>-0.009153</td>\n",
              "      <td>-0.020888</td>\n",
              "      <td>-0.027346</td>\n",
              "      <td>-0.028478</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>-0.028763</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-334af88e-3818-4ee1-a95e-3a1a71237106')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-334af88e-3818-4ee1-a95e-3a1a71237106 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-334af88e-3818-4ee1-a95e-3a1a71237106');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import InputLayer, Dense, LSTM, Input, Dropout\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import SGD,Adam,Adamax,Nadam,Ftrl,Adadelta\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from keras.backend import clear_session\n",
        "from tensorflow.keras.losses import mean_absolute_percentage_error, huber,kld\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "clear_session()\n",
        "\n",
        "kernel_reg_1=tf.keras.regularizers.L2(0.1)\n",
        "\n",
        "input_size=20\n",
        "drop_frac0=0.0  \n",
        "drop_frac1=0.0  \n",
        "\n",
        "input1=Input(shape=(input_size,))\n",
        "l1_out=Dense(35,activation=\"relu\",)(input1) # kernel_initializer='lecun_normal'\n",
        "l2_out=Dropout(drop_frac0)(l1_out)\n",
        "\n",
        "\n",
        "l3_out=Dense(5,activation=\"relu\",)(l2_out) #kernel_initializer='lecun_normal',\n",
        "l4_out=Dropout(drop_frac1)(l3_out)\n",
        "\n",
        "pred=Dense(1, activation=\"sigmoid\",)(l4_out)\n",
        "\n",
        "model = Model(inputs=input1, outputs=pred)\n",
        "optimizer=SGD(learning_rate=0.01,) #\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "    optimizer=optimizer,\n",
        "    metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "rcPrX4lWP2R_"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediktorok=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\"]\n",
        "X_NN=df_all_normalized[prediktorok][:-100]  # \n",
        "y_NN=df_all_normalized[\"state\"][:-100]"
      ],
      "metadata": {
        "id": "RGIztQ3tQ3ni"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(X_NN,y_NN,train_size=0.7,shuffle=False)"
      ],
      "metadata": {
        "id": "rdH49nLKRVoh"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " history = model.fit(X_train, y_train, epochs=1300, batch_size=16, validation_data=(X_test, y_test),\n",
        "                    \n",
        "                   verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ol0mW6WRlkS",
        "outputId": "c1a8ff62-f162-4a66-f31a-81942533bd95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1300\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.7287 - accuracy: 0.7375 - val_loss: 0.8200 - val_accuracy: 0.1841\n",
            "Epoch 2/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.6368 - accuracy: 0.7529 - val_loss: 0.8234 - val_accuracy: 0.2051\n",
            "Epoch 3/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.5972 - accuracy: 0.7548 - val_loss: 0.8524 - val_accuracy: 0.2246\n",
            "Epoch 4/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.5664 - accuracy: 0.7548 - val_loss: 0.8800 - val_accuracy: 0.2455\n",
            "Epoch 5/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.5391 - accuracy: 0.7574 - val_loss: 0.9363 - val_accuracy: 0.2335\n",
            "Epoch 6/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.5174 - accuracy: 0.7612 - val_loss: 0.9670 - val_accuracy: 0.2365\n",
            "Epoch 7/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.7619 - val_loss: 0.9862 - val_accuracy: 0.2515\n",
            "Epoch 8/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.4859 - accuracy: 0.7644 - val_loss: 1.0203 - val_accuracy: 0.2560\n",
            "Epoch 9/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.7677 - val_loss: 1.0552 - val_accuracy: 0.2530\n",
            "Epoch 10/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.7696 - val_loss: 1.0899 - val_accuracy: 0.2500\n",
            "Epoch 11/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.7702 - val_loss: 1.0904 - val_accuracy: 0.2605\n",
            "Epoch 12/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7754 - val_loss: 1.1087 - val_accuracy: 0.2680\n",
            "Epoch 13/1300\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7805 - val_loss: 1.1412 - val_accuracy: 0.2545\n",
            "Epoch 14/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7824 - val_loss: 1.1161 - val_accuracy: 0.2784\n",
            "Epoch 15/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.7875 - val_loss: 1.1228 - val_accuracy: 0.2769\n",
            "Epoch 16/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.7940 - val_loss: 1.1457 - val_accuracy: 0.2725\n",
            "Epoch 17/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.7965 - val_loss: 1.1782 - val_accuracy: 0.2680\n",
            "Epoch 18/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.3954 - accuracy: 0.8017 - val_loss: 1.1529 - val_accuracy: 0.2844\n",
            "Epoch 19/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.3881 - accuracy: 0.8055 - val_loss: 1.1656 - val_accuracy: 0.2934\n",
            "Epoch 20/1300\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.3808 - accuracy: 0.8074 - val_loss: 1.1883 - val_accuracy: 0.2919\n",
            "Epoch 21/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.3747 - accuracy: 0.8126 - val_loss: 1.1632 - val_accuracy: 0.3084\n",
            "Epoch 22/1300\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.3673 - accuracy: 0.8171 - val_loss: 1.1615 - val_accuracy: 0.3428\n",
            "Epoch 23/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.3601 - accuracy: 0.8222 - val_loss: 1.1586 - val_accuracy: 0.3743\n",
            "Epoch 24/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.3537 - accuracy: 0.8562 - val_loss: 1.1587 - val_accuracy: 0.4805\n",
            "Epoch 25/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.3471 - accuracy: 0.8935 - val_loss: 1.1201 - val_accuracy: 0.5030\n",
            "Epoch 26/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.3411 - accuracy: 0.8941 - val_loss: 1.1663 - val_accuracy: 0.4940\n",
            "Epoch 27/1300\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.3353 - accuracy: 0.8979 - val_loss: 1.0996 - val_accuracy: 0.5120\n",
            "Epoch 28/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.3295 - accuracy: 0.9018 - val_loss: 1.1300 - val_accuracy: 0.5045\n",
            "Epoch 29/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.3237 - accuracy: 0.9069 - val_loss: 1.1515 - val_accuracy: 0.5015\n",
            "Epoch 30/1300\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.3183 - accuracy: 0.9076 - val_loss: 1.0828 - val_accuracy: 0.5225\n",
            "Epoch 31/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.3134 - accuracy: 0.9114 - val_loss: 1.0945 - val_accuracy: 0.5180\n",
            "Epoch 32/1300\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.3077 - accuracy: 0.9114 - val_loss: 1.1244 - val_accuracy: 0.5090\n",
            "Epoch 33/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.3022 - accuracy: 0.9108 - val_loss: 1.0979 - val_accuracy: 0.5240\n",
            "Epoch 34/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2971 - accuracy: 0.9166 - val_loss: 1.1606 - val_accuracy: 0.5105\n",
            "Epoch 35/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2929 - accuracy: 0.9153 - val_loss: 1.1075 - val_accuracy: 0.5269\n",
            "Epoch 36/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2885 - accuracy: 0.9134 - val_loss: 1.0889 - val_accuracy: 0.5329\n",
            "Epoch 37/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2853 - accuracy: 0.9146 - val_loss: 1.1148 - val_accuracy: 0.5299\n",
            "Epoch 38/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2813 - accuracy: 0.9159 - val_loss: 1.1083 - val_accuracy: 0.5269\n",
            "Epoch 39/1300\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.2781 - accuracy: 0.9146 - val_loss: 1.1332 - val_accuracy: 0.5254\n",
            "Epoch 40/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2753 - accuracy: 0.9159 - val_loss: 1.1034 - val_accuracy: 0.5314\n",
            "Epoch 41/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2721 - accuracy: 0.9114 - val_loss: 1.1769 - val_accuracy: 0.5195\n",
            "Epoch 42/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2696 - accuracy: 0.9159 - val_loss: 1.1481 - val_accuracy: 0.5254\n",
            "Epoch 43/1300\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.2666 - accuracy: 0.9146 - val_loss: 1.0872 - val_accuracy: 0.5374\n",
            "Epoch 44/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2640 - accuracy: 0.9159 - val_loss: 1.0946 - val_accuracy: 0.5389\n",
            "Epoch 45/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2619 - accuracy: 0.9121 - val_loss: 1.0582 - val_accuracy: 0.5464\n",
            "Epoch 46/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2591 - accuracy: 0.9172 - val_loss: 1.1542 - val_accuracy: 0.5284\n",
            "Epoch 47/1300\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.2565 - accuracy: 0.9185 - val_loss: 1.1258 - val_accuracy: 0.5359\n",
            "Epoch 48/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2539 - accuracy: 0.9172 - val_loss: 1.1352 - val_accuracy: 0.5404\n",
            "Epoch 49/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2511 - accuracy: 0.9166 - val_loss: 1.1794 - val_accuracy: 0.5329\n",
            "Epoch 50/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2488 - accuracy: 0.9185 - val_loss: 1.1659 - val_accuracy: 0.5374\n",
            "Epoch 51/1300\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.2464 - accuracy: 0.9178 - val_loss: 1.1319 - val_accuracy: 0.5494\n",
            "Epoch 52/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2446 - accuracy: 0.9191 - val_loss: 1.1372 - val_accuracy: 0.5479\n",
            "Epoch 53/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2427 - accuracy: 0.9191 - val_loss: 1.1664 - val_accuracy: 0.5449\n",
            "Epoch 54/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2400 - accuracy: 0.9217 - val_loss: 1.1922 - val_accuracy: 0.5449\n",
            "Epoch 55/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2379 - accuracy: 0.9198 - val_loss: 1.1622 - val_accuracy: 0.5494\n",
            "Epoch 56/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2354 - accuracy: 0.9243 - val_loss: 1.1897 - val_accuracy: 0.5479\n",
            "Epoch 57/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2338 - accuracy: 0.9217 - val_loss: 1.1586 - val_accuracy: 0.5494\n",
            "Epoch 58/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2314 - accuracy: 0.9236 - val_loss: 1.1703 - val_accuracy: 0.5524\n",
            "Epoch 59/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2290 - accuracy: 0.9249 - val_loss: 1.2363 - val_accuracy: 0.5464\n",
            "Epoch 60/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2274 - accuracy: 0.9243 - val_loss: 1.2060 - val_accuracy: 0.5509\n",
            "Epoch 61/1300\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.2251 - accuracy: 0.9281 - val_loss: 1.1906 - val_accuracy: 0.5524\n",
            "Epoch 62/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2234 - accuracy: 0.9268 - val_loss: 1.1330 - val_accuracy: 0.5614\n",
            "Epoch 63/1300\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.2220 - accuracy: 0.9275 - val_loss: 1.1625 - val_accuracy: 0.5584\n",
            "Epoch 64/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2193 - accuracy: 0.9320 - val_loss: 1.1649 - val_accuracy: 0.5614\n",
            "Epoch 65/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2190 - accuracy: 0.9300 - val_loss: 1.1901 - val_accuracy: 0.5569\n",
            "Epoch 66/1300\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.2174 - accuracy: 0.9313 - val_loss: 1.1930 - val_accuracy: 0.5584\n",
            "Epoch 67/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2163 - accuracy: 0.9326 - val_loss: 1.2029 - val_accuracy: 0.5584\n",
            "Epoch 68/1300\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.2147 - accuracy: 0.9339 - val_loss: 1.2167 - val_accuracy: 0.5569\n",
            "Epoch 69/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2131 - accuracy: 0.9332 - val_loss: 1.2335 - val_accuracy: 0.5509\n",
            "Epoch 70/1300\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.2125 - accuracy: 0.9332 - val_loss: 1.2329 - val_accuracy: 0.5569\n",
            "Epoch 71/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2112 - accuracy: 0.9339 - val_loss: 1.2234 - val_accuracy: 0.5554\n",
            "Epoch 72/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2102 - accuracy: 0.9352 - val_loss: 1.2019 - val_accuracy: 0.5629\n",
            "Epoch 73/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2094 - accuracy: 0.9332 - val_loss: 1.3101 - val_accuracy: 0.5434\n",
            "Epoch 74/1300\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.2083 - accuracy: 0.9358 - val_loss: 1.2719 - val_accuracy: 0.5539\n",
            "Epoch 75/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2070 - accuracy: 0.9365 - val_loss: 1.3300 - val_accuracy: 0.5449\n",
            "Epoch 76/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2060 - accuracy: 0.9365 - val_loss: 1.2789 - val_accuracy: 0.5509\n",
            "Epoch 77/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2056 - accuracy: 0.9358 - val_loss: 1.2979 - val_accuracy: 0.5524\n",
            "Epoch 78/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2040 - accuracy: 0.9377 - val_loss: 1.3243 - val_accuracy: 0.5494\n",
            "Epoch 79/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2027 - accuracy: 0.9377 - val_loss: 1.1855 - val_accuracy: 0.5674\n",
            "Epoch 80/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2029 - accuracy: 0.9371 - val_loss: 1.3084 - val_accuracy: 0.5509\n",
            "Epoch 81/1300\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.2016 - accuracy: 0.9397 - val_loss: 1.3661 - val_accuracy: 0.5449\n",
            "Epoch 82/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2009 - accuracy: 0.9390 - val_loss: 1.2634 - val_accuracy: 0.5584\n",
            "Epoch 83/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.2002 - accuracy: 0.9390 - val_loss: 1.3287 - val_accuracy: 0.5494\n",
            "Epoch 84/1300\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.1992 - accuracy: 0.9377 - val_loss: 1.3688 - val_accuracy: 0.5479\n",
            "Epoch 85/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1986 - accuracy: 0.9390 - val_loss: 1.3663 - val_accuracy: 0.5449\n",
            "Epoch 86/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1982 - accuracy: 0.9397 - val_loss: 1.3601 - val_accuracy: 0.5509\n",
            "Epoch 87/1300\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.1969 - accuracy: 0.9384 - val_loss: 1.3164 - val_accuracy: 0.5554\n",
            "Epoch 88/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1967 - accuracy: 0.9397 - val_loss: 1.3761 - val_accuracy: 0.5494\n",
            "Epoch 89/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1959 - accuracy: 0.9397 - val_loss: 1.3055 - val_accuracy: 0.5599\n",
            "Epoch 90/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1955 - accuracy: 0.9409 - val_loss: 1.3771 - val_accuracy: 0.5464\n",
            "Epoch 91/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1947 - accuracy: 0.9403 - val_loss: 1.3797 - val_accuracy: 0.5449\n",
            "Epoch 92/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1940 - accuracy: 0.9390 - val_loss: 1.4508 - val_accuracy: 0.5359\n",
            "Epoch 93/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1935 - accuracy: 0.9397 - val_loss: 1.4180 - val_accuracy: 0.5479\n",
            "Epoch 94/1300\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.1931 - accuracy: 0.9397 - val_loss: 1.4322 - val_accuracy: 0.5494\n",
            "Epoch 95/1300\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.1926 - accuracy: 0.9403 - val_loss: 1.3638 - val_accuracy: 0.5569\n",
            "Epoch 96/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1915 - accuracy: 0.9384 - val_loss: 1.3934 - val_accuracy: 0.5494\n",
            "Epoch 97/1300\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.1914 - accuracy: 0.9403 - val_loss: 1.4401 - val_accuracy: 0.5419\n",
            "Epoch 98/1300\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.1903 - accuracy: 0.9416 - val_loss: 1.2956 - val_accuracy: 0.5704\n",
            "Epoch 99/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1906 - accuracy: 0.9403 - val_loss: 1.3584 - val_accuracy: 0.5629\n",
            "Epoch 100/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1896 - accuracy: 0.9409 - val_loss: 1.4168 - val_accuracy: 0.5539\n",
            "Epoch 101/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1894 - accuracy: 0.9403 - val_loss: 1.4811 - val_accuracy: 0.5389\n",
            "Epoch 102/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1887 - accuracy: 0.9416 - val_loss: 1.4565 - val_accuracy: 0.5464\n",
            "Epoch 103/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1880 - accuracy: 0.9403 - val_loss: 1.4406 - val_accuracy: 0.5509\n",
            "Epoch 104/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1875 - accuracy: 0.9403 - val_loss: 1.4996 - val_accuracy: 0.5419\n",
            "Epoch 105/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1866 - accuracy: 0.9416 - val_loss: 1.5464 - val_accuracy: 0.5329\n",
            "Epoch 106/1300\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.1862 - accuracy: 0.9422 - val_loss: 1.5043 - val_accuracy: 0.5389\n",
            "Epoch 107/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1853 - accuracy: 0.9416 - val_loss: 1.5630 - val_accuracy: 0.5344\n",
            "Epoch 108/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1854 - accuracy: 0.9422 - val_loss: 1.5158 - val_accuracy: 0.5359\n",
            "Epoch 109/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1839 - accuracy: 0.9429 - val_loss: 1.4661 - val_accuracy: 0.5389\n",
            "Epoch 110/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1844 - accuracy: 0.9409 - val_loss: 1.5165 - val_accuracy: 0.5374\n",
            "Epoch 111/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1838 - accuracy: 0.9422 - val_loss: 1.5068 - val_accuracy: 0.5419\n",
            "Epoch 112/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1830 - accuracy: 0.9416 - val_loss: 1.4203 - val_accuracy: 0.5584\n",
            "Epoch 113/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1827 - accuracy: 0.9422 - val_loss: 1.4869 - val_accuracy: 0.5464\n",
            "Epoch 114/1300\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.1820 - accuracy: 0.9435 - val_loss: 1.3799 - val_accuracy: 0.5629\n",
            "Epoch 115/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1819 - accuracy: 0.9416 - val_loss: 1.5113 - val_accuracy: 0.5434\n",
            "Epoch 116/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1808 - accuracy: 0.9422 - val_loss: 1.6299 - val_accuracy: 0.5329\n",
            "Epoch 117/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1811 - accuracy: 0.9429 - val_loss: 1.5620 - val_accuracy: 0.5344\n",
            "Epoch 118/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1802 - accuracy: 0.9429 - val_loss: 1.5480 - val_accuracy: 0.5374\n",
            "Epoch 119/1300\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.1799 - accuracy: 0.9422 - val_loss: 1.5265 - val_accuracy: 0.5389\n",
            "Epoch 120/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1796 - accuracy: 0.9435 - val_loss: 1.5996 - val_accuracy: 0.5314\n",
            "Epoch 121/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1794 - accuracy: 0.9435 - val_loss: 1.6500 - val_accuracy: 0.5299\n",
            "Epoch 122/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1786 - accuracy: 0.9442 - val_loss: 1.5604 - val_accuracy: 0.5374\n",
            "Epoch 123/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1778 - accuracy: 0.9442 - val_loss: 1.7134 - val_accuracy: 0.5299\n",
            "Epoch 124/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1781 - accuracy: 0.9435 - val_loss: 1.5798 - val_accuracy: 0.5374\n",
            "Epoch 125/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1776 - accuracy: 0.9442 - val_loss: 1.6373 - val_accuracy: 0.5344\n",
            "Epoch 126/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1768 - accuracy: 0.9442 - val_loss: 1.6550 - val_accuracy: 0.5344\n",
            "Epoch 127/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1765 - accuracy: 0.9442 - val_loss: 1.5077 - val_accuracy: 0.5434\n",
            "Epoch 128/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1758 - accuracy: 0.9454 - val_loss: 1.5976 - val_accuracy: 0.5389\n",
            "Epoch 129/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1761 - accuracy: 0.9429 - val_loss: 1.5899 - val_accuracy: 0.5419\n",
            "Epoch 130/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1758 - accuracy: 0.9442 - val_loss: 1.7332 - val_accuracy: 0.5284\n",
            "Epoch 131/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1750 - accuracy: 0.9454 - val_loss: 1.5626 - val_accuracy: 0.5434\n",
            "Epoch 132/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1751 - accuracy: 0.9442 - val_loss: 1.6873 - val_accuracy: 0.5314\n",
            "Epoch 133/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1743 - accuracy: 0.9442 - val_loss: 1.6568 - val_accuracy: 0.5359\n",
            "Epoch 134/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1740 - accuracy: 0.9467 - val_loss: 1.5566 - val_accuracy: 0.5464\n",
            "Epoch 135/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1735 - accuracy: 0.9461 - val_loss: 1.6855 - val_accuracy: 0.5314\n",
            "Epoch 136/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1733 - accuracy: 0.9454 - val_loss: 1.6444 - val_accuracy: 0.5359\n",
            "Epoch 137/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1730 - accuracy: 0.9454 - val_loss: 1.5759 - val_accuracy: 0.5449\n",
            "Epoch 138/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1723 - accuracy: 0.9454 - val_loss: 1.6540 - val_accuracy: 0.5404\n",
            "Epoch 139/1300\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.1718 - accuracy: 0.9467 - val_loss: 1.5916 - val_accuracy: 0.5449\n",
            "Epoch 140/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1722 - accuracy: 0.9448 - val_loss: 1.6667 - val_accuracy: 0.5329\n",
            "Epoch 141/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1717 - accuracy: 0.9454 - val_loss: 1.6553 - val_accuracy: 0.5419\n",
            "Epoch 142/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1713 - accuracy: 0.9461 - val_loss: 1.7134 - val_accuracy: 0.5344\n",
            "Epoch 143/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1708 - accuracy: 0.9454 - val_loss: 1.6664 - val_accuracy: 0.5389\n",
            "Epoch 144/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1705 - accuracy: 0.9454 - val_loss: 1.6678 - val_accuracy: 0.5419\n",
            "Epoch 145/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1706 - accuracy: 0.9467 - val_loss: 1.7041 - val_accuracy: 0.5359\n",
            "Epoch 146/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1699 - accuracy: 0.9454 - val_loss: 1.7328 - val_accuracy: 0.5329\n",
            "Epoch 147/1300\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.1692 - accuracy: 0.9480 - val_loss: 1.7723 - val_accuracy: 0.5359\n",
            "Epoch 148/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1691 - accuracy: 0.9461 - val_loss: 1.7833 - val_accuracy: 0.5314\n",
            "Epoch 149/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1680 - accuracy: 0.9474 - val_loss: 1.9548 - val_accuracy: 0.5225\n",
            "Epoch 150/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1684 - accuracy: 0.9467 - val_loss: 1.6373 - val_accuracy: 0.5479\n",
            "Epoch 151/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1682 - accuracy: 0.9461 - val_loss: 1.6864 - val_accuracy: 0.5464\n",
            "Epoch 152/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1681 - accuracy: 0.9467 - val_loss: 1.7366 - val_accuracy: 0.5359\n",
            "Epoch 153/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1675 - accuracy: 0.9448 - val_loss: 1.7246 - val_accuracy: 0.5434\n",
            "Epoch 154/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1664 - accuracy: 0.9467 - val_loss: 1.8881 - val_accuracy: 0.5240\n",
            "Epoch 155/1300\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.1671 - accuracy: 0.9461 - val_loss: 1.8067 - val_accuracy: 0.5329\n",
            "Epoch 156/1300\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.1664 - accuracy: 0.9467 - val_loss: 1.8034 - val_accuracy: 0.5344\n",
            "Epoch 157/1300\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.1660 - accuracy: 0.9474 - val_loss: 1.8041 - val_accuracy: 0.5374\n",
            "Epoch 158/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1653 - accuracy: 0.9461 - val_loss: 1.8431 - val_accuracy: 0.5299\n",
            "Epoch 159/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1659 - accuracy: 0.9474 - val_loss: 1.8705 - val_accuracy: 0.5314\n",
            "Epoch 160/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1651 - accuracy: 0.9467 - val_loss: 1.8112 - val_accuracy: 0.5404\n",
            "Epoch 161/1300\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.1648 - accuracy: 0.9474 - val_loss: 1.8669 - val_accuracy: 0.5344\n",
            "Epoch 162/1300\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.1641 - accuracy: 0.9487 - val_loss: 1.7597 - val_accuracy: 0.5464\n",
            "Epoch 163/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1641 - accuracy: 0.9454 - val_loss: 1.9571 - val_accuracy: 0.5240\n",
            "Epoch 164/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1638 - accuracy: 0.9499 - val_loss: 1.7874 - val_accuracy: 0.5419\n",
            "Epoch 165/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1635 - accuracy: 0.9487 - val_loss: 1.8334 - val_accuracy: 0.5404\n",
            "Epoch 166/1300\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.1622 - accuracy: 0.9480 - val_loss: 1.7312 - val_accuracy: 0.5524\n",
            "Epoch 167/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1621 - accuracy: 0.9467 - val_loss: 1.9313 - val_accuracy: 0.5344\n",
            "Epoch 168/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1618 - accuracy: 0.9487 - val_loss: 1.7112 - val_accuracy: 0.5554\n",
            "Epoch 169/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1623 - accuracy: 0.9474 - val_loss: 1.8498 - val_accuracy: 0.5404\n",
            "Epoch 170/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1609 - accuracy: 0.9499 - val_loss: 1.7505 - val_accuracy: 0.5524\n",
            "Epoch 171/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1608 - accuracy: 0.9474 - val_loss: 1.7865 - val_accuracy: 0.5494\n",
            "Epoch 172/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1607 - accuracy: 0.9493 - val_loss: 1.8988 - val_accuracy: 0.5374\n",
            "Epoch 173/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1601 - accuracy: 0.9474 - val_loss: 1.9044 - val_accuracy: 0.5389\n",
            "Epoch 174/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1599 - accuracy: 0.9487 - val_loss: 1.8354 - val_accuracy: 0.5419\n",
            "Epoch 175/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1602 - accuracy: 0.9480 - val_loss: 2.0356 - val_accuracy: 0.5254\n",
            "Epoch 176/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1598 - accuracy: 0.9493 - val_loss: 1.8578 - val_accuracy: 0.5479\n",
            "Epoch 177/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1592 - accuracy: 0.9499 - val_loss: 1.8498 - val_accuracy: 0.5464\n",
            "Epoch 178/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1584 - accuracy: 0.9499 - val_loss: 1.9747 - val_accuracy: 0.5374\n",
            "Epoch 179/1300\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.1575 - accuracy: 0.9519 - val_loss: 1.7027 - val_accuracy: 0.5629\n",
            "Epoch 180/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1585 - accuracy: 0.9480 - val_loss: 1.8802 - val_accuracy: 0.5464\n",
            "Epoch 181/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1569 - accuracy: 0.9493 - val_loss: 1.9800 - val_accuracy: 0.5419\n",
            "Epoch 182/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1571 - accuracy: 0.9493 - val_loss: 1.8820 - val_accuracy: 0.5494\n",
            "Epoch 183/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1568 - accuracy: 0.9493 - val_loss: 1.7126 - val_accuracy: 0.5674\n",
            "Epoch 184/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1575 - accuracy: 0.9480 - val_loss: 2.0706 - val_accuracy: 0.5314\n",
            "Epoch 185/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1565 - accuracy: 0.9493 - val_loss: 1.8375 - val_accuracy: 0.5494\n",
            "Epoch 186/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1547 - accuracy: 0.9499 - val_loss: 1.8152 - val_accuracy: 0.5554\n",
            "Epoch 187/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1553 - accuracy: 0.9512 - val_loss: 1.9305 - val_accuracy: 0.5479\n",
            "Epoch 188/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1551 - accuracy: 0.9487 - val_loss: 2.0322 - val_accuracy: 0.5419\n",
            "Epoch 189/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1546 - accuracy: 0.9493 - val_loss: 1.9634 - val_accuracy: 0.5479\n",
            "Epoch 190/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1540 - accuracy: 0.9499 - val_loss: 1.9496 - val_accuracy: 0.5524\n",
            "Epoch 191/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1537 - accuracy: 0.9493 - val_loss: 1.9332 - val_accuracy: 0.5479\n",
            "Epoch 192/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1534 - accuracy: 0.9499 - val_loss: 1.9111 - val_accuracy: 0.5509\n",
            "Epoch 193/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1530 - accuracy: 0.9499 - val_loss: 1.9138 - val_accuracy: 0.5524\n",
            "Epoch 194/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1527 - accuracy: 0.9499 - val_loss: 2.0106 - val_accuracy: 0.5479\n",
            "Epoch 195/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1526 - accuracy: 0.9506 - val_loss: 1.9189 - val_accuracy: 0.5509\n",
            "Epoch 196/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1523 - accuracy: 0.9499 - val_loss: 1.8809 - val_accuracy: 0.5569\n",
            "Epoch 197/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1515 - accuracy: 0.9506 - val_loss: 1.9090 - val_accuracy: 0.5569\n",
            "Epoch 198/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1515 - accuracy: 0.9499 - val_loss: 1.9277 - val_accuracy: 0.5539\n",
            "Epoch 199/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1509 - accuracy: 0.9519 - val_loss: 1.9784 - val_accuracy: 0.5479\n",
            "Epoch 200/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1499 - accuracy: 0.9519 - val_loss: 1.8608 - val_accuracy: 0.5614\n",
            "Epoch 201/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1514 - accuracy: 0.9512 - val_loss: 1.9583 - val_accuracy: 0.5539\n",
            "Epoch 202/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1490 - accuracy: 0.9512 - val_loss: 2.0975 - val_accuracy: 0.5419\n",
            "Epoch 203/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1502 - accuracy: 0.9538 - val_loss: 2.0320 - val_accuracy: 0.5434\n",
            "Epoch 204/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1488 - accuracy: 0.9525 - val_loss: 1.9907 - val_accuracy: 0.5509\n",
            "Epoch 205/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1492 - accuracy: 0.9512 - val_loss: 2.1705 - val_accuracy: 0.5329\n",
            "Epoch 206/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1487 - accuracy: 0.9525 - val_loss: 2.0150 - val_accuracy: 0.5524\n",
            "Epoch 207/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1472 - accuracy: 0.9538 - val_loss: 2.1867 - val_accuracy: 0.5374\n",
            "Epoch 208/1300\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9519 - val_loss: 2.0097 - val_accuracy: 0.5554\n",
            "Epoch 209/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1479 - accuracy: 0.9525 - val_loss: 2.0427 - val_accuracy: 0.5494\n",
            "Epoch 210/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1473 - accuracy: 0.9531 - val_loss: 2.0484 - val_accuracy: 0.5539\n",
            "Epoch 211/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1459 - accuracy: 0.9512 - val_loss: 1.9293 - val_accuracy: 0.5599\n",
            "Epoch 212/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1457 - accuracy: 0.9551 - val_loss: 2.1217 - val_accuracy: 0.5449\n",
            "Epoch 213/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1460 - accuracy: 0.9525 - val_loss: 2.1440 - val_accuracy: 0.5419\n",
            "Epoch 214/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1461 - accuracy: 0.9557 - val_loss: 2.2399 - val_accuracy: 0.5344\n",
            "Epoch 215/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1492 - accuracy: 0.9525 - val_loss: 2.1139 - val_accuracy: 0.5464\n",
            "Epoch 216/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1464 - accuracy: 0.9538 - val_loss: 2.0537 - val_accuracy: 0.5494\n",
            "Epoch 217/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1452 - accuracy: 0.9544 - val_loss: 2.1336 - val_accuracy: 0.5464\n",
            "Epoch 218/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1440 - accuracy: 0.9551 - val_loss: 1.9308 - val_accuracy: 0.5599\n",
            "Epoch 219/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1450 - accuracy: 0.9551 - val_loss: 2.0747 - val_accuracy: 0.5494\n",
            "Epoch 220/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1441 - accuracy: 0.9576 - val_loss: 2.0685 - val_accuracy: 0.5554\n",
            "Epoch 221/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1436 - accuracy: 0.9557 - val_loss: 2.0741 - val_accuracy: 0.5584\n",
            "Epoch 222/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1435 - accuracy: 0.9538 - val_loss: 2.2211 - val_accuracy: 0.5419\n",
            "Epoch 223/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1440 - accuracy: 0.9570 - val_loss: 2.1669 - val_accuracy: 0.5479\n",
            "Epoch 224/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1428 - accuracy: 0.9576 - val_loss: 2.0667 - val_accuracy: 0.5539\n",
            "Epoch 225/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1427 - accuracy: 0.9551 - val_loss: 2.0187 - val_accuracy: 0.5644\n",
            "Epoch 226/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1433 - accuracy: 0.9576 - val_loss: 2.1643 - val_accuracy: 0.5524\n",
            "Epoch 227/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1420 - accuracy: 0.9557 - val_loss: 2.2281 - val_accuracy: 0.5479\n",
            "Epoch 228/1300\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.1429 - accuracy: 0.9576 - val_loss: 2.1729 - val_accuracy: 0.5479\n",
            "Epoch 229/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1415 - accuracy: 0.9570 - val_loss: 2.2973 - val_accuracy: 0.5404\n",
            "Epoch 230/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1414 - accuracy: 0.9570 - val_loss: 2.1755 - val_accuracy: 0.5464\n",
            "Epoch 231/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1410 - accuracy: 0.9564 - val_loss: 2.2035 - val_accuracy: 0.5494\n",
            "Epoch 232/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1414 - accuracy: 0.9564 - val_loss: 2.3194 - val_accuracy: 0.5419\n",
            "Epoch 233/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1416 - accuracy: 0.9551 - val_loss: 2.1074 - val_accuracy: 0.5554\n",
            "Epoch 234/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1399 - accuracy: 0.9576 - val_loss: 2.2212 - val_accuracy: 0.5479\n",
            "Epoch 235/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1398 - accuracy: 0.9583 - val_loss: 2.3001 - val_accuracy: 0.5434\n",
            "Epoch 236/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1396 - accuracy: 0.9576 - val_loss: 2.2844 - val_accuracy: 0.5479\n",
            "Epoch 237/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1387 - accuracy: 0.9583 - val_loss: 1.8990 - val_accuracy: 0.5823\n",
            "Epoch 238/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1403 - accuracy: 0.9564 - val_loss: 2.2171 - val_accuracy: 0.5494\n",
            "Epoch 239/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1392 - accuracy: 0.9557 - val_loss: 2.0921 - val_accuracy: 0.5629\n",
            "Epoch 240/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1390 - accuracy: 0.9570 - val_loss: 1.9779 - val_accuracy: 0.5793\n",
            "Epoch 241/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1390 - accuracy: 0.9570 - val_loss: 2.1227 - val_accuracy: 0.5614\n",
            "Epoch 242/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1386 - accuracy: 0.9583 - val_loss: 2.0706 - val_accuracy: 0.5674\n",
            "Epoch 243/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1384 - accuracy: 0.9583 - val_loss: 2.1742 - val_accuracy: 0.5584\n",
            "Epoch 244/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1379 - accuracy: 0.9564 - val_loss: 2.3270 - val_accuracy: 0.5449\n",
            "Epoch 245/1300\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.1376 - accuracy: 0.9583 - val_loss: 2.2228 - val_accuracy: 0.5539\n",
            "Epoch 246/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1388 - accuracy: 0.9583 - val_loss: 2.3678 - val_accuracy: 0.5464\n",
            "Epoch 247/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1379 - accuracy: 0.9583 - val_loss: 2.1583 - val_accuracy: 0.5614\n",
            "Epoch 248/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1379 - accuracy: 0.9570 - val_loss: 2.1602 - val_accuracy: 0.5599\n",
            "Epoch 249/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1367 - accuracy: 0.9583 - val_loss: 2.2935 - val_accuracy: 0.5524\n",
            "Epoch 250/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1359 - accuracy: 0.9583 - val_loss: 2.3186 - val_accuracy: 0.5494\n",
            "Epoch 251/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1364 - accuracy: 0.9596 - val_loss: 2.1993 - val_accuracy: 0.5584\n",
            "Epoch 252/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1342 - accuracy: 0.9564 - val_loss: 2.1165 - val_accuracy: 0.5644\n",
            "Epoch 253/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1365 - accuracy: 0.9570 - val_loss: 2.2522 - val_accuracy: 0.5599\n",
            "Epoch 254/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1366 - accuracy: 0.9576 - val_loss: 2.2353 - val_accuracy: 0.5569\n",
            "Epoch 255/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1359 - accuracy: 0.9583 - val_loss: 2.1506 - val_accuracy: 0.5689\n",
            "Epoch 256/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1357 - accuracy: 0.9589 - val_loss: 2.2357 - val_accuracy: 0.5614\n",
            "Epoch 257/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1351 - accuracy: 0.9583 - val_loss: 2.2428 - val_accuracy: 0.5569\n",
            "Epoch 258/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1355 - accuracy: 0.9570 - val_loss: 2.2694 - val_accuracy: 0.5569\n",
            "Epoch 259/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1349 - accuracy: 0.9589 - val_loss: 2.4450 - val_accuracy: 0.5419\n",
            "Epoch 260/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1341 - accuracy: 0.9583 - val_loss: 2.2527 - val_accuracy: 0.5674\n",
            "Epoch 261/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1342 - accuracy: 0.9589 - val_loss: 2.0869 - val_accuracy: 0.5763\n",
            "Epoch 262/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1336 - accuracy: 0.9583 - val_loss: 2.3995 - val_accuracy: 0.5509\n",
            "Epoch 263/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1335 - accuracy: 0.9589 - val_loss: 2.3551 - val_accuracy: 0.5584\n",
            "Epoch 264/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1345 - accuracy: 0.9576 - val_loss: 2.2840 - val_accuracy: 0.5659\n",
            "Epoch 265/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1339 - accuracy: 0.9576 - val_loss: 2.2018 - val_accuracy: 0.5734\n",
            "Epoch 266/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1336 - accuracy: 0.9596 - val_loss: 2.0826 - val_accuracy: 0.5823\n",
            "Epoch 267/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1334 - accuracy: 0.9602 - val_loss: 2.2104 - val_accuracy: 0.5719\n",
            "Epoch 268/1300\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.1331 - accuracy: 0.9576 - val_loss: 2.3798 - val_accuracy: 0.5599\n",
            "Epoch 269/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1322 - accuracy: 0.9602 - val_loss: 2.1531 - val_accuracy: 0.5808\n",
            "Epoch 270/1300\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.1322 - accuracy: 0.9596 - val_loss: 2.3900 - val_accuracy: 0.5629\n",
            "Epoch 271/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1325 - accuracy: 0.9589 - val_loss: 2.4651 - val_accuracy: 0.5614\n",
            "Epoch 272/1300\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.1335 - accuracy: 0.9583 - val_loss: 2.3138 - val_accuracy: 0.5659\n",
            "Epoch 273/1300\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.1314 - accuracy: 0.9596 - val_loss: 2.3191 - val_accuracy: 0.5644\n",
            "Epoch 274/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1317 - accuracy: 0.9576 - val_loss: 2.3648 - val_accuracy: 0.5659\n",
            "Epoch 275/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1317 - accuracy: 0.9589 - val_loss: 2.3988 - val_accuracy: 0.5584\n",
            "Epoch 276/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1316 - accuracy: 0.9596 - val_loss: 2.2844 - val_accuracy: 0.5719\n",
            "Epoch 277/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1311 - accuracy: 0.9589 - val_loss: 2.5004 - val_accuracy: 0.5524\n",
            "Epoch 278/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1312 - accuracy: 0.9596 - val_loss: 2.2763 - val_accuracy: 0.5719\n",
            "Epoch 279/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1303 - accuracy: 0.9602 - val_loss: 2.5117 - val_accuracy: 0.5569\n",
            "Epoch 280/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1300 - accuracy: 0.9596 - val_loss: 2.4545 - val_accuracy: 0.5599\n",
            "Epoch 281/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1297 - accuracy: 0.9602 - val_loss: 2.3759 - val_accuracy: 0.5644\n",
            "Epoch 282/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1301 - accuracy: 0.9602 - val_loss: 2.3851 - val_accuracy: 0.5674\n",
            "Epoch 283/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1302 - accuracy: 0.9589 - val_loss: 2.3463 - val_accuracy: 0.5719\n",
            "Epoch 284/1300\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.1304 - accuracy: 0.9602 - val_loss: 2.4125 - val_accuracy: 0.5674\n",
            "Epoch 285/1300\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.1297 - accuracy: 0.9602 - val_loss: 2.4745 - val_accuracy: 0.5644\n",
            "Epoch 286/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1291 - accuracy: 0.9589 - val_loss: 2.4953 - val_accuracy: 0.5614\n",
            "Epoch 287/1300\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.1286 - accuracy: 0.9602 - val_loss: 2.4378 - val_accuracy: 0.5644\n",
            "Epoch 288/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1286 - accuracy: 0.9608 - val_loss: 2.5786 - val_accuracy: 0.5554\n",
            "Epoch 289/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1281 - accuracy: 0.9596 - val_loss: 2.4188 - val_accuracy: 0.5659\n",
            "Epoch 290/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1288 - accuracy: 0.9602 - val_loss: 2.4038 - val_accuracy: 0.5704\n",
            "Epoch 291/1300\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.1285 - accuracy: 0.9608 - val_loss: 2.4026 - val_accuracy: 0.5719\n",
            "Epoch 292/1300\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.1271 - accuracy: 0.9596 - val_loss: 2.4404 - val_accuracy: 0.5629\n",
            "Epoch 293/1300\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.1289 - accuracy: 0.9615 - val_loss: 2.3998 - val_accuracy: 0.5719\n",
            "Epoch 294/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1279 - accuracy: 0.9621 - val_loss: 2.2784 - val_accuracy: 0.5793\n",
            "Epoch 295/1300\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.1281 - accuracy: 0.9596 - val_loss: 2.4638 - val_accuracy: 0.5734\n",
            "Epoch 296/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1274 - accuracy: 0.9602 - val_loss: 2.4751 - val_accuracy: 0.5599\n",
            "Epoch 297/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1274 - accuracy: 0.9602 - val_loss: 2.4434 - val_accuracy: 0.5659\n",
            "Epoch 298/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1267 - accuracy: 0.9608 - val_loss: 2.3597 - val_accuracy: 0.5749\n",
            "Epoch 299/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1262 - accuracy: 0.9602 - val_loss: 2.3159 - val_accuracy: 0.5749\n",
            "Epoch 300/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1270 - accuracy: 0.9615 - val_loss: 2.5816 - val_accuracy: 0.5614\n",
            "Epoch 301/1300\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.1252 - accuracy: 0.9621 - val_loss: 2.3607 - val_accuracy: 0.5778\n",
            "Epoch 302/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1250 - accuracy: 0.9615 - val_loss: 2.5258 - val_accuracy: 0.5659\n",
            "Epoch 303/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1264 - accuracy: 0.9608 - val_loss: 2.3485 - val_accuracy: 0.5778\n",
            "Epoch 304/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1258 - accuracy: 0.9615 - val_loss: 2.4845 - val_accuracy: 0.5719\n",
            "Epoch 305/1300\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.1251 - accuracy: 0.9608 - val_loss: 2.5707 - val_accuracy: 0.5629\n",
            "Epoch 306/1300\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.1239 - accuracy: 0.9608 - val_loss: 2.7708 - val_accuracy: 0.5524\n",
            "Epoch 307/1300\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.1253 - accuracy: 0.9615 - val_loss: 2.4194 - val_accuracy: 0.5749\n",
            "Epoch 308/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1249 - accuracy: 0.9621 - val_loss: 2.4786 - val_accuracy: 0.5719\n",
            "Epoch 309/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1243 - accuracy: 0.9628 - val_loss: 2.4078 - val_accuracy: 0.5778\n",
            "Epoch 310/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1243 - accuracy: 0.9634 - val_loss: 2.5707 - val_accuracy: 0.5644\n",
            "Epoch 311/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1248 - accuracy: 0.9615 - val_loss: 2.6169 - val_accuracy: 0.5614\n",
            "Epoch 312/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1233 - accuracy: 0.9628 - val_loss: 2.4389 - val_accuracy: 0.5763\n",
            "Epoch 313/1300\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.1253 - accuracy: 0.9602 - val_loss: 2.5250 - val_accuracy: 0.5689\n",
            "Epoch 314/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1242 - accuracy: 0.9615 - val_loss: 2.6165 - val_accuracy: 0.5629\n",
            "Epoch 315/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1257 - accuracy: 0.9596 - val_loss: 2.4598 - val_accuracy: 0.5778\n",
            "Epoch 316/1300\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.1228 - accuracy: 0.9634 - val_loss: 2.6006 - val_accuracy: 0.5674\n",
            "Epoch 317/1300\n",
            "68/98 [===================>..........] - ETA: 0s - loss: 0.1186 - accuracy: 0.9651"
          ]
        }
      ]
    }
  ]
}