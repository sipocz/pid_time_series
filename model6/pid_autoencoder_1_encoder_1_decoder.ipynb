{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sipocz/pid_time_series/blob/main/model6/pid_autoencoder_1_encoder_1_decoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0tNYnFR-6Xh",
        "outputId": "4fe5b4cb-1a38-4379-cbae-e0925ebbe337"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.13.7-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from wandb) (57.4.0)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 63.9 MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from wandb) (6.0)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.3)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.12.1-py2.py3-none-any.whl (174 kB)\n",
            "\u001b[K     |████████████████████████████████| 174 kB 60.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.15.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.6 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.12.0-py2.py3-none-any.whl (173 kB)\n",
            "\u001b[K     |████████████████████████████████| 173 kB 64.9 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.11.1-py2.py3-none-any.whl (168 kB)\n",
            "\u001b[K     |████████████████████████████████| 168 kB 62.1 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.11.0-py2.py3-none-any.whl (168 kB)\n",
            "\u001b[K     |████████████████████████████████| 168 kB 63.3 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.10.1-py2.py3-none-any.whl (166 kB)\n",
            "\u001b[K     |████████████████████████████████| 166 kB 61.7 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.10.0-py2.py3-none-any.whl (166 kB)\n",
            "\u001b[K     |████████████████████████████████| 166 kB 61.4 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.10-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 53.3 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.9-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 63.9 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.8-py2.py3-none-any.whl (158 kB)\n",
            "\u001b[K     |████████████████████████████████| 158 kB 64.5 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.7-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 62.0 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.6-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 54.8 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 63.6 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 66.7 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 52.5 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 85.0 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 73.6 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 46.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=3c6789b5b57ca3dbd3cb22392c73bf57d012981912cfe28aff559ccac95fa69b\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.29 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.11 smmap-5.0.0 wandb-0.13.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OWFIUUUGKGdA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import seaborn as sns\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ag6zIuPmKTux"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coqJiGk7KW_4",
        "outputId": "d4f8dcc5-fc6a-4ce7-901d-e64722d9e946"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-_usNw7yKZDt"
      },
      "outputs": [],
      "source": [
        "#user = \"Anna\"\n",
        "user = \"SL\"\n",
        "uzem = \"Szint1\"\n",
        "data_source=\"5\"\n",
        "#fname=\"72C03_TC_error_toNN.csv\"\n",
        "fname_good = \"415_SC_error_part1.csv\"\n",
        "fname_bad = \"415_SC_error_part2.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OkO7F6NaKbxi"
      },
      "outputs": [],
      "source": [
        "# Elérési út a 415_SC_error-hoz\n",
        "if user==\"Anna\":\n",
        "    path_good = \"/content/drive/MyDrive/Egyetem_MSc/Diplomamunka/2022Anna/Datapipeline/\" + data_source + \"/\" + fname_good\n",
        "    path_bad = \"/content/drive/MyDrive/Egyetem_MSc/Diplomamunka/2022Anna/Datapipeline/\" + data_source + \"/\" + fname_bad\n",
        "    path_fig = \"/content/drive/MyDrive/Egyetem_MSc/Diplomamunka/2022Anna/Datapipeline/plots/\"\n",
        "else:\n",
        "    path_good = \"/content/drive/MyDrive/2022Anna/Datapipeline/\" + data_source + \"/\" + fname_good\n",
        "    path_bad = \"/content/drive/MyDrive/2022Anna/Datapipeline/\" + data_source + \"/\" + fname_bad\n",
        "    path_fig = \"/content/drive/MyDrive/2022Anna/Datapipeline/plots/\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5ZDDiY9KfAQ",
        "outputId": "a1448e5b-e999-40ec-db02-6663144c77bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/2022Anna/Datapipeline/5/415_SC_error_part1.csv\n",
            "/content/drive/MyDrive/2022Anna/Datapipeline/5/415_SC_error_part2.csv\n"
          ]
        }
      ],
      "source": [
        "print(path_good)\n",
        "print(path_bad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vUcMjZAGKvtt"
      },
      "outputs": [],
      "source": [
        "df_good = pd.read_csv(path_good,usecols=None)\n",
        "df_bad = pd.read_csv(path_bad,usecols=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYuDXKraLOt4",
        "outputId": "505ebefc-5aaa-46f1-b3d9-55a982bd8213"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "print(df_good.isnull().values.any())\n",
        "print(df_bad.isnull().values.any())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "vzl5zIO1LUoq",
        "outputId": "8a738e1b-fa5c-4413-9327-0f4b0941e57b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0          1          2          3          4        5         6  \\\n",
              "0 -54.810024 -80.342186 -60.770203 -41.081482 -21.779583 -3.82353 -0.806820   \n",
              "1 -80.342186 -60.770203 -41.081482 -21.779583  -3.823530 -0.80682  0.220875   \n",
              "\n",
              "          7         8         9        10        11        12        13  \\\n",
              "0  0.220875  0.220875  0.220875  0.220875  0.220875  0.220875  0.220875   \n",
              "1  0.220875  0.220875  0.220875  0.220875  0.220875  0.220875  0.220875   \n",
              "\n",
              "         14        15        16        17        18        19  \n",
              "0  0.220875  0.220875  0.220875  0.220875  0.220875  0.220875  \n",
              "1  0.220875  0.220875  0.220875  0.220875  0.220875  0.220875  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-45303828-0ca8-41e1-897f-ff823c6a9489\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-54.810024</td>\n",
              "      <td>-80.342186</td>\n",
              "      <td>-60.770203</td>\n",
              "      <td>-41.081482</td>\n",
              "      <td>-21.779583</td>\n",
              "      <td>-3.82353</td>\n",
              "      <td>-0.806820</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-80.342186</td>\n",
              "      <td>-60.770203</td>\n",
              "      <td>-41.081482</td>\n",
              "      <td>-21.779583</td>\n",
              "      <td>-3.823530</td>\n",
              "      <td>-0.80682</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "      <td>0.220875</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45303828-0ca8-41e1-897f-ff823c6a9489')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-45303828-0ca8-41e1-897f-ff823c6a9489 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-45303828-0ca8-41e1-897f-ff823c6a9489');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df_good.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "f0xJfadFMOfA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "hIMQw2sULmj9"
      },
      "outputs": [],
      "source": [
        "\n",
        "import matplotlib.pyplot as plot\n",
        "\n",
        "\n",
        "\n",
        "df_ = df_good\n",
        "\n",
        "# You must normalize the data before applying the fit method\n",
        "df_good_normalized=(df_ - df_.mean()) / df_.std()\n",
        "\n",
        "# Normalize bad data with the good data parameters\n",
        "df_bad_normalized=(df_bad - df_.mean()) / df_.std()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "df_all=pd.concat([df_good,df_bad],axis=0)\n",
        "scaler=MinMaxScaler()\n",
        "scaler.fit(df_all)\n",
        "good_scaled=scaler.transform(df_good)\n",
        "bad_scaled=scaler.transform(df_bad)\n"
      ],
      "metadata": {
        "id": "ibrdNyqsspbR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XxLD8g1htekl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_good_scaled=pd.DataFrame(good_scaled,columns=df_all.columns)\n",
        "df_bad_scaled=pd.DataFrame(bad_scaled,columns=df_all.columns)\n",
        "df_good_scaled[\"state\"]=0\n",
        "df_bad_scaled[\"state\"]=1"
      ],
      "metadata": {
        "id": "9FdSgm_ztqjZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wknFhIRBNQ7k"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "3W5mi70VM6hL",
        "outputId": "4e952033-2107-44ea-a3a6-dbfacd591793"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             0         1         2         3         4         5         6  \\\n",
              "0     0.203312  0.000000  0.000000  0.149256  0.339488  0.516456  0.546188   \n",
              "1     0.000000  0.155851  0.185726  0.339488  0.516456  0.546188  0.556316   \n",
              "2     0.155851  0.312632  0.367803  0.516456  0.546188  0.556316  0.556316   \n",
              "3     0.312632  0.466332  0.537185  0.546188  0.556316  0.556316  0.556316   \n",
              "4     0.466332  0.609315  0.565642  0.556316  0.556316  0.556316  0.556316   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "1053  0.641521  0.641521  0.575337  0.556316  0.556316  0.556316  0.556316   \n",
              "1054  0.641521  0.641521  0.575337  0.556316  0.556316  0.556316  0.556316   \n",
              "1055  0.641521  0.641521  0.575337  0.556316  0.556316  0.556316  0.556316   \n",
              "1056  0.641521  0.641521  0.575337  0.556316  0.556316  0.556316  0.556316   \n",
              "1057  0.641521  0.641521  0.575337  0.556316  0.556316  0.556316  0.556316   \n",
              "\n",
              "             7         8         9  ...        11        12        13  \\\n",
              "0     0.556316  0.556316  0.556316  ...  0.556316  0.556316  0.556316   \n",
              "1     0.556316  0.556316  0.556316  ...  0.556316  0.556316  0.556316   \n",
              "2     0.556316  0.556316  0.556316  ...  0.556316  0.556316  0.556316   \n",
              "3     0.556316  0.556316  0.556316  ...  0.556316  0.556316  0.556316   \n",
              "4     0.556316  0.556316  0.556316  ...  0.556316  0.556316  0.556316   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "1053  0.556316  0.556316  0.556316  ...  0.556316  0.556316  0.556316   \n",
              "1054  0.556316  0.556316  0.556316  ...  0.556316  0.556316  0.556316   \n",
              "1055  0.556316  0.556316  0.556316  ...  0.556316  0.556316  0.556316   \n",
              "1056  0.556316  0.556316  0.556316  ...  0.556316  0.556316  0.556316   \n",
              "1057  0.556316  0.556316  0.556316  ...  0.556316  0.556316  0.556316   \n",
              "\n",
              "            14        15        16        17        18        19  state  \n",
              "0     0.556316  0.556316  0.556316  0.556316  0.556316  0.556316      0  \n",
              "1     0.556316  0.556316  0.556316  0.556316  0.556316  0.556316      0  \n",
              "2     0.556316  0.556316  0.556316  0.556316  0.556316  0.556316      0  \n",
              "3     0.556316  0.556316  0.556316  0.556316  0.556316  0.556316      0  \n",
              "4     0.556316  0.556316  0.556316  0.556316  0.556316  0.556316      0  \n",
              "...        ...       ...       ...       ...       ...       ...    ...  \n",
              "1053  0.556316  0.556316  0.556316  0.556316  0.556316  0.556316      0  \n",
              "1054  0.556316  0.556316  0.556316  0.556316  0.556316  0.556316      0  \n",
              "1055  0.556316  0.556316  0.556316  0.556316  0.556316  0.556316      0  \n",
              "1056  0.556316  0.556316  0.556316  0.556316  0.556316  0.556316      0  \n",
              "1057  0.556316  0.556316  0.556316  0.556316  0.556316  0.556316      0  \n",
              "\n",
              "[1058 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c7c34185-26bb-4395-921b-18d42748c02f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.203312</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.149256</td>\n",
              "      <td>0.339488</td>\n",
              "      <td>0.516456</td>\n",
              "      <td>0.546188</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>...</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.155851</td>\n",
              "      <td>0.185726</td>\n",
              "      <td>0.339488</td>\n",
              "      <td>0.516456</td>\n",
              "      <td>0.546188</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>...</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.155851</td>\n",
              "      <td>0.312632</td>\n",
              "      <td>0.367803</td>\n",
              "      <td>0.516456</td>\n",
              "      <td>0.546188</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>...</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.312632</td>\n",
              "      <td>0.466332</td>\n",
              "      <td>0.537185</td>\n",
              "      <td>0.546188</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>...</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.466332</td>\n",
              "      <td>0.609315</td>\n",
              "      <td>0.565642</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>...</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1053</th>\n",
              "      <td>0.641521</td>\n",
              "      <td>0.641521</td>\n",
              "      <td>0.575337</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>...</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1054</th>\n",
              "      <td>0.641521</td>\n",
              "      <td>0.641521</td>\n",
              "      <td>0.575337</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>...</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1055</th>\n",
              "      <td>0.641521</td>\n",
              "      <td>0.641521</td>\n",
              "      <td>0.575337</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>...</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1056</th>\n",
              "      <td>0.641521</td>\n",
              "      <td>0.641521</td>\n",
              "      <td>0.575337</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>...</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1057</th>\n",
              "      <td>0.641521</td>\n",
              "      <td>0.641521</td>\n",
              "      <td>0.575337</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>...</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0.556316</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1058 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7c34185-26bb-4395-921b-18d42748c02f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c7c34185-26bb-4395-921b-18d42748c02f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c7c34185-26bb-4395-921b-18d42748c02f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "df_good_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9nY0OMtYPT8J"
      },
      "outputs": [],
      "source": [
        "df_all_scaled=pd.concat([df_good_scaled,df_bad_scaled],axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "ClfUnwBRPwgK",
        "outputId": "966a8ccc-4e56-43d8-d10c-6e51af6406f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             0         1         2         3         4         5         6  \\\n",
              "1263  0.641184  0.641184  0.574937  0.555899  0.555899  0.555899  0.555899   \n",
              "1264  0.641184  0.641184  0.574937  0.555899  0.555899  0.555899  0.555899   \n",
              "1265  0.641184  0.641184  0.574937  0.555899  0.555899  0.555899  0.555899   \n",
              "1266  0.641184  0.641184  0.574937  0.555899  0.555899  0.555899  0.555899   \n",
              "1267  0.641184  0.641184  0.574937  0.555899  0.555899  0.555899  0.555899   \n",
              "\n",
              "             7         8         9  ...        11        12        13  \\\n",
              "1263  0.555899  0.555899  0.555899  ...  0.555899  0.555899  0.555899   \n",
              "1264  0.555899  0.555899  0.555899  ...  0.555899  0.555899  0.555899   \n",
              "1265  0.555899  0.555899  0.555899  ...  0.555899  0.555899  0.555899   \n",
              "1266  0.555899  0.555899  0.555899  ...  0.555899  0.555899  0.555899   \n",
              "1267  0.555899  0.555899  0.555899  ...  0.555899  0.555899  0.555899   \n",
              "\n",
              "            14        15        16        17        18        19  state  \n",
              "1263  0.555899  0.555899  0.555899  0.555899  0.555899  0.555899      1  \n",
              "1264  0.555899  0.555899  0.555899  0.555899  0.555899  0.555899      1  \n",
              "1265  0.555899  0.555899  0.555899  0.555899  0.555899  0.555899      1  \n",
              "1266  0.555899  0.555899  0.555899  0.555899  0.555899  0.555899      1  \n",
              "1267  0.555899  0.555899  0.555899  0.555899  0.555899  0.555899      1  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-127b35eb-d171-42fb-add1-c6ea55d7f608\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1263</th>\n",
              "      <td>0.641184</td>\n",
              "      <td>0.641184</td>\n",
              "      <td>0.574937</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>...</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1264</th>\n",
              "      <td>0.641184</td>\n",
              "      <td>0.641184</td>\n",
              "      <td>0.574937</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>...</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1265</th>\n",
              "      <td>0.641184</td>\n",
              "      <td>0.641184</td>\n",
              "      <td>0.574937</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>...</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1266</th>\n",
              "      <td>0.641184</td>\n",
              "      <td>0.641184</td>\n",
              "      <td>0.574937</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>...</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1267</th>\n",
              "      <td>0.641184</td>\n",
              "      <td>0.641184</td>\n",
              "      <td>0.574937</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>...</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>0.555899</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-127b35eb-d171-42fb-add1-c6ea55d7f608')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-127b35eb-d171-42fb-add1-c6ea55d7f608 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-127b35eb-d171-42fb-add1-c6ea55d7f608');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "df_all_scaled.tail()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n"
      ],
      "metadata": {
        "id": "nVvhP84S_F1y"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "7 dimenzióra képez, a grafikus megjelenítés biztató\n",
        "_N1_=135\n",
        "_N2_=30\n",
        "_N3_=7\n",
        "_lr_=0.0001\n",
        "_batch_size_=32\n",
        "_drop1_=0.0\n",
        "_drop2_=0.0\n",
        "_epochs_=3500\n",
        "'''\n",
        "\n",
        "'''\n",
        "_N1_=135\n",
        "_N2_=30\n",
        "_N3_=2\n",
        "_lr_=0.0001\n",
        "_batch_size_=32\n",
        "_drop1_=0.0\n",
        "_drop2_=0.0\n",
        "_epochs_=3500\n",
        "'''\n",
        "_N1_=13\n",
        "_N2_=6\n",
        "_N3_=2\n",
        "_N4_=2\n",
        "_lr_=0.0001\n",
        "_batch_size_=32\n",
        "_drop1_=0.0\n",
        "_drop2_=0.0\n",
        "_epochs_=3500\n",
        "_comment_=\"2 réteg input: 13 encoded 2\"\n",
        "\n"
      ],
      "metadata": {
        "id": "XC5_bGE0iyi4"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"lr\": _lr_, \"batch_size\": _batch_size_,\"architecture\": \"AutoencoderNN\", \n",
        "          \"depth\": 2,\n",
        "          \"layer1\":_N1_,  \"layer2\":_N2_,\"layer3\":_N3_,\"layer4\":_N2_,\"layer5\":_N1_,\"layer_out\":20, \n",
        "          \"drop1\":_drop1_,\"drop2\":_drop2_,\n",
        "          \"epochs\":_epochs_,\n",
        "          \"comment\": _comment_\n",
        "\n",
        "          \n",
        "          \n",
        "          }\n",
        "\n",
        "wandb.init(project=\"pid_autoencoder\", entity=\"pid_status\",config=config)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461,
          "referenced_widgets": [
            "3a8d680614944e95984728a70e5b46f2",
            "a6eea2d0e7ba4948a42d4edbd705b63c",
            "8cea66204b0d495bacb9124341fbc10b",
            "9776370480df49c4a1d9738e1fc56795",
            "3c7adc8514634114b36f81b2a508185b",
            "ae419c74223e4de086eccb300edcfece",
            "726c3e51b435451abbc29be39807af3b",
            "e57670f1da264245b75ffd1cb7ae9e9f"
          ]
        },
        "id": "nOtKllcviuoj",
        "outputId": "cd5ea01c-3aac-4b98-c86f-b6ef5c8d0c0e"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:2punf352) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.099 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.005652…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a8d680614944e95984728a70e5b46f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/MAE</td><td>██▇▇▆▆▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇▇█▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▆▇▇██</td></tr><tr><td>epoch/learning_rate</td><td>██████▄▄▄▄▄▄▁▁▁▁▁▁▁▁▁▁▁███▄▄▄▄▄▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>██▇▇▆▆▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/lr</td><td>██████▄▄▄▄▄▄▁▁▁▁▁▁▁▁▁▁▁███▄▄▄▄▄▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/MAE</td><td>0.02052</td></tr><tr><td>epoch/epoch</td><td>3499</td></tr><tr><td>epoch/learning_rate</td><td>1e-05</td></tr><tr><td>epoch/loss</td><td>0.02052</td></tr><tr><td>epoch/lr</td><td>1e-05</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">sparkling-music-82</strong>: <a href=\"https://wandb.ai/sipoczlaszlo/pid_autoencoder/runs/2punf352\" target=\"_blank\">https://wandb.ai/sipoczlaszlo/pid_autoencoder/runs/2punf352</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20221221_085828-2punf352/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:2punf352). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221221_093713-1y17rqzp</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/pid_status/pid_autoencoder/runs/1y17rqzp\" target=\"_blank\">true-moon-1</a></strong> to <a href=\"https://wandb.ai/pid_status/pid_autoencoder\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/pid_status/pid_autoencoder/runs/1y17rqzp?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fbc36023fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "rcPrX4lWP2R_"
      },
      "outputs": [],
      "source": [
        "from keras.engine.base_layer import regularizers\n",
        "from keras.layers import InputLayer, Dense, LSTM, Input, Dropout\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import SGD,Adam,Adamax,Nadam,Ftrl,Adadelta\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from keras.backend import clear_session\n",
        "from tensorflow.keras.losses import mean_absolute_percentage_error, huber,kld\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "clear_session()\n",
        "\n",
        "kernel_reg_1=tf.keras.regularizers.L2(0.1)\n",
        "\n",
        "input_size=20\n",
        "\n",
        "\n",
        "input1=Input(shape=(input_size,))\n",
        "l1_out=Dense(_N1_,activation=\"relu\",kernel_initializer='glorot_uniform',kernel_regularizer=None)(input1) # kernel_initializer='lecun_normal'  # L1\n",
        "\n",
        "#l2_out=Dropout(_drop1_)(l1_out)\n",
        "\n",
        "#l3_out=Dense(_N2_,activation=\"relu\",kernel_initializer='glorot_uniform',kernel_regularizer=None)(l2_out) #kernel_initializer='lecun_normal',  # L2\n",
        "#l4_out=Dropout(_drop2_)(l3_out)\n",
        "\n",
        "l5_out=Dense(_N3_,activation=\"linear\",kernel_initializer='glorot_uniform',name=\"encoded\",kernel_regularizer=None)(l1_out) #kernel_initializer='lecun_normal',  # L3\n",
        "\n",
        "#l7_out=Dense(_N2_,activation=\"relu\",kernel_initializer='glorot_uniform',kernel_regularizer=None)(l5_out) #kernel_initializer='lecun_normal',  # L4\n",
        "\n",
        "l9_out=Dense(_N1_,activation=\"relu\",kernel_initializer='glorot_uniform',kernel_regularizer=None)(l5_out) #kernel_initializer='lecun_normal',  # L5\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "pred=Dense(input_size, activation=\"sigmoid\",)(l9_out)\n",
        "\n",
        "model = Model(inputs=input1, outputs=pred)\n",
        "optimizer=Adamax(learning_rate=_lr_,) #\n",
        "\n",
        "model.compile(loss='MAE',\n",
        "    optimizer=optimizer,\n",
        "    metrics=[\"MAE\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "yLzRRMnbIk9X"
      },
      "outputs": [],
      "source": [
        "# autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "RGIztQ3tQ3ni"
      },
      "outputs": [],
      "source": [
        "prediktorok=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\"]\n",
        "X_NN=df_all_scaled[prediktorok][:]  # \n",
        "y_NN=df_all_scaled[\"state\"][:]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_file=\"model_PID__54_loss_0.116_vloss_0.115_acc_0.953_vacc_0.958.hdf5\"\n",
        "#model_file=\"model_PID__94_loss_0.116_vloss_0.115_acc_0.950_vacc_0.966.hdf5\"\n",
        "model_file=\"model_PID__4491_loss_0.115_vloss_0.679_acc_0.954_vacc_0.880.hdf5\""
      ],
      "metadata": {
        "id": "DgjVCU185nNO"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_url=\"https://github.com/sipocz/pid_time_series/raw/main/model3/\"+model_file"
      ],
      "metadata": {
        "id": "iUhe0_4L5ufk"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "__load_file__=False"
      ],
      "metadata": {
        "id": "UIxI3AS6Yw3S"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __load_file__:\n",
        "    ! rm *.hdf5 \n",
        "    ! wget $model_url\n",
        "    model.load_weights(model_file)"
      ],
      "metadata": {
        "id": "ZNjx5XGesZPO"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "rdH49nLKRVoh"
      },
      "outputs": [],
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(X_NN,y_NN,train_size=len(X_NN)-1,shuffle=True,random_state=33)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_NN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Xru7s5BsOD3",
        "outputId": "037a1437-aaa3-4703-d7f1-ac8f636bf757"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2326"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm *.hdf5 "
      ],
      "metadata": {
        "id": "jJfOOTfGfDXi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72a9ce3b-aa8c-4e7e-f9c1-67b84bf04c19"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '*.hdf5': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def learning_rate_corrector(epoch,lr):\n",
        "    \n",
        "    if epoch > 4000:\n",
        "        lr = 0.000005\n",
        "        return lr\n",
        "    if epoch > 2000:\n",
        "        lr = 0.00001\n",
        "        return lr\n",
        "    if epoch > 1000:\n",
        "        lr = 0.00005\n",
        "        return lr\n",
        "    \n",
        "    if epoch > 500:\n",
        "        lr = 0.0001\n",
        "        return lr\n",
        "    return lr\n",
        "    "
      ],
      "metadata": {
        "id": "A-Kv8ORiEfub"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wandb.keras import WandbMetricsLogger\n",
        "fname=\"./model_Encoder_\"\n",
        "callbacks = [\n",
        "        LearningRateScheduler(learning_rate_corrector,verbose=1),\n",
        "        WandbMetricsLogger(),       \n",
        "        #ModelCheckpoint(filepath=fname+\"_{epoch:04.0f}\"+\"_loss_{loss:.3f}_vloss_{val_loss:.3f}_acc_{MAE:.3f}_vacc_{val_MAE:.3f}.hdf5\", \n",
        "        #                monitor='loss', verbose=2, save_best_only=True, mode='min')\n",
        "        ]\n"
      ],
      "metadata": {
        "id": "RNfi--Kfo4HM"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "__learning__=True"
      ],
      "metadata": {
        "id": "O6ofy0moderd"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "7Z3Z4q14D7eC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51c73889-1747-455e-d3c2-967219b9b154"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 20)]              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 13)                273       \n",
            "                                                                 \n",
            " encoded (Dense)             (None, 2)                 28        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 13)                39        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 20)                280       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620\n",
            "Trainable params: 620\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {
        "id": "9Ol0mW6WRlkS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7afd787d-a821-4e33-e6bf-a6b4ccb0f51b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mA streamkimeneten csak az utolsó 5000 sor látható.\u001b[0m\n",
            "Epoch 2251: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2251/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2252: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2252/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2253: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2253/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2254: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2254/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2255: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2255/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2256: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2256/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2257: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2257/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2258: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2258/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2259: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2259/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2260: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2260/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2261: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2261/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2262: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2262/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2263: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2263/3500\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2264: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2264/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2265: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2265/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2266: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2266/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2267: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2267/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2268: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2268/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2269: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2269/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2270: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2270/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2271: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2271/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2272: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2272/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2273: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2273/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2274: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2274/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2275: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2275/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2276: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2276/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2277: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2277/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2278: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2278/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2279: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2279/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2280: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2280/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2281: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2281/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2282: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2282/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2283: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2283/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2284: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2284/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2285: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2285/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2286: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2286/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2287: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2287/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2288: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2288/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2289: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2289/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2290: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2290/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2291: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2291/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2292: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2292/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2293: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2293/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2294: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2294/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2295: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2295/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2296: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2296/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2297: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2297/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2298: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2298/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2299: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2299/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2300: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2300/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2301: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2301/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2302: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2302/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2303: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2303/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2304: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2304/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2305: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2305/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2306: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2306/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2307: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2307/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2308: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2308/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2309: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2309/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2310: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2310/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2311: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2311/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2312: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2312/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2313: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2313/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2314: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2314/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2315: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2315/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2316: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2316/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2317: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2317/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2318: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2318/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2319: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2319/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2320: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2320/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2321: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2321/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2322: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2322/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2323: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2323/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2324: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2324/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2325: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2325/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2326: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2326/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2327: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2327/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2328: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2328/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2329: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2329/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2330: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2330/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2331: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2331/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2332: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2332/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2333: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2333/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2334: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2334/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2335: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2335/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2336: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2336/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2337: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2337/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2338: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2338/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2339: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2339/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2340: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2340/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2341: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2341/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2342: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2342/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2343: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2343/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2344: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2344/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2345: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2345/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2346: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2346/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2347: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2347/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2348: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2348/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2349: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2349/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2350: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2350/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2351: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2351/3500\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2352: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2352/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2353: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2353/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2354: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2354/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2355: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2355/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2356: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2356/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2357: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2357/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2358: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2358/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2359: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2359/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2360: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2360/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2361: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2361/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2362: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2362/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2363: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2363/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2364: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2364/3500\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2365: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2365/3500\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2366: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2366/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2367: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2367/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2368: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2368/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2369: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2369/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2370: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2370/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2371: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2371/3500\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2372: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2372/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2373: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2373/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2374: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2374/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2375: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2375/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2376: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2376/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2377: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2377/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2378: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2378/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2379: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2379/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2380: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2380/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2381: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2381/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2382: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2382/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2383: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2383/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2384: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2384/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2385: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2385/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2386: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2386/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2387: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2387/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2388: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2388/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2389: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2389/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2390: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2390/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2391: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2391/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2392: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2392/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2393: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2393/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2394: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2394/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2395: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2395/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2396: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2396/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2397: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2397/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2398: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2398/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2399: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2399/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2400: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2400/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2401: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2401/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2402: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2402/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2403: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2403/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2404: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2404/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2405: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2405/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2406: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2406/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2407: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2407/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2408: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2408/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2409: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2409/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2410: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2410/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2411: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2411/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2412: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2412/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2413: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2413/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2414: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2414/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2415: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2415/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2416: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2416/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2417: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2417/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2418: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2418/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2419: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2419/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2420: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2420/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2421: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2421/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2422: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2422/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2423: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2423/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2424: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2424/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2425: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2425/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2426: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2426/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2427: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2427/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2428: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2428/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2429: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2429/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2430: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2430/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2431: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2431/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2432: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2432/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2433: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2433/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2434: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2434/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2435: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2435/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2436: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2436/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2437: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2437/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2438: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2438/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2439: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2439/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2440: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2440/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2441: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2441/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2442: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2442/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2443: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2443/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2444: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2444/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2445: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2445/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2446: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2446/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2447: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2447/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2448: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2448/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2449: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2449/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2450: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2450/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2451: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2451/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2452: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2452/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2453: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2453/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2454: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2454/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2455: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2455/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2456: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2456/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2457: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2457/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2458: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2458/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2459: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2459/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2460: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2460/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2461: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2461/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2462: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2462/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2463: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2463/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2464: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2464/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2465: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2465/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2466: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2466/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2467: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2467/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2468: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2468/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2469: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2469/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2470: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2470/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2471: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2471/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2472: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2472/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2473: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2473/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2474: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2474/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2475: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2475/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2476: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2476/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2477: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2477/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2478: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2478/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2479: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2479/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2480: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2480/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2481: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2481/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2482: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2482/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2483: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2483/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2484: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2484/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2485: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2485/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2486: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2486/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2487: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2487/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2488: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2488/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2489: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2489/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2490: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2490/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2491: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2491/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2492: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2492/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2493: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2493/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2494: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2494/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2495: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2495/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2496: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2496/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2497: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2497/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2498: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2498/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2499: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2499/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2500: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2500/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2501: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2501/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2502: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2502/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2503: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2503/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2504: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2504/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2505: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2505/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2506: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2506/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2507: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2507/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2508: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2508/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2509: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2509/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2510: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2510/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2511: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2511/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2512: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2512/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2513: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2513/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2514: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2514/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2515: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2515/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2516: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2516/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2517: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2517/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2518: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2518/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2519: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2519/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2520: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2520/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2521: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2521/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2522: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2522/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2523: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2523/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2524: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2524/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2525: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2525/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2526: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2526/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2527: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2527/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2528: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2528/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2529: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2529/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2530: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2530/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2531: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2531/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2532: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2532/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2533: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2533/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2534: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2534/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2535: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2535/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2536: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2536/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2537: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2537/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2538: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2538/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2539: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2539/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2540: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2540/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2541: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2541/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2542: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2542/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2543: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2543/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2544: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2544/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2545: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2545/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2546: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2546/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2547: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2547/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2548: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2548/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2549: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2549/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2550: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2550/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2551: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2551/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2552: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2552/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2553: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2553/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2554: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2554/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2555: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2555/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2556: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2556/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2557: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2557/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2558: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2558/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2559: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2559/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2560: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2560/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2561: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2561/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2562: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2562/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2563: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2563/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2564: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2564/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2565: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2565/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2566: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2566/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2567: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2567/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2568: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2568/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2569: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2569/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2570: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2570/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2571: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2571/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2572: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2572/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2573: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2573/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2574: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2574/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2575: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2575/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2576: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2576/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2577: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2577/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2578: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2578/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2579: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2579/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2580: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2580/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2581: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2581/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2582: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2582/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2583: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2583/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2584: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2584/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2585: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2585/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2586: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2586/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2587: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2587/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2588: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2588/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2589: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2589/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2590: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2590/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2591: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2591/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2592: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2592/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2593: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2593/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2594: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2594/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2595: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2595/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2596: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2596/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2597: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2597/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2598: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2598/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2599: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2599/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2600: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2600/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2601: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2601/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2602: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2602/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2603: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2603/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2604: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2604/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2605: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2605/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2606: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2606/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2607: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2607/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2608: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2608/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2609: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2609/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2610: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2610/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2611: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2611/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2612: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2612/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2613: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2613/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2614: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2614/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2615: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2615/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2616: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2616/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2617: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2617/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2618: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2618/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2619: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2619/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2620: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2620/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2621: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2621/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2622: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2622/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2623: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2623/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2624: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2624/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2625: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2625/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2626: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2626/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2627: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2627/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2628: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2628/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2629: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2629/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2630: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2630/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2631: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2631/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2632: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2632/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2633: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2633/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2634: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2634/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2635: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2635/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2636: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2636/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2637: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2637/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2638: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2638/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2639: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2639/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2640: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2640/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2641: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2641/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2642: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2642/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2643: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2643/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2644: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2644/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2645: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2645/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2646: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2646/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2647: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2647/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2648: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2648/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2649: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2649/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2650: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2650/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2651: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2651/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2652: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2652/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2653: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2653/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2654: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2654/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2655: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2655/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2656: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2656/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2657: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2657/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2658: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2658/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2659: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2659/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2660: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2660/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2661: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2661/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2662: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2662/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2663: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2663/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2664: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2664/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2665: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2665/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2666: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2666/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2667: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2667/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2668: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2668/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2669: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2669/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2670: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2670/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2671: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2671/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2672: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2672/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2673: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2673/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2674: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2674/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2675: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2675/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2676: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2676/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2677: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2677/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2678: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2678/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2679: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2679/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2680: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2680/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2681: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2681/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2682: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2682/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2683: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2683/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2684: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2684/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2685: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2685/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2686: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2686/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2687: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2687/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2688: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2688/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2689: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2689/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2690: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2690/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2691: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2691/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2692: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2692/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2693: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2693/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2694: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2694/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2695: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2695/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2696: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2696/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2697: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2697/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2698: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2698/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2699: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2699/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2700: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2700/3500\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2701: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2701/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2702: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2702/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2703: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2703/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2704: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2704/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2705: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2705/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2706: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2706/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2707: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2707/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2708: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2708/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2709: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2709/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2710: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2710/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2711: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2711/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2712: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2712/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2713: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2713/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2714: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2714/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2715: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2715/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2716: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2716/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2717: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2717/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2718: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2718/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2719: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2719/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2720: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2720/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2721: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2721/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2722: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2722/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2723: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2723/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2724: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2724/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2725: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2725/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2726: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2726/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2727: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2727/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2728: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2728/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2729: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2729/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2730: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2730/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2731: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2731/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2732: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2732/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2733: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2733/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2734: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2734/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2735: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2735/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2736: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2736/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2737: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2737/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2738: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2738/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2739: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2739/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2740: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2740/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2741: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2741/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2742: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2742/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2743: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2743/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2744: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2744/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2745: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2745/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2746: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2746/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2747: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2747/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2748: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2748/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2749: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2749/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2750: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2750/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2751: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2751/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2752: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2752/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2753: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2753/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2754: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2754/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2755: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2755/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2756: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2756/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2757: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2757/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2758: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2758/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2759: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2759/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2760: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2760/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2761: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2761/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2762: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2762/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2763: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2763/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2764: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2764/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2765: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2765/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2766: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2766/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2767: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2767/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2768: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2768/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2769: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2769/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2770: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2770/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2771: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2771/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2772: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2772/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2773: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2773/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2774: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2774/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2775: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2775/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2776: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2776/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2777: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2777/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2778: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2778/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2779: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2779/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2780: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2780/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2781: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2781/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2782: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2782/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2783: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2783/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2784: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2784/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2785: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2785/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2786: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2786/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2787: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2787/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2788: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2788/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2789: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2789/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2790: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2790/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2791: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2791/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2792: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2792/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2793: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2793/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2794: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2794/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2795: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2795/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2796: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2796/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2797: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2797/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2798: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2798/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2799: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2799/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2800: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2800/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2801: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2801/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2802: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2802/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2803: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2803/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2804: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2804/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2805: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2805/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2806: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2806/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2807: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2807/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2808: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2808/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2809: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2809/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2810: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2810/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2811: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2811/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2812: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2812/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2813: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2813/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2814: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2814/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2815: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2815/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2816: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2816/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2817: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2817/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2818: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2818/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2819: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2819/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2820: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2820/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2821: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2821/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2822: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2822/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2823: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2823/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2824: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2824/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2825: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2825/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2826: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2826/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2827: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2827/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2828: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2828/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2829: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2829/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2830: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2830/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2831: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2831/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2832: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2832/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2833: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2833/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2834: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2834/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2835: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2835/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2836: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2836/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2837: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2837/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2838: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2838/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2839: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2839/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2840: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2840/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2841: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2841/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2842: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2842/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2843: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2843/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2844: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2844/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2845: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2845/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2846: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2846/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2847: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2847/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2848: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2848/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2849: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2849/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2850: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2850/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2851: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2851/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2852: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2852/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2853: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2853/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2854: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2854/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2855: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2855/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2856: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2856/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2857: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2857/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2858: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2858/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2859: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2859/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2860: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2860/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2861: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2861/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2862: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2862/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2863: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2863/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2864: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2864/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2865: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2865/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2866: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2866/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2867: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2867/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2868: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2868/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2869: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2869/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2870: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2870/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2871: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2871/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2872: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2872/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2873: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2873/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2874: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2874/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2875: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2875/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2876: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2876/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2877: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2877/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2878: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2878/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2879: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2879/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2880: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2880/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2881: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2881/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2882: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2882/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2883: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2883/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2884: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2884/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2885: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2885/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2886: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2886/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2887: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2887/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2888: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2888/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2889: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2889/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2890: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2890/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2891: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2891/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2892: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2892/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2893: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2893/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2894: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2894/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2895: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2895/3500\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2896: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2896/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2897: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2897/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2898: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2898/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2899: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2899/3500\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2900: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2900/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2901: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2901/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2902: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2902/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2903: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2903/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2904: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2904/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2905: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2905/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2906: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2906/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2907: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2907/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2908: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2908/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2909: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2909/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2910: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2910/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2911: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2911/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2912: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2912/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2913: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2913/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2914: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2914/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2915: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2915/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2916: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2916/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2917: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2917/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2918: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2918/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2919: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2919/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2920: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2920/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2921: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2921/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2922: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2922/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2923: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2923/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2924: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2924/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2925: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2925/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2926: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2926/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2927: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2927/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2928: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2928/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2929: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2929/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2930: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2930/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2931: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2931/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2932: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2932/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2933: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2933/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2934: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2934/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2935: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2935/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2936: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2936/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2937: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2937/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2938: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2938/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2939: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2939/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2940: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2940/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2941: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2941/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2942: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2942/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2943: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2943/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2944: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2944/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2945: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2945/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2946: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2946/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2947: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2947/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2948: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2948/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2949: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2949/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2950: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2950/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2951: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2951/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2952: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2952/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2953: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2953/3500\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2954: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2954/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2955: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2955/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2956: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2956/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2957: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2957/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2958: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2958/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2959: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2959/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2960: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2960/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2961: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2961/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2962: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2962/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2963: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2963/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2964: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2964/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2965: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2965/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2966: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2966/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2967: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2967/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2968: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2968/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2969: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2969/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2970: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2970/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2971: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2971/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2972: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2972/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2973: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2973/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2974: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2974/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2975: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2975/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2976: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2976/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2977: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2977/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2978: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2978/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2979: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2979/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2980: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2980/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2981: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2981/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2982: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2982/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2983: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2983/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2984: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2984/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2985: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2985/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2986: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2986/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2987: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2987/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2988: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2988/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2989: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2989/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2990: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2990/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2991: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2991/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2992: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2992/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2993: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2993/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2994: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2994/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2995: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2995/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2996: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2996/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2997: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2997/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2998: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2998/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 2999: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 2999/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3000: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3000/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3001: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3001/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3002: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3002/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3003: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3003/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3004: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3004/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3005: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3005/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3006: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3006/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3007: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3007/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3008: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3008/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3009: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3009/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3010: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3010/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3011: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3011/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3012: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3012/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3013: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3013/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3014: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3014/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3015: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3015/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3016: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3016/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3017: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3017/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3018: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3018/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3019: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3019/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3020: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3020/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3021: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3021/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3022: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3022/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3023: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3023/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3024: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3024/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3025: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3025/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3026: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3026/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3027: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3027/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3028: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3028/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3029: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3029/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3030: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3030/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3031: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3031/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3032: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3032/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3033: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3033/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3034: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3034/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3035: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3035/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3036: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3036/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3037: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3037/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3038: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3038/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3039: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3039/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3040: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3040/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3041: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3041/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3042: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3042/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3043: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3043/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3044: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3044/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3045: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3045/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3046: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3046/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3047: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3047/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3048: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3048/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3049: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3049/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3050: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3050/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3051: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3051/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3052: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3052/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3053: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3053/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3054: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3054/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3055: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3055/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3056: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3056/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3057: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3057/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3058: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3058/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3059: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3059/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3060: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3060/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3061: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3061/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3062: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3062/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3063: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3063/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3064: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3064/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3065: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3065/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3066: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3066/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3067: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3067/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3068: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3068/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3069: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3069/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3070: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3070/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3071: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3071/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3072: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3072/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3073: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3073/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3074: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3074/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3075: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3075/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3076: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3076/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3077: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3077/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3078: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3078/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3079: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3079/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3080: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3080/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3081: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3081/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3082: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3082/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3083: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3083/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3084: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3084/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3085: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3085/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3086: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3086/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3087: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3087/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3088: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3088/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3089: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3089/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3090: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3090/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3091: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3091/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3092: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3092/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3093: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3093/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3094: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3094/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3095: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3095/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3096: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3096/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3097: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3097/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3098: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3098/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3099: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3099/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3100: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3100/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3101: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3101/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3102: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3102/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3103: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3103/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3104: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3104/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3105: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3105/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3106: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3106/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3107: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3107/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3108: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3108/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3109: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3109/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3110: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3110/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3111: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3111/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3112: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3112/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3113: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3113/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3114: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3114/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3115: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3115/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3116: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3116/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3117: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3117/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3118: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3118/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3119: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3119/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3120: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3120/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3121: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3121/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3122: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3122/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3123: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3123/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3124: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3124/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3125: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3125/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3126: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3126/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3127: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3127/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3128: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3128/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3129: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3129/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3130: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3130/3500\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3131: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3131/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3132: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3132/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3133: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3133/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3134: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3134/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3135: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3135/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3136: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3136/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3137: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3137/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3138: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3138/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3139: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3139/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3140: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3140/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3141: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3141/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3142: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3142/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3143: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3143/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3144: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3144/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3145: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3145/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3146: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3146/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3147: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3147/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3148: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3148/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3149: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3149/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3150: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3150/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3151: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3151/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3152: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3152/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3153: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3153/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3154: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3154/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3155: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3155/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3156: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3156/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3157: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3157/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3158: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3158/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3159: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3159/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3160: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3160/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3161: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3161/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3162: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3162/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3163: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3163/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3164: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3164/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3165: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3165/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3166: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3166/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3167: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3167/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3168: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3168/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3169: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3169/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3170: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3170/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3171: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3171/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3172: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3172/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3173: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3173/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3174: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3174/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3175: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3175/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3176: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3176/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3177: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3177/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3178: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3178/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3179: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3179/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3180: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3180/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3181: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3181/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3182: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3182/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3183: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3183/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3184: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3184/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3185: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3185/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3186: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3186/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3187: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3187/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3188: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3188/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3189: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3189/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3190: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3190/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3191: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3191/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3192: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3192/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3193: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3193/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3194: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3194/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3195: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3195/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3196: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3196/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3197: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3197/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3198: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3198/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3199: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3199/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3200: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3200/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3201: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3201/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3202: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3202/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3203: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3203/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3204: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3204/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3205: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3205/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3206: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3206/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3207: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3207/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3208: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3208/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3209: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3209/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3210: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3210/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3211: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3211/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3212: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3212/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3213: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3213/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3214: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3214/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3215: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3215/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3216: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3216/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3217: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3217/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3218: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3218/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3219: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3219/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3220: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3220/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3221: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3221/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3222: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3222/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3223: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3223/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3224: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3224/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3225: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3225/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3226: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3226/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3227: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3227/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3228: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3228/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3229: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3229/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3230: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3230/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3231: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3231/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3232: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3232/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3233: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3233/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3234: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3234/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3235: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3235/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3236: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3236/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3237: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3237/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3238: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3238/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3239: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3239/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3240: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3240/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3241: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3241/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3242: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3242/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3243: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3243/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3244: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3244/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3245: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3245/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3246: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3246/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3247: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3247/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3248: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3248/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3249: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3249/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3250: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3250/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3251: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3251/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3252: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3252/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3253: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3253/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3254: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3254/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3255: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3255/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3256: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3256/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3257: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3257/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3258: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3258/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3259: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3259/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3260: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3260/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3261: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3261/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3262: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3262/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3263: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3263/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3264: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3264/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3265: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3265/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3266: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3266/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3267: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3267/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3268: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3268/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3269: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3269/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3270: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3270/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3271: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3271/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3272: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3272/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3273: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3273/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3274: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3274/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3275: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3275/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3276: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3276/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3277: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3277/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3278: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3278/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3279: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3279/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3280: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3280/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3281: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3281/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3282: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3282/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3283: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3283/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3284: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3284/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3285: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3285/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3286: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3286/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3287: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3287/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3288: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3288/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3289: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3289/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3290: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3290/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3291: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3291/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3292: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3292/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3293: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3293/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3294: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3294/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3295: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3295/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3296: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3296/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3297: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3297/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3298: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3298/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3299: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3299/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3300: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3300/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3301: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3301/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3302: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3302/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3303: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3303/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3304: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3304/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3305: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3305/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3306: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3306/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3307: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3307/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3308: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3308/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3309: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3309/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3310: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3310/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3311: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3311/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3312: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3312/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3313: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3313/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3314: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3314/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3315: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3315/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3316: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3316/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3317: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3317/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3318: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3318/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3319: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3319/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3320: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3320/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3321: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3321/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3322: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3322/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3323: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3323/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3324: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3324/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3325: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3325/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3326: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3326/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3327: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3327/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3328: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3328/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3329: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3329/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3330: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3330/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3331: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3331/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3332: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3332/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3333: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3333/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3334: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3334/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3335: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3335/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3336: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3336/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3337: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3337/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3338: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3338/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3339: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3339/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3340: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3340/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3341: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3341/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3342: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3342/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3343: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3343/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3344: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3344/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3345: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3345/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3346: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3346/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3347: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3347/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3348: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3348/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3349: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3349/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3350: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3350/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3351: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3351/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3352: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3352/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3353: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3353/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3354: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3354/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3355: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3355/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3356: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3356/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3357: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3357/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3358: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3358/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3359: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3359/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3360: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3360/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3361: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3361/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3362: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3362/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3363: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3363/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3364: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3364/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3365: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3365/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3366: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3366/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3367: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3367/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3368: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3368/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3369: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3369/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3370: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3370/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3371: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3371/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3372: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3372/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3373: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3373/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3374: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3374/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3375: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3375/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3376: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3376/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3377: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3377/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3378: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3378/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3379: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3379/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3380: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3380/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3381: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3381/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3382: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3382/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3383: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3383/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3384: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3384/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3385: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3385/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3386: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3386/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3387: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3387/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3388: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3388/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3389: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3389/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3390: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3390/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3391: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3391/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3392: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3392/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3393: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3393/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3394: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3394/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3395: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3395/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3396: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3396/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3397: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3397/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3398: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3398/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3399: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3399/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3400: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3400/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3401: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3401/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3402: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3402/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3403: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3403/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3404: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3404/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3405: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3405/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3406: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3406/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3407: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3407/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3408: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3408/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3409: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3409/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3410: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3410/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3411: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3411/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3412: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3412/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3413: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3413/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3414: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3414/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3415: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3415/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3416: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3416/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3417: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3417/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3418: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3418/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3419: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3419/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3420: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3420/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3421: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3421/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3422: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3422/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3423: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3423/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3424: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3424/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3425: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3425/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3426: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3426/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3427: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3427/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3428: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3428/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3429: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3429/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3430: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3430/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3431: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3431/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3432: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3432/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3433: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3433/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3434: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3434/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3435: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3435/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3436: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3436/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3437: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3437/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3438: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3438/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3439: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3439/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3440: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3440/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3441: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3441/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3442: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3442/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3443: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3443/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3444: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3444/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3445: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3445/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3446: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3446/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3447: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3447/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3448: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3448/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3449: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3449/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3450: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3450/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3451: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3451/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3452: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3452/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3453: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3453/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3454: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3454/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3455: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3455/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3456: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3456/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3457: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3457/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3458: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3458/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3459: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3459/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3460: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3460/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3461: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3461/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3462: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3462/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3463: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3463/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3464: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3464/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3465: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3465/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3466: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3466/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3467: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3467/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3468: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3468/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3469: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3469/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3470: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3470/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3471: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3471/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3472: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3472/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3473: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3473/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3474: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3474/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3475: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3475/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3476: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3476/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3477: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3477/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3478: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3478/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3479: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3479/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3480: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3480/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3481: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3481/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3482: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3482/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3483: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3483/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3484: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3484/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3485: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3485/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3486: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3486/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3487: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3487/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3488: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3488/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3489: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3489/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3490: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3490/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3491: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3491/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3492: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3492/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3493: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3493/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3494: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3494/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3495: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3495/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3496: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3496/3500\n",
            "73/73 [==============================] - 0s 4ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3497: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3497/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3498: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3498/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3499: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3499/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 3500: LearningRateScheduler setting learning rate to 1e-05.\n",
            "Epoch 3500/3500\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 0.0195 - MAE: 0.0195 - lr: 1.0000e-05\n"
          ]
        }
      ],
      "source": [
        "if __learning__: \n",
        "    history = model.fit(X_train, X_train, epochs=_epochs_, batch_size=_batch_size_, verbose=1,callbacks=callbacks)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"autoencoder_model_1_encoder.hdf5\")"
      ],
      "metadata": {
        "id": "EkZ9T-NH513_"
      },
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "__load_file__=False\n",
        "model_file=\"model_PID__0634_loss_0.086_vloss_1.253_acc_0.961_vacc_0.886.hdf5\"\n",
        "model_url=\"https://github.com/sipocz/pid_time_series/raw/main/model3/\"+model_file"
      ],
      "metadata": {
        "id": "EGg1PjCJDTKF"
      },
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __load_file__:\n",
        "    ! rm *.hdf5 \n",
        "    ! wget $model_url\n",
        "    model.load_weights(model_file)"
      ],
      "metadata": {
        "id": "JgzklVywoNmk"
      },
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwcWQ94IpDFu",
        "outputId": "82cd001a-84b0-4875-c206-3b5bdfe16b2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 31ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred=model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_display_object_visualization.html#sphx-glr-auto-examples-miscellaneous-plot-display-object-visualization-py"
      ],
      "metadata": {
        "id": "H0c0Fkd2cWRj"
      },
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import Binarizer\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "zctwrl1AcTZ0"
      },
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JlHV6_j9wUiE"
      },
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i1=model.get_layer(\"dense\")"
      ],
      "metadata": {
        "id": "rLxI7wmUDgID"
      },
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "o1=model.get_layer(\"encoded\")"
      ],
      "metadata": {
        "id": "zeveHSkCDoma"
      },
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "to3v7cxmD60p"
      },
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_states_fun = K.function([i1.input],[o1.output])\n",
        "     "
      ],
      "metadata": {
        "id": "4798J_V2D9QW"
      },
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding(X):\n",
        "    \"\"\"Return the hidden state associated with an input at the given timestep.\n",
        "    \"\"\"\n",
        "    \n",
        "    hidden_states = hidden_states_fun(X.to_numpy())[0]\n",
        "    \n",
        "    return hidden_states\n",
        "     "
      ],
      "metadata": {
        "id": "4e-T3C50EG_a"
      },
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_embedding(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSdDesJpqcEn",
        "outputId": "83a374c7-e81e-46cc-fe15-0bdda9d6f805"
      },
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.6912386 , 0.19157873],\n",
              "       [1.6591666 , 0.6339333 ],\n",
              "       [1.4813614 , 0.28614214],\n",
              "       ...,\n",
              "       [1.491081  , 0.2793443 ],\n",
              "       [1.4921093 , 0.27955684],\n",
              "       [1.492724  , 0.28105608]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hs=hidden_states_fun(X_train.to_numpy())[0]"
      ],
      "metadata": {
        "id": "WHyjbcplufFm"
      },
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(hs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sIYdxIqrmdO",
        "outputId": "e0818b78-79c3-4caf-a070-e6069d57fda8"
      },
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2325"
            ]
          },
          "metadata": {},
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hs[3].tolist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flhNv2Thq5jP",
        "outputId": "2dcd0607-a942-4997-ca2e-ba986e4f2a16"
      },
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4902584552764893, 0.2791745364665985]"
            ]
          },
          "metadata": {},
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.iloc[1:2,:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "OkaLjsUxEi6_",
        "outputId": "53357d93-428d-45aa-b93a-ade46e85b9c6"
      },
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0         1         2         3         4        5        6  \\\n",
              "197  0.745236  0.736633  0.669679  0.675073  0.666591  0.65811  0.68836   \n",
              "\n",
              "            7         8         9        10        11        12        13  \\\n",
              "197  0.659147  0.647462  0.596853  0.613648  0.635157  0.586837  0.428412   \n",
              "\n",
              "           14        15        16       17        18        19  \n",
              "197  0.429968  0.350293  0.655865  0.55388  0.427329  0.359316  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ebafa14d-8035-424a-8d09-748ce0808a23\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>0.745236</td>\n",
              "      <td>0.736633</td>\n",
              "      <td>0.669679</td>\n",
              "      <td>0.675073</td>\n",
              "      <td>0.666591</td>\n",
              "      <td>0.65811</td>\n",
              "      <td>0.68836</td>\n",
              "      <td>0.659147</td>\n",
              "      <td>0.647462</td>\n",
              "      <td>0.596853</td>\n",
              "      <td>0.613648</td>\n",
              "      <td>0.635157</td>\n",
              "      <td>0.586837</td>\n",
              "      <td>0.428412</td>\n",
              "      <td>0.429968</td>\n",
              "      <td>0.350293</td>\n",
              "      <td>0.655865</td>\n",
              "      <td>0.55388</td>\n",
              "      <td>0.427329</td>\n",
              "      <td>0.359316</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ebafa14d-8035-424a-8d09-748ce0808a23')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ebafa14d-8035-424a-8d09-748ce0808a23 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ebafa14d-8035-424a-8d09-748ce0808a23');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_list=get_embedding(X_train)"
      ],
      "metadata": {
        "id": "Tnh4GKWNERZF"
      },
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embedding_list)"
      ],
      "metadata": {
        "id": "hxZwDiKYhA5H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4f765d3-272d-4b22-b19a-a0deee9375d2"
      },
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2325"
            ]
          },
          "metadata": {},
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "id": "eCqcqNJl79G5"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z69kCq3T-pMo"
      },
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "id": "nZ0rmkNsBGnl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sNIc1l6vF6Y4"
      },
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def color_changer(arr):\n",
        "    o=[\"r\" if i>0.5 else \"g\" for i in arr]\n",
        "    return o"
      ],
      "metadata": {
        "id": "YFJoZO8TG1ED"
      },
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JtghT29KKGA4"
      },
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_list[:][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H96EO2p_LE3u",
        "outputId": "d9adf588-f9e9-466c-8d8b-c0b93c595581"
      },
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.6912386 , 0.19157873], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_list[:][-100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e82a7m3sJxZi",
        "outputId": "babdef33-c2ed-4b44-eb43-08003e6a626b"
      },
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.6477594 , 0.37281916], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 261
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_embedding(list_in, predicted):\n",
        "    xkoordinata=[i[0] for i in list_in]\n",
        "    ykoordinata=[i[1] for i in list_in]\n",
        "    \n",
        "    plot.figure(figsize=(12,6))\n",
        "    col_ch=color_changer(predicted)\n",
        "    plot.scatter(xkoordinata,ykoordinata,c=col_ch,marker=\".\",alpha=0.3)\n",
        "    plot.ylabel('értékek')\n",
        "    plot.xlabel('index')\n",
        "    plot\n",
        "    plot.show()"
      ],
      "metadata": {
        "id": "YMHy-wbZGeqq"
      },
      "execution_count": 262,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HuL1OutGHHEc"
      },
      "execution_count": 262,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4aXpzheKE7bM"
      },
      "execution_count": 262,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "70M96KLSdCHW"
      },
      "execution_count": 262,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e72-bHKzdZve"
      },
      "execution_count": 262,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_list[0:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1t90K4auzlY",
        "outputId": "3fb9c248-085f-48a4-957b-2f02205271d0"
      },
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.6912386 , 0.19157873],\n",
              "       [1.6591666 , 0.6339333 ],\n",
              "       [1.4813614 , 0.28614214],\n",
              "       ...,\n",
              "       [1.491081  , 0.2793443 ],\n",
              "       [1.4921093 , 0.27955684],\n",
              "       [1.492724  , 0.28105608]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_embedding(embedding_list[:],y_train[:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "BO3xdrHVGXhL",
        "outputId": "d1279806-5d16-4a63-86aa-538b4eb77830"
      },
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WMRd5eGU9ASA"
      },
      "execution_count": 264,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grafikon3(fx,desc1,txt1,desc2=\"\",txt2=\"\",desc3=\"\",txt3=\"\",ngraf=2,c1='rgba(35,128,132,0.8)', c2='rgba(193,99,99,0.8)',c3='rgba(193,99,99,0.8)',title=None):\n",
        "    '''\n",
        "    fx: dataFrame\n",
        "    desc1:column1\n",
        "    txt1: label1\n",
        "    desc2:column2\n",
        "    txt2: label2\n",
        "    ngraf: number of graph\n",
        "    c1: color1\n",
        "    c2: color2\n",
        "    title: graph title\n",
        "    '''\n",
        "    \n",
        "    #x_=[i for i in range(len(y_pred))]\n",
        "    if title==None:\n",
        "      title=txt1+\" \"+txt2\n",
        "    import plotly.express as px\n",
        "    import plotly.graph_objects as go\n",
        "    from plotly.subplots import make_subplots\n",
        "    fig0 = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
        "\n",
        "\n",
        "    if ngraf>=3:\n",
        "        fig0.add_trace(\n",
        "            go.Bar(x=fx.index, y=fx[desc3], marker_color='rgba(225, 20, 20,0.2)',  name=txt3, showlegend=True, ),\n",
        "              secondary_y=False,\n",
        "            #row=1, col=1\n",
        "        )\n",
        "\n",
        "\n",
        "    if ngraf>=2:\n",
        "        fig0.add_trace(\n",
        "            go.Scatter(x=fx.index, y=fx[desc2], name=txt2, line=dict(color=c2) ,showlegend=True  ),\n",
        "            secondary_y=False,\n",
        "            #row=1, col=1\n",
        "\n",
        "        )\n",
        "\n",
        "    fig0.add_trace(\n",
        "        go.Scatter(x=fx.index, y=fx[desc1], name=txt1, line=dict(color=c1) ,showlegend=True  ),\n",
        "        secondary_y=False,\n",
        "        #row=1, col=1\n",
        "\n",
        "    )\n",
        "\n",
        "    fig0.update_layout(\n",
        "        title=title,\n",
        "        autosize=False,\n",
        "        width=1200,\n",
        "        height=600,\n",
        "        \n",
        "        )\n",
        "\n",
        "    print(title)\n",
        "    fig0.update_yaxes(title_text=\"<b>\"+title+\"</b>\", secondary_y=False)\n",
        "    #fig0.update_yaxes(title_text=\"<b>Alarm státusz</b>\", secondary_y=True)\n",
        "    fig0.update_layout(paper_bgcolor='rgb(200,200,200)')\n",
        "    fig0.show()"
      ],
      "metadata": {
        "id": "qa-AQAZV0EPd"
      },
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history_df=pd.DataFrame({\"epoch\":history.epoch, \"loss\":history.history[\"loss\"],\"val_loss\":history.history[\"val_loss\"]})"
      ],
      "metadata": {
        "id": "Uve0EfpV0Rkl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "60a3bf90-3d6f-4bba-a5da-d936ad266ae3"
      },
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-266-e7d36d1446ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: 'val_loss'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grafikon3(history_df,\"loss\",\"Loss\",\"val_loss\",\"Val_Loss\",title=None)"
      ],
      "metadata": {
        "id": "4ENvDCA-0U1g"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3fYxdlhKT0mZAL/YUaSK9",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3a8d680614944e95984728a70e5b46f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6eea2d0e7ba4948a42d4edbd705b63c",
              "IPY_MODEL_8cea66204b0d495bacb9124341fbc10b"
            ],
            "layout": "IPY_MODEL_9776370480df49c4a1d9738e1fc56795"
          }
        },
        "a6eea2d0e7ba4948a42d4edbd705b63c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c7adc8514634114b36f81b2a508185b",
            "placeholder": "​",
            "style": "IPY_MODEL_ae419c74223e4de086eccb300edcfece",
            "value": "0.001 MB of 0.099 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "8cea66204b0d495bacb9124341fbc10b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_726c3e51b435451abbc29be39807af3b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e57670f1da264245b75ffd1cb7ae9e9f",
            "value": 0.005652211463721247
          }
        },
        "9776370480df49c4a1d9738e1fc56795": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c7adc8514634114b36f81b2a508185b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae419c74223e4de086eccb300edcfece": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "726c3e51b435451abbc29be39807af3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e57670f1da264245b75ffd1cb7ae9e9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}